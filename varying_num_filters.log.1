Vocabulary Size: 33447
encodedPathwayA = 8 encodedPathwayB = 53
Varying number of filter
Starting Experiment - num_filter_128 



Starting Fold: 0 => Train/Dev split: 31795/10599


 #################### 


SEQUENCE LENGTH 273
BATCH SIZE 64
EMBEDDING SIZE 128
FILTER SIZES [3, 4, 5]
NUMBER OF FILTERS 128
L2 REG LAMBDA 0.0
EPOCHS 20



RESULT DIR num_filter_128_fold_0
VOCAB SIZE 33447
DROPOUT PROBABILITY 0.5



WORD EMBEDDING True
POSITION EMBEDDING True
POS EMBEDDING True


 #################### 


Writing to /Users/adb/Google Drive/Data Analytics/project/xtalkdb/Deep Learning/num_filter_128_fold_0/1512852011

Start training
2017-12-09T15:40:14.637584: step 1, loss 7.1319, acc 0.09375, prec 0, recall 0
2017-12-09T15:40:15.197984: step 2, loss 3.62392, acc 0.296875, prec 0, recall 0
2017-12-09T15:40:15.762301: step 3, loss 1.11725, acc 0.75, prec 0.00833333, recall 1
2017-12-09T15:40:16.325481: step 4, loss 11.4761, acc 0.890625, prec 0.00793651, recall 0.5
2017-12-09T15:40:16.898151: step 5, loss 19.5851, acc 0.90625, prec 0.00769231, recall 0.25
2017-12-09T15:40:17.473911: step 6, loss 13.0099, acc 0.9375, prec 0.0075188, recall 0.2
2017-12-09T15:40:18.052661: step 7, loss 25.66, acc 0.90625, prec 0.00729927, recall 0.142857
2017-12-09T15:40:18.619663: step 8, loss 2.68774, acc 0.75, prec 0.00657895, recall 0.125
2017-12-09T15:40:19.185766: step 9, loss 1.20809, acc 0.65625, prec 0.0114286, recall 0.222222
2017-12-09T15:40:19.738805: step 10, loss 7.30025, acc 0.609375, prec 0.010101, recall 0.181818
2017-12-09T15:40:20.299645: step 11, loss 2.63144, acc 0.390625, prec 0.00843882, recall 0.181818
2017-12-09T15:40:20.863855: step 12, loss 3.32061, acc 0.296875, prec 0.0070922, recall 0.181818
2017-12-09T15:40:21.414112: step 13, loss 3.85082, acc 0.375, prec 0.00621118, recall 0.181818
2017-12-09T15:40:21.975010: step 14, loss 4.68569, acc 0.28125, prec 0.00543478, recall 0.181818
2017-12-09T15:40:22.534717: step 15, loss 5.01168, acc 0.21875, prec 0.00478469, recall 0.181818
2017-12-09T15:40:23.098478: step 16, loss 5.04888, acc 0.203125, prec 0.00426439, recall 0.181818
2017-12-09T15:40:23.681819: step 17, loss 5.48414, acc 0.21875, prec 0.00385356, recall 0.181818
2017-12-09T15:40:24.240420: step 18, loss 4.57885, acc 0.28125, prec 0.00705467, recall 0.307692
2017-12-09T15:40:24.801006: step 19, loss 4.5387, acc 0.359375, prec 0.00657895, recall 0.307692
2017-12-09T15:40:25.365050: step 20, loss 3.56376, acc 0.328125, prec 0.00614439, recall 0.307692
2017-12-09T15:40:25.916191: step 21, loss 15.6911, acc 0.5625, prec 0.00736377, recall 0.333333
2017-12-09T15:40:26.473717: step 22, loss 11.9554, acc 0.53125, prec 0.00846262, recall 0.352941
2017-12-09T15:40:27.034380: step 23, loss 21.3593, acc 0.5625, prec 0.00817439, recall 0.3
2017-12-09T15:40:27.591354: step 24, loss 3.79175, acc 0.40625, prec 0.00905563, recall 0.333333
2017-12-09T15:40:28.146915: step 25, loss 9.804, acc 0.359375, prec 0.00982801, recall 0.347826
2017-12-09T15:40:28.693292: step 26, loss 4.54243, acc 0.25, prec 0.00928074, recall 0.347826
2017-12-09T15:40:29.242740: step 27, loss 5.30476, acc 0.234375, prec 0.00986842, recall 0.375
2017-12-09T15:40:29.789516: step 28, loss 5.09987, acc 0.28125, prec 0.012487, recall 0.444444
2017-12-09T15:40:30.340216: step 29, loss 6.1444, acc 0.28125, prec 0.0148515, recall 0.5
2017-12-09T15:40:30.894492: step 30, loss 4.83143, acc 0.25, prec 0.0160377, recall 0.53125
2017-12-09T15:40:31.441567: step 31, loss 4.22021, acc 0.3125, prec 0.017179, recall 0.558824
2017-12-09T15:40:32.003215: step 32, loss 6.03345, acc 0.234375, prec 0.0164502, recall 0.558824
2017-12-09T15:40:32.559553: step 33, loss 4.79697, acc 0.3125, prec 0.0174854, recall 0.583333
2017-12-09T15:40:33.109943: step 34, loss 14.1964, acc 0.3125, prec 0.016881, recall 0.567568
2017-12-09T15:40:33.680861: step 35, loss 20.8513, acc 0.265625, prec 0.0178019, recall 0.575
2017-12-09T15:40:34.260118: step 36, loss 6.27176, acc 0.328125, prec 0.0179775, recall 0.571429
2017-12-09T15:40:34.830323: step 37, loss 3.97896, acc 0.328125, prec 0.0174165, recall 0.571429
2017-12-09T15:40:35.392558: step 38, loss 4.4136, acc 0.296875, prec 0.0175562, recall 0.581395
2017-12-09T15:40:35.995767: step 39, loss 3.89916, acc 0.421875, prec 0.0177839, recall 0.590909
2017-12-09T15:40:36.563844: step 40, loss 3.66526, acc 0.34375, prec 0.0172872, recall 0.590909
2017-12-09T15:40:37.150563: step 41, loss 9.53323, acc 0.484375, prec 0.0175667, recall 0.586957
2017-12-09T15:40:37.726289: step 42, loss 3.07555, acc 0.484375, prec 0.0171975, recall 0.586957
2017-12-09T15:40:38.318376: step 43, loss 2.55359, acc 0.5625, prec 0.0168961, recall 0.586957
2017-12-09T15:40:38.884893: step 44, loss 2.02761, acc 0.578125, prec 0.0166154, recall 0.586957
2017-12-09T15:40:39.447119: step 45, loss 2.93412, acc 0.46875, prec 0.0162749, recall 0.586957
2017-12-09T15:40:39.993615: step 46, loss 3.91864, acc 0.484375, prec 0.0165485, recall 0.583333
2017-12-09T15:40:40.544238: step 47, loss 3.51071, acc 0.546875, prec 0.0174216, recall 0.588235
2017-12-09T15:40:41.097911: step 48, loss 2.17705, acc 0.5, prec 0.0171038, recall 0.588235
2017-12-09T15:40:41.648417: step 49, loss 1.58342, acc 0.59375, prec 0.0168539, recall 0.588235
2017-12-09T15:40:42.261568: step 50, loss 16.8335, acc 0.484375, prec 0.0165654, recall 0.566038
2017-12-09T15:40:42.852680: step 51, loss 1.62754, acc 0.515625, prec 0.0162866, recall 0.566038
2017-12-09T15:40:43.466213: step 52, loss 8.63177, acc 0.546875, prec 0.0171032, recall 0.561404
2017-12-09T15:40:44.081889: step 53, loss 2.13884, acc 0.609375, prec 0.0168776, recall 0.561404
2017-12-09T15:40:44.647463: step 54, loss 2.01374, acc 0.578125, prec 0.0171518, recall 0.568965
2017-12-09T15:40:45.203276: step 55, loss 2.13893, acc 0.421875, prec 0.0168281, recall 0.568965
2017-12-09T15:40:45.759525: step 56, loss 3.04871, acc 0.53125, prec 0.0170683, recall 0.576271
2017-12-09T15:40:46.310813: step 57, loss 2.20652, acc 0.5625, prec 0.0168317, recall 0.576271
2017-12-09T15:40:46.861429: step 58, loss 8.9098, acc 0.578125, prec 0.0170982, recall 0.57377
2017-12-09T15:40:47.412615: step 59, loss 3.15845, acc 0.5, prec 0.0177799, recall 0.587302
2017-12-09T15:40:47.962759: step 60, loss 4.76425, acc 0.46875, prec 0.0188947, recall 0.597015
2017-12-09T15:40:48.507009: step 61, loss 3.25327, acc 0.3125, prec 0.0185099, recall 0.597015
2017-12-09T15:40:49.061045: step 62, loss 2.74929, acc 0.515625, prec 0.0182482, recall 0.597015
2017-12-09T15:40:49.614410: step 63, loss 3.85573, acc 0.53125, prec 0.0184518, recall 0.594203
2017-12-09T15:40:50.177081: step 64, loss 5.0306, acc 0.40625, prec 0.0190097, recall 0.605634
2017-12-09T15:40:50.729243: step 65, loss 3.12053, acc 0.421875, prec 0.0191304, recall 0.611111
2017-12-09T15:40:51.282041: step 66, loss 6.57463, acc 0.46875, prec 0.0192802, recall 0.608108
2017-12-09T15:40:51.833947: step 67, loss 3.98849, acc 0.34375, prec 0.0193521, recall 0.613333
2017-12-09T15:40:52.431429: step 68, loss 3.4944, acc 0.40625, prec 0.0190476, recall 0.613333
2017-12-09T15:40:52.982436: step 69, loss 2.867, acc 0.390625, prec 0.0191446, recall 0.618421
2017-12-09T15:40:53.544183: step 70, loss 3.21765, acc 0.4375, prec 0.0192616, recall 0.623377
2017-12-09T15:40:54.093208: step 71, loss 3.12862, acc 0.46875, prec 0.0197785, recall 0.632911
2017-12-09T15:40:54.648981: step 72, loss 3.18547, acc 0.546875, prec 0.0199452, recall 0.62963
2017-12-09T15:40:55.214981: step 73, loss 2.53495, acc 0.46875, prec 0.0196835, recall 0.62963
2017-12-09T15:40:55.778245: step 74, loss 2.1533, acc 0.578125, prec 0.0194805, recall 0.62963
2017-12-09T15:40:56.334333: step 75, loss 6.1344, acc 0.5, prec 0.020362, recall 0.635294
2017-12-09T15:40:56.890757: step 76, loss 1.82006, acc 0.640625, prec 0.0205531, recall 0.639535
2017-12-09T15:40:57.442306: step 77, loss 1.34705, acc 0.625, prec 0.0203704, recall 0.639535
2017-12-09T15:40:58.002520: step 78, loss 1.92884, acc 0.640625, prec 0.0209174, recall 0.647727
2017-12-09T15:40:58.570742: step 79, loss 1.90591, acc 0.5625, prec 0.0210603, recall 0.651685
2017-12-09T15:40:59.164919: step 80, loss 9.24612, acc 0.671875, prec 0.0212613, recall 0.648352
2017-12-09T15:40:59.747383: step 81, loss 1.61109, acc 0.734375, prec 0.0211318, recall 0.648352
2017-12-09T15:41:00.316376: step 82, loss 1.39034, acc 0.640625, prec 0.0213068, recall 0.652174
2017-12-09T15:41:00.888455: step 83, loss 1.30315, acc 0.6875, prec 0.0215016, recall 0.655914
2017-12-09T15:41:01.464586: step 84, loss 1.38466, acc 0.75, prec 0.021381, recall 0.655914
2017-12-09T15:41:02.037301: step 85, loss 1.59753, acc 0.625, prec 0.0212026, recall 0.655914
2017-12-09T15:41:02.608638: step 86, loss 1.14245, acc 0.828125, prec 0.0211219, recall 0.655914
2017-12-09T15:41:03.200679: step 87, loss 5.17134, acc 0.5625, prec 0.0209262, recall 0.648936
2017-12-09T15:41:03.778251: step 88, loss 1.11849, acc 0.734375, prec 0.0214724, recall 0.65625
2017-12-09T15:41:04.344716: step 89, loss 3.70601, acc 0.625, prec 0.0216362, recall 0.653061
2017-12-09T15:41:04.921014: step 90, loss 1.01716, acc 0.765625, prec 0.0215271, recall 0.653061
2017-12-09T15:41:05.497826: step 91, loss 1.6627, acc 0.734375, prec 0.0214047, recall 0.653061
2017-12-09T15:41:06.074968: step 92, loss 1.43528, acc 0.796875, prec 0.0216378, recall 0.656566
2017-12-09T15:41:06.652591: step 93, loss 12.9771, acc 0.59375, prec 0.0217822, recall 0.653465
2017-12-09T15:41:07.232585: step 94, loss 0.902073, acc 0.765625, prec 0.0219961, recall 0.656863
2017-12-09T15:41:07.813414: step 95, loss 1.10096, acc 0.671875, prec 0.0218455, recall 0.656863
2017-12-09T15:41:08.389840: step 96, loss 4.1945, acc 0.609375, prec 0.0223084, recall 0.657143
2017-12-09T15:41:08.972417: step 97, loss 8.64062, acc 0.625, prec 0.0224575, recall 0.654206
2017-12-09T15:41:09.547184: step 98, loss 9.10398, acc 0.578125, prec 0.0222788, recall 0.642202
2017-12-09T15:41:10.129617: step 99, loss 2.56526, acc 0.5625, prec 0.0223904, recall 0.645455
2017-12-09T15:41:10.701277: step 100, loss 8.78333, acc 0.25, prec 0.0220634, recall 0.63964
Saved model checkpoint to /Users/adb/Google Drive/Data Analytics/project/xtalkdb/Deep Learning/num_filter_128_fold_0/1512852011/checkpoints/model-100

2017-12-09T15:41:12.056707: step 101, loss 3.74725, acc 0.390625, prec 0.0220994, recall 0.642857
2017-12-09T15:41:12.625332: step 102, loss 4.58364, acc 0.28125, prec 0.0220877, recall 0.646018
2017-12-09T15:41:13.197120: step 103, loss 3.93093, acc 0.328125, prec 0.0220961, recall 0.649123
2017-12-09T15:41:13.777822: step 104, loss 6.25957, acc 0.1875, prec 0.0223332, recall 0.655172
2017-12-09T15:41:14.358064: step 105, loss 6.44407, acc 0.21875, prec 0.0220098, recall 0.655172
2017-12-09T15:41:14.936639: step 106, loss 5.28984, acc 0.234375, prec 0.0219812, recall 0.65812
2017-12-09T15:41:15.511672: step 107, loss 5.25408, acc 0.25, prec 0.021684, recall 0.65812
2017-12-09T15:41:16.083108: step 108, loss 5.37646, acc 0.25, prec 0.0216667, recall 0.661017
2017-12-09T15:41:16.655028: step 109, loss 4.45428, acc 0.34375, prec 0.0214168, recall 0.661017
2017-12-09T15:41:17.238100: step 110, loss 3.11733, acc 0.484375, prec 0.0214908, recall 0.663866
2017-12-09T15:41:17.813189: step 111, loss 3.4872, acc 0.40625, prec 0.0215343, recall 0.666667
2017-12-09T15:41:18.388151: step 112, loss 6.34368, acc 0.4375, prec 0.0215942, recall 0.663934
2017-12-09T15:41:18.965787: step 113, loss 5.14355, acc 0.609375, prec 0.0219751, recall 0.664
2017-12-09T15:41:19.541335: step 114, loss 2.50487, acc 0.546875, prec 0.0220646, recall 0.666667
2017-12-09T15:41:20.119016: step 115, loss 2.46516, acc 0.59375, prec 0.0219149, recall 0.666667
2017-12-09T15:41:20.706574: step 116, loss 9.75975, acc 0.53125, prec 0.0217504, recall 0.661417
2017-12-09T15:41:21.292538: step 117, loss 13.5694, acc 0.546875, prec 0.0218453, recall 0.658915
2017-12-09T15:41:21.873197: step 118, loss 2.39529, acc 0.578125, prec 0.0219444, recall 0.661538
2017-12-09T15:41:22.452092: step 119, loss 2.59977, acc 0.546875, prec 0.0220309, recall 0.664122
2017-12-09T15:41:23.031329: step 120, loss 2.32949, acc 0.53125, prec 0.0228471, recall 0.674074
2017-12-09T15:41:23.611385: step 121, loss 2.0066, acc 0.5625, prec 0.0226876, recall 0.674074
2017-12-09T15:41:24.185642: step 122, loss 1.94541, acc 0.625, prec 0.0225527, recall 0.674074
2017-12-09T15:41:24.771170: step 123, loss 1.68929, acc 0.6875, prec 0.0226824, recall 0.676471
2017-12-09T15:41:25.355420: step 124, loss 1.65672, acc 0.5625, prec 0.0225269, recall 0.676471
2017-12-09T15:41:25.936367: step 125, loss 1.8418, acc 0.734375, prec 0.0226719, recall 0.678832
2017-12-09T15:41:26.525490: step 126, loss 3.59826, acc 0.6875, prec 0.0228045, recall 0.676259
2017-12-09T15:41:27.109295: step 127, loss 1.69351, acc 0.765625, prec 0.022958, recall 0.678571
2017-12-09T15:41:27.687583: step 128, loss 2.68475, acc 0.640625, prec 0.0228311, recall 0.678571
2017-12-09T15:41:28.273286: step 129, loss 1.47816, acc 0.671875, prec 0.0227164, recall 0.678571
2017-12-09T15:41:28.850553: step 130, loss 1.2048, acc 0.71875, prec 0.022619, recall 0.678571
2017-12-09T15:41:29.425920: step 131, loss 1.17076, acc 0.765625, prec 0.0227704, recall 0.680851
2017-12-09T15:41:30.014290: step 132, loss 1.87067, acc 0.78125, prec 0.022926, recall 0.683099
2017-12-09T15:41:30.598648: step 133, loss 12.1535, acc 0.78125, prec 0.0228558, recall 0.678322
2017-12-09T15:41:31.175205: step 134, loss 0.841314, acc 0.78125, prec 0.0230101, recall 0.680556
2017-12-09T15:41:31.759904: step 135, loss 1.39946, acc 0.828125, prec 0.0231796, recall 0.682759
2017-12-09T15:41:32.341934: step 136, loss 3.37278, acc 0.71875, prec 0.0233155, recall 0.680272
2017-12-09T15:41:32.918843: step 137, loss 6.403, acc 0.6875, prec 0.0234448, recall 0.673333
2017-12-09T15:41:33.495834: step 138, loss 2.7126, acc 0.53125, prec 0.0235077, recall 0.675497
2017-12-09T15:41:34.074834: step 139, loss 2.85259, acc 0.53125, prec 0.0235698, recall 0.677632
2017-12-09T15:41:34.657536: step 140, loss 3.23102, acc 0.453125, prec 0.0233825, recall 0.677632
2017-12-09T15:41:35.243138: step 141, loss 6.58062, acc 0.5, prec 0.0236593, recall 0.677419
2017-12-09T15:41:35.824042: step 142, loss 3.66695, acc 0.390625, prec 0.0236713, recall 0.679487
2017-12-09T15:41:36.426321: step 143, loss 4.76654, acc 0.296875, prec 0.0236516, recall 0.681529
2017-12-09T15:41:37.006799: step 144, loss 6.07997, acc 0.359375, prec 0.0234443, recall 0.677215
2017-12-09T15:41:37.591809: step 145, loss 2.7705, acc 0.4375, prec 0.0234732, recall 0.679245
2017-12-09T15:41:38.176318: step 146, loss 4.89154, acc 0.359375, prec 0.0232658, recall 0.679245
2017-12-09T15:41:38.758678: step 147, loss 4.07079, acc 0.359375, prec 0.0232707, recall 0.68125
2017-12-09T15:41:39.340306: step 148, loss 3.97443, acc 0.46875, prec 0.0237238, recall 0.687117
2017-12-09T15:41:39.924115: step 149, loss 4.44372, acc 0.40625, prec 0.0235344, recall 0.687117
2017-12-09T15:41:40.512414: step 150, loss 3.5007, acc 0.40625, prec 0.0233479, recall 0.687117
2017-12-09T15:41:41.112442: step 151, loss 4.59611, acc 0.328125, prec 0.0231405, recall 0.687117
2017-12-09T15:41:41.697492: step 152, loss 3.29459, acc 0.515625, prec 0.0233942, recall 0.690909
2017-12-09T15:41:42.324096: step 153, loss 3.95511, acc 0.34375, prec 0.023393, recall 0.692771
2017-12-09T15:41:42.904460: step 154, loss 2.57433, acc 0.53125, prec 0.0232511, recall 0.692771
2017-12-09T15:41:43.488627: step 155, loss 2.43385, acc 0.53125, prec 0.0231109, recall 0.692771
2017-12-09T15:41:44.073285: step 156, loss 1.54477, acc 0.6875, prec 0.0236047, recall 0.698225
2017-12-09T15:41:44.661404: step 157, loss 1.25241, acc 0.703125, prec 0.0237099, recall 0.7
2017-12-09T15:41:45.249249: step 158, loss 1.34553, acc 0.71875, prec 0.023819, recall 0.701754
2017-12-09T15:41:45.829325: step 159, loss 13.5177, acc 0.734375, prec 0.0239414, recall 0.695402
2017-12-09T15:41:46.419496: step 160, loss 1.19263, acc 0.734375, prec 0.0238612, recall 0.695402
2017-12-09T15:41:47.009810: step 161, loss 7.00607, acc 0.640625, prec 0.0237581, recall 0.691429
2017-12-09T15:41:47.596500: step 162, loss 6.52066, acc 0.765625, prec 0.0246527, recall 0.692308
2017-12-09T15:41:48.182049: step 163, loss 1.53536, acc 0.671875, prec 0.0247419, recall 0.693989
2017-12-09T15:41:48.770037: step 164, loss 1.94434, acc 0.65625, prec 0.0246363, recall 0.693989
2017-12-09T15:41:49.361106: step 165, loss 2.08929, acc 0.59375, prec 0.0245126, recall 0.693989
2017-12-09T15:41:49.957286: step 166, loss 2.35549, acc 0.59375, prec 0.0245776, recall 0.695652
2017-12-09T15:41:50.543970: step 167, loss 2.62409, acc 0.59375, prec 0.0246418, recall 0.697297
2017-12-09T15:41:51.145550: step 168, loss 3.07315, acc 0.53125, prec 0.0245014, recall 0.697297
2017-12-09T15:41:51.736711: step 169, loss 3.01048, acc 0.5625, prec 0.0243718, recall 0.697297
2017-12-09T15:41:52.339225: step 170, loss 3.15207, acc 0.546875, prec 0.0246056, recall 0.700535
2017-12-09T15:41:52.953124: step 171, loss 2.18614, acc 0.5625, prec 0.0244768, recall 0.700535
2017-12-09T15:41:53.573492: step 172, loss 1.86617, acc 0.59375, prec 0.0243585, recall 0.700535
2017-12-09T15:41:54.169512: step 173, loss 2.74668, acc 0.53125, prec 0.0242234, recall 0.700535
2017-12-09T15:41:54.761663: step 174, loss 1.95564, acc 0.5625, prec 0.0244575, recall 0.703704
2017-12-09T15:41:55.352132: step 175, loss 1.9899, acc 0.671875, prec 0.0245421, recall 0.705263
2017-12-09T15:41:55.942912: step 176, loss 2.51438, acc 0.65625, prec 0.0244436, recall 0.705263
2017-12-09T15:41:56.531023: step 177, loss 1.39284, acc 0.65625, prec 0.0243459, recall 0.705263
2017-12-09T15:41:57.116521: step 178, loss 1.33373, acc 0.734375, prec 0.024271, recall 0.705263
2017-12-09T15:41:57.710072: step 179, loss 1.00088, acc 0.765625, prec 0.0243814, recall 0.706806
2017-12-09T15:41:58.304901: step 180, loss 7.67036, acc 0.703125, prec 0.0243024, recall 0.703125
2017-12-09T15:41:58.896336: step 181, loss 1.65214, acc 0.703125, prec 0.0242196, recall 0.703125
2017-12-09T15:41:59.486328: step 182, loss 1.1182, acc 0.75, prec 0.0241503, recall 0.703125
2017-12-09T15:42:00.073789: step 183, loss 1.83965, acc 0.640625, prec 0.0240513, recall 0.703125
2017-12-09T15:42:00.661397: step 184, loss 1.05259, acc 0.78125, prec 0.0239915, recall 0.703125
2017-12-09T15:42:01.259716: step 185, loss 0.639419, acc 0.8125, prec 0.0239404, recall 0.703125
2017-12-09T15:42:01.861011: step 186, loss 0.737306, acc 0.8125, prec 0.0238896, recall 0.703125
2017-12-09T15:42:02.440736: step 187, loss 0.682911, acc 0.828125, prec 0.0238432, recall 0.703125
2017-12-09T15:42:03.059971: step 188, loss 1.41751, acc 0.765625, prec 0.024124, recall 0.706186
2017-12-09T15:42:03.647247: step 189, loss 0.991331, acc 0.828125, prec 0.0242488, recall 0.707692
2017-12-09T15:42:04.259040: step 190, loss 6.75389, acc 0.859375, prec 0.024386, recall 0.705584
2017-12-09T15:42:04.859480: step 191, loss 0.79534, acc 0.828125, prec 0.024339, recall 0.705584
2017-12-09T15:42:05.435510: step 192, loss 2.9298, acc 0.875, prec 0.0243092, recall 0.70202
2017-12-09T15:42:06.020345: step 193, loss 0.412244, acc 0.859375, prec 0.024271, recall 0.70202
2017-12-09T15:42:06.609818: step 194, loss 0.652427, acc 0.828125, prec 0.0242245, recall 0.70202
2017-12-09T15:42:07.195966: step 195, loss 0.365293, acc 0.875, prec 0.0243605, recall 0.703518
2017-12-09T15:42:07.773824: step 196, loss 19.0522, acc 0.78125, prec 0.0244749, recall 0.701493
2017-12-09T15:42:08.360386: step 197, loss 0.594341, acc 0.8125, prec 0.024424, recall 0.701493
2017-12-09T15:42:08.948738: step 198, loss 4.70472, acc 0.8125, prec 0.0248834, recall 0.702439
2017-12-09T15:42:09.545509: step 199, loss 11.563, acc 0.734375, prec 0.0248148, recall 0.699029
2017-12-09T15:42:10.140038: step 200, loss 0.85441, acc 0.734375, prec 0.0249098, recall 0.700483
Saved model checkpoint to /Users/adb/Google Drive/Data Analytics/project/xtalkdb/Deep Learning/num_filter_128_fold_0/1512852011/checkpoints/model-200

2017-12-09T15:42:11.527019: step 201, loss 1.63039, acc 0.703125, prec 0.0248288, recall 0.700483
2017-12-09T15:42:12.110071: step 202, loss 1.8296, acc 0.640625, prec 0.0250639, recall 0.703349
2017-12-09T15:42:12.701016: step 203, loss 2.55994, acc 0.484375, prec 0.0249237, recall 0.703349
2017-12-09T15:42:13.278948: step 204, loss 8.95268, acc 0.46875, prec 0.024785, recall 0.7
2017-12-09T15:42:13.861737: step 205, loss 2.92285, acc 0.46875, prec 0.0248072, recall 0.701422
2017-12-09T15:42:14.437081: step 206, loss 3.27985, acc 0.484375, prec 0.0248333, recall 0.70283
2017-12-09T15:42:15.013379: step 207, loss 3.26736, acc 0.421875, prec 0.0246811, recall 0.70283
2017-12-09T15:42:15.586596: step 208, loss 3.79465, acc 0.390625, prec 0.0245227, recall 0.70283
2017-12-09T15:42:16.167067: step 209, loss 3.04289, acc 0.359375, prec 0.0243583, recall 0.70283
2017-12-09T15:42:16.747380: step 210, loss 2.92539, acc 0.484375, prec 0.0245449, recall 0.705607
2017-12-09T15:42:17.324757: step 211, loss 2.95973, acc 0.453125, prec 0.0245637, recall 0.706977
2017-12-09T15:42:17.904161: step 212, loss 2.42074, acc 0.578125, prec 0.0246139, recall 0.708333
2017-12-09T15:42:18.484447: step 213, loss 2.88223, acc 0.453125, prec 0.0244761, recall 0.708333
2017-12-09T15:42:19.064663: step 214, loss 1.69065, acc 0.625, prec 0.0246933, recall 0.711009
2017-12-09T15:42:19.668996: step 215, loss 1.37956, acc 0.640625, prec 0.0246032, recall 0.711009
2017-12-09T15:42:20.274717: step 216, loss 0.876738, acc 0.765625, prec 0.0245447, recall 0.711009
2017-12-09T15:42:20.849098: step 217, loss 7.42971, acc 0.71875, prec 0.0244788, recall 0.707763
2017-12-09T15:42:21.430983: step 218, loss 0.985992, acc 0.765625, prec 0.0245747, recall 0.709091
2017-12-09T15:42:22.015778: step 219, loss 1.41752, acc 0.734375, prec 0.0246623, recall 0.710407
2017-12-09T15:42:22.597864: step 220, loss 0.733857, acc 0.859375, prec 0.0246275, recall 0.710407
2017-12-09T15:42:23.181967: step 221, loss 1.03353, acc 0.8125, prec 0.0247339, recall 0.711712
2017-12-09T15:42:23.763022: step 222, loss 0.550786, acc 0.875, prec 0.0248554, recall 0.713004
2017-12-09T15:42:24.343910: step 223, loss 1.03832, acc 0.796875, prec 0.0254132, recall 0.718062
2017-12-09T15:42:24.927309: step 224, loss 6.72233, acc 0.78125, prec 0.0253618, recall 0.714912
2017-12-09T15:42:25.510262: step 225, loss 0.4113, acc 0.921875, prec 0.0254935, recall 0.716157
2017-12-09T15:42:26.090996: step 226, loss 0.721725, acc 0.875, prec 0.0254619, recall 0.716157
2017-12-09T15:42:26.677365: step 227, loss 14.7302, acc 0.84375, prec 0.0254342, recall 0.706897
2017-12-09T15:42:27.266168: step 228, loss 0.958935, acc 0.734375, prec 0.0253674, recall 0.706897
2017-12-09T15:42:27.846723: step 229, loss 0.92826, acc 0.78125, prec 0.0253125, recall 0.706897
2017-12-09T15:42:28.424626: step 230, loss 1.84972, acc 0.59375, prec 0.0252114, recall 0.706897
2017-12-09T15:42:29.006952: step 231, loss 1.26059, acc 0.703125, prec 0.025138, recall 0.706897
2017-12-09T15:42:29.589854: step 232, loss 1.07514, acc 0.765625, prec 0.0253784, recall 0.709402
2017-12-09T15:42:30.168619: step 233, loss 8.70505, acc 0.6875, prec 0.0254534, recall 0.707627
2017-12-09T15:42:30.752981: step 234, loss 1.84086, acc 0.609375, prec 0.0256527, recall 0.710084
2017-12-09T15:42:31.334769: step 235, loss 1.72477, acc 0.671875, prec 0.0255712, recall 0.710084
2017-12-09T15:42:31.912520: step 236, loss 1.52242, acc 0.6875, prec 0.025641, recall 0.711297
2017-12-09T15:42:32.493491: step 237, loss 1.76459, acc 0.609375, prec 0.0255447, recall 0.711297
2017-12-09T15:42:33.078931: step 238, loss 2.18863, acc 0.578125, prec 0.0255873, recall 0.7125
2017-12-09T15:42:33.661998: step 239, loss 2.33182, acc 0.546875, prec 0.0256219, recall 0.713693
2017-12-09T15:42:34.242007: step 240, loss 1.93962, acc 0.609375, prec 0.0255269, recall 0.713693
2017-12-09T15:42:34.817758: step 241, loss 2.20943, acc 0.640625, prec 0.0255841, recall 0.714876
2017-12-09T15:42:35.391792: step 242, loss 1.34821, acc 0.59375, prec 0.0254862, recall 0.714876
2017-12-09T15:42:35.977413: step 243, loss 1.86497, acc 0.578125, prec 0.0255282, recall 0.716049
2017-12-09T15:42:36.559442: step 244, loss 1.83613, acc 0.578125, prec 0.0254274, recall 0.716049
2017-12-09T15:42:37.145828: step 245, loss 7.7671, acc 0.578125, prec 0.0254731, recall 0.714286
2017-12-09T15:42:37.732140: step 246, loss 0.561387, acc 0.8125, prec 0.0254287, recall 0.714286
2017-12-09T15:42:38.316589: step 247, loss 9.35827, acc 0.734375, prec 0.0255146, recall 0.709677
2017-12-09T15:42:38.903199: step 248, loss 1.43372, acc 0.765625, prec 0.0256002, recall 0.710843
2017-12-09T15:42:39.486551: step 249, loss 1.6106, acc 0.640625, prec 0.0255154, recall 0.710843
2017-12-09T15:42:40.073801: step 250, loss 1.65937, acc 0.640625, prec 0.025431, recall 0.710843
2017-12-09T15:42:40.664334: step 251, loss 1.31106, acc 0.65625, prec 0.0253509, recall 0.710843
2017-12-09T15:42:41.245944: step 252, loss 1.35467, acc 0.6875, prec 0.0252785, recall 0.710843
2017-12-09T15:42:41.849792: step 253, loss 1.40756, acc 0.703125, prec 0.0252101, recall 0.710843
2017-12-09T15:42:42.449407: step 254, loss 1.57139, acc 0.578125, prec 0.0253901, recall 0.713147
2017-12-09T15:42:43.038946: step 255, loss 1.53489, acc 0.828125, prec 0.0256265, recall 0.715415
2017-12-09T15:42:43.627495: step 256, loss 1.16327, acc 0.734375, prec 0.025565, recall 0.715415
2017-12-09T15:42:44.214519: step 257, loss 1.40046, acc 0.625, prec 0.0254786, recall 0.715415
2017-12-09T15:42:44.796115: step 258, loss 1.30183, acc 0.640625, prec 0.0255331, recall 0.716535
2017-12-09T15:42:45.385878: step 259, loss 3.30502, acc 0.765625, prec 0.0256195, recall 0.714844
2017-12-09T15:42:45.976428: step 260, loss 0.796224, acc 0.796875, prec 0.0257091, recall 0.715953
2017-12-09T15:42:46.566689: step 261, loss 1.26752, acc 0.765625, prec 0.025927, recall 0.718147
2017-12-09T15:42:47.149840: step 262, loss 1.34359, acc 0.6875, prec 0.0258549, recall 0.718147
2017-12-09T15:42:47.731338: step 263, loss 0.917986, acc 0.765625, prec 0.0258011, recall 0.718147
2017-12-09T15:42:48.317551: step 264, loss 0.745574, acc 0.796875, prec 0.0258895, recall 0.719231
2017-12-09T15:42:48.905127: step 265, loss 1.27681, acc 0.734375, prec 0.0258287, recall 0.719231
2017-12-09T15:42:49.487028: step 266, loss 0.871947, acc 0.796875, prec 0.0257824, recall 0.719231
2017-12-09T15:42:50.073909: step 267, loss 1.03138, acc 0.828125, prec 0.0258775, recall 0.720307
2017-12-09T15:42:50.651878: step 268, loss 1.12375, acc 0.765625, prec 0.0258242, recall 0.720307
2017-12-09T15:42:51.235209: step 269, loss 0.945202, acc 0.8125, prec 0.0259153, recall 0.721374
2017-12-09T15:42:51.822045: step 270, loss 9.27929, acc 0.828125, prec 0.0258798, recall 0.718631
2017-12-09T15:42:52.404547: step 271, loss 0.769088, acc 0.796875, prec 0.0258338, recall 0.718631
2017-12-09T15:42:52.980078: step 272, loss 0.557004, acc 0.8125, prec 0.0257915, recall 0.718631
2017-12-09T15:42:53.575373: step 273, loss 7.39708, acc 0.75, prec 0.0257388, recall 0.715909
2017-12-09T15:42:54.159372: step 274, loss 1.2169, acc 0.6875, prec 0.0256689, recall 0.715909
2017-12-09T15:42:54.747008: step 275, loss 0.339662, acc 0.875, prec 0.025641, recall 0.715909
2017-12-09T15:42:55.330780: step 276, loss 1.42238, acc 0.703125, prec 0.0255751, recall 0.715909
2017-12-09T15:42:55.915042: step 277, loss 21.1656, acc 0.71875, prec 0.0256549, recall 0.708955
2017-12-09T15:42:56.496661: step 278, loss 6.04996, acc 0.78125, prec 0.0256099, recall 0.70632
2017-12-09T15:42:57.072411: step 279, loss 1.84996, acc 0.609375, prec 0.0255239, recall 0.70632
2017-12-09T15:42:57.653857: step 280, loss 1.80548, acc 0.703125, prec 0.0255895, recall 0.707407
2017-12-09T15:42:58.233031: step 281, loss 3.19402, acc 0.453125, prec 0.0256, recall 0.708487
2017-12-09T15:42:58.806441: step 282, loss 2.22392, acc 0.53125, prec 0.0257568, recall 0.710623
2017-12-09T15:42:59.385718: step 283, loss 2.21117, acc 0.625, prec 0.0258039, recall 0.711679
2017-12-09T15:42:59.955810: step 284, loss 3.06945, acc 0.390625, prec 0.0257997, recall 0.712727
2017-12-09T15:43:00.533750: step 285, loss 3.74719, acc 0.46875, prec 0.02594, recall 0.714801
2017-12-09T15:43:01.111406: step 286, loss 2.53353, acc 0.5, prec 0.0259588, recall 0.715827
2017-12-09T15:43:01.693546: step 287, loss 3.02031, acc 0.453125, prec 0.0260937, recall 0.717857
2017-12-09T15:43:02.269127: step 288, loss 2.76598, acc 0.609375, prec 0.0261353, recall 0.718861
2017-12-09T15:43:02.850645: step 289, loss 3.3594, acc 0.578125, prec 0.0264209, recall 0.721831
2017-12-09T15:43:03.443684: step 290, loss 2.57844, acc 0.5, prec 0.0264374, recall 0.722807
2017-12-09T15:43:04.025115: step 291, loss 2.47813, acc 0.59375, prec 0.0263494, recall 0.722807
2017-12-09T15:43:04.598788: step 292, loss 2.14503, acc 0.5625, prec 0.0263795, recall 0.723776
2017-12-09T15:43:05.172028: step 293, loss 12.3961, acc 0.5625, prec 0.0262891, recall 0.721254
2017-12-09T15:43:05.753160: step 294, loss 2.15331, acc 0.53125, prec 0.0261893, recall 0.721254
2017-12-09T15:43:06.327733: step 295, loss 2.15827, acc 0.578125, prec 0.0261001, recall 0.721254
2017-12-09T15:43:06.900084: step 296, loss 1.63549, acc 0.625, prec 0.0260214, recall 0.721254
2017-12-09T15:43:07.471197: step 297, loss 1.54698, acc 0.6875, prec 0.0259561, recall 0.721254
2017-12-09T15:43:08.049354: step 298, loss 0.945561, acc 0.75, prec 0.026026, recall 0.722222
2017-12-09T15:43:08.622706: step 299, loss 1.61759, acc 0.6875, prec 0.0259611, recall 0.722222
2017-12-09T15:43:09.194721: step 300, loss 0.69586, acc 0.828125, prec 0.0259255, recall 0.722222

Evaluation:
2017-12-09T15:44:02.447486: step 300, loss 1.78988, acc 0.803849, prec 0.0322264, recall 0.725664

Saved model checkpoint to /Users/adb/Google Drive/Data Analytics/project/xtalkdb/Deep Learning/num_filter_128_fold_0/1512852011/checkpoints/model-300

2017-12-09T15:44:04.556292: step 301, loss 0.948172, acc 0.78125, prec 0.0321821, recall 0.725664
2017-12-09T15:44:05.178185: step 302, loss 0.925985, acc 0.75, prec 0.0322265, recall 0.726269
2017-12-09T15:44:05.780279: step 303, loss 0.857824, acc 0.828125, prec 0.0322865, recall 0.726872
2017-12-09T15:44:06.357709: step 304, loss 13.0557, acc 0.78125, prec 0.0322455, recall 0.725275
2017-12-09T15:44:06.921655: step 305, loss 0.554867, acc 0.8125, prec 0.0322077, recall 0.725275
2017-12-09T15:44:07.483923: step 306, loss 2.6345, acc 0.8125, prec 0.0321731, recall 0.723684
2017-12-09T15:44:08.049137: step 307, loss 1.22979, acc 0.765625, prec 0.0322204, recall 0.724289
2017-12-09T15:44:08.605191: step 308, loss 13.2723, acc 0.8125, prec 0.0322832, recall 0.721739
2017-12-09T15:44:09.187411: step 309, loss 3.54108, acc 0.84375, prec 0.0322549, recall 0.720174
2017-12-09T15:44:09.758489: step 310, loss 0.847621, acc 0.75, prec 0.0322049, recall 0.720174
2017-12-09T15:44:10.319464: step 311, loss 1.09939, acc 0.75, prec 0.032155, recall 0.720174
2017-12-09T15:44:10.888289: step 312, loss 2.51011, acc 0.640625, prec 0.032177, recall 0.720779
2017-12-09T15:44:11.456819: step 313, loss 2.05747, acc 0.53125, prec 0.032084, recall 0.720779
2017-12-09T15:44:12.026247: step 314, loss 2.76642, acc 0.546875, prec 0.0320876, recall 0.721382
2017-12-09T15:44:12.598063: step 315, loss 2.83805, acc 0.46875, prec 0.0319831, recall 0.721382
2017-12-09T15:44:13.174695: step 316, loss 3.00125, acc 0.421875, prec 0.0318702, recall 0.721382
2017-12-09T15:44:13.776750: step 317, loss 2.53349, acc 0.546875, prec 0.0318744, recall 0.721983
2017-12-09T15:44:14.402571: step 318, loss 3.01114, acc 0.453125, prec 0.0318604, recall 0.722581
2017-12-09T15:44:14.978529: step 319, loss 4.03309, acc 0.40625, prec 0.031932, recall 0.722222
2017-12-09T15:44:15.545686: step 320, loss 5.67143, acc 0.46875, prec 0.0318327, recall 0.720682
2017-12-09T15:44:16.122912: step 321, loss 7.67993, acc 0.671875, prec 0.0319549, recall 0.720339
2017-12-09T15:44:16.693912: step 322, loss 2.90958, acc 0.390625, prec 0.0319288, recall 0.72093
2017-12-09T15:44:17.260500: step 323, loss 2.76393, acc 0.46875, prec 0.0318275, recall 0.72093
2017-12-09T15:44:17.828044: step 324, loss 2.92754, acc 0.453125, prec 0.031904, recall 0.722105
2017-12-09T15:44:18.396238: step 325, loss 2.01029, acc 0.65625, prec 0.0319287, recall 0.722689
2017-12-09T15:44:18.963670: step 326, loss 2.59888, acc 0.46875, prec 0.0319178, recall 0.72327
2017-12-09T15:44:19.539212: step 327, loss 1.7032, acc 0.578125, prec 0.0318383, recall 0.72327
2017-12-09T15:44:20.107749: step 328, loss 2.73086, acc 0.46875, prec 0.0317387, recall 0.72327
2017-12-09T15:44:20.681509: step 329, loss 2.33923, acc 0.546875, prec 0.0317431, recall 0.723849
2017-12-09T15:44:21.268593: step 330, loss 1.6329, acc 0.546875, prec 0.0317475, recall 0.724426
2017-12-09T15:44:21.842083: step 331, loss 1.90974, acc 0.671875, prec 0.0316866, recall 0.724426
2017-12-09T15:44:22.423005: step 332, loss 11.7853, acc 0.671875, prec 0.0317171, recall 0.723493
2017-12-09T15:44:23.009393: step 333, loss 0.706784, acc 0.796875, prec 0.0316796, recall 0.723493
2017-12-09T15:44:23.582985: step 334, loss 1.05045, acc 0.6875, prec 0.031622, recall 0.723493
2017-12-09T15:44:24.195208: step 335, loss 0.822814, acc 0.765625, prec 0.0316668, recall 0.724066
2017-12-09T15:44:24.788517: step 336, loss 0.963393, acc 0.71875, prec 0.0317029, recall 0.724638
2017-12-09T15:44:25.365759: step 337, loss 4.61272, acc 0.859375, prec 0.0318552, recall 0.72428
2017-12-09T15:44:25.951703: step 338, loss 0.282847, acc 0.875, prec 0.0318322, recall 0.72428
2017-12-09T15:44:26.537102: step 339, loss 1.02127, acc 0.734375, prec 0.0317833, recall 0.72428
2017-12-09T15:44:27.124542: step 340, loss 11.5546, acc 0.703125, prec 0.0318247, recall 0.720408
2017-12-09T15:44:27.719897: step 341, loss 1.12494, acc 0.6875, prec 0.0317675, recall 0.720408
2017-12-09T15:44:28.307577: step 342, loss 2.23201, acc 0.75, prec 0.0319827, recall 0.72211
2017-12-09T15:44:28.898126: step 343, loss 0.982172, acc 0.734375, prec 0.0320208, recall 0.722672
2017-12-09T15:44:29.484719: step 344, loss 1.37111, acc 0.703125, prec 0.032053, recall 0.723232
2017-12-09T15:44:30.092643: step 345, loss 1.64317, acc 0.640625, prec 0.0319871, recall 0.723232
2017-12-09T15:44:30.693476: step 346, loss 1.7689, acc 0.59375, prec 0.031913, recall 0.723232
2017-12-09T15:44:31.280563: step 347, loss 17.6525, acc 0.578125, prec 0.0318392, recall 0.721774
2017-12-09T15:44:31.858111: step 348, loss 1.83784, acc 0.578125, prec 0.0317629, recall 0.721774
2017-12-09T15:44:32.436851: step 349, loss 1.97333, acc 0.546875, prec 0.0316814, recall 0.721774
2017-12-09T15:44:33.016737: step 350, loss 3.17904, acc 0.453125, prec 0.0317544, recall 0.722892
2017-12-09T15:44:33.599481: step 351, loss 2.47111, acc 0.484375, prec 0.0316623, recall 0.722892
2017-12-09T15:44:34.182875: step 352, loss 1.93991, acc 0.53125, prec 0.0315789, recall 0.722892
2017-12-09T15:44:34.765680: step 353, loss 2.27718, acc 0.484375, prec 0.0314878, recall 0.722892
2017-12-09T15:44:35.340101: step 354, loss 2.47073, acc 0.515625, prec 0.0314871, recall 0.723447
2017-12-09T15:44:35.933869: step 355, loss 2.39242, acc 0.546875, prec 0.031492, recall 0.724
2017-12-09T15:44:36.527457: step 356, loss 1.72406, acc 0.578125, prec 0.0315022, recall 0.724551
2017-12-09T15:44:37.116933: step 357, loss 1.35246, acc 0.703125, prec 0.0314504, recall 0.724551
2017-12-09T15:44:37.700728: step 358, loss 1.04582, acc 0.703125, prec 0.0314824, recall 0.7251
2017-12-09T15:44:38.287673: step 359, loss 1.36645, acc 0.8125, prec 0.0316171, recall 0.72619
2017-12-09T15:44:38.862234: step 360, loss 0.762251, acc 0.8125, prec 0.0315844, recall 0.72619
2017-12-09T15:44:39.436380: step 361, loss 0.976452, acc 0.703125, prec 0.0315327, recall 0.72619
2017-12-09T15:44:40.011571: step 362, loss 0.928161, acc 0.75, prec 0.0314893, recall 0.72619
2017-12-09T15:44:40.585825: step 363, loss 0.464435, acc 0.828125, prec 0.0314595, recall 0.72619
2017-12-09T15:44:41.170350: step 364, loss 0.732243, acc 0.796875, prec 0.0314244, recall 0.72619
2017-12-09T15:44:41.755625: step 365, loss 17.0594, acc 0.734375, prec 0.031467, recall 0.723866
2017-12-09T15:44:42.354746: step 366, loss 0.645806, acc 0.84375, prec 0.0314401, recall 0.723866
2017-12-09T15:44:42.936980: step 367, loss 1.30666, acc 0.71875, prec 0.0315573, recall 0.724951
2017-12-09T15:44:43.535880: step 368, loss 0.717307, acc 0.90625, prec 0.0316239, recall 0.72549
2017-12-09T15:44:44.117211: step 369, loss 0.368376, acc 0.875, prec 0.0316023, recall 0.72549
2017-12-09T15:44:44.706876: step 370, loss 0.569585, acc 0.828125, prec 0.0316553, recall 0.726027
2017-12-09T15:44:45.282691: step 371, loss 0.322866, acc 0.84375, prec 0.0316283, recall 0.726027
2017-12-09T15:44:45.854840: step 372, loss 0.595106, acc 0.828125, prec 0.0315987, recall 0.726027
2017-12-09T15:44:46.433554: step 373, loss 0.385316, acc 0.859375, prec 0.0315745, recall 0.726027
2017-12-09T15:44:47.010282: step 374, loss 0.788595, acc 0.78125, prec 0.0315369, recall 0.726027
2017-12-09T15:44:47.591618: step 375, loss 0.902621, acc 0.734375, prec 0.0314914, recall 0.726027
2017-12-09T15:44:48.170627: step 376, loss 0.518128, acc 0.84375, prec 0.0314647, recall 0.726027
2017-12-09T15:44:48.752578: step 377, loss 0.727745, acc 0.796875, prec 0.03143, recall 0.726027
2017-12-09T15:44:49.324943: step 378, loss 0.719888, acc 0.796875, prec 0.0313954, recall 0.726027
2017-12-09T15:44:49.908146: step 379, loss 1.41906, acc 0.828125, prec 0.03153, recall 0.727096
2017-12-09T15:44:50.490683: step 380, loss 0.508672, acc 0.859375, prec 0.031506, recall 0.727096
2017-12-09T15:44:51.071587: step 381, loss 0.154556, acc 0.953125, prec 0.0314981, recall 0.727096
2017-12-09T15:44:51.666085: step 382, loss 0.453334, acc 0.859375, prec 0.0314741, recall 0.727096
2017-12-09T15:44:52.256328: step 383, loss 0.487408, acc 0.84375, prec 0.0314476, recall 0.727096
2017-12-09T15:44:52.858016: step 384, loss 0.461458, acc 0.953125, prec 0.0315213, recall 0.727626
2017-12-09T15:44:53.449004: step 385, loss 0.589501, acc 0.875, prec 0.0315, recall 0.727626
2017-12-09T15:44:54.038282: step 386, loss 8.61658, acc 0.84375, prec 0.0315577, recall 0.726744
2017-12-09T15:44:54.631315: step 387, loss 0.559405, acc 0.90625, prec 0.0315418, recall 0.726744
2017-12-09T15:44:55.217132: step 388, loss 0.513972, acc 0.828125, prec 0.031594, recall 0.727273
2017-12-09T15:44:55.810298: step 389, loss 0.559223, acc 0.953125, prec 0.0317487, recall 0.728324
2017-12-09T15:44:56.406758: step 390, loss 0.260085, acc 0.875, prec 0.0317274, recall 0.728324
2017-12-09T15:44:57.003752: step 391, loss 0.298819, acc 0.96875, prec 0.0317221, recall 0.728324
2017-12-09T15:44:57.601172: step 392, loss 4.66161, acc 0.890625, prec 0.0317061, recall 0.726923
2017-12-09T15:44:58.201200: step 393, loss 0.415233, acc 0.90625, prec 0.0317713, recall 0.727447
2017-12-09T15:44:58.792575: step 394, loss 1.25904, acc 0.859375, prec 0.0318285, recall 0.727969
2017-12-09T15:44:59.385602: step 395, loss 0.567358, acc 0.828125, prec 0.0317992, recall 0.727969
2017-12-09T15:44:59.979823: step 396, loss 1.20572, acc 0.671875, prec 0.0318243, recall 0.728489
2017-12-09T15:45:00.570016: step 397, loss 1.24417, acc 0.765625, prec 0.0318652, recall 0.729008
2017-12-09T15:45:01.171524: step 398, loss 1.01048, acc 0.71875, prec 0.0318174, recall 0.729008
2017-12-09T15:45:01.759281: step 399, loss 0.692778, acc 0.796875, prec 0.031783, recall 0.729008
2017-12-09T15:45:02.350634: step 400, loss 1.02101, acc 0.75, prec 0.0318212, recall 0.729524
Saved model checkpoint to /Users/adb/Google Drive/Data Analytics/project/xtalkdb/Deep Learning/num_filter_128_fold_0/1512852011/checkpoints/model-400

2017-12-09T15:45:03.744812: step 401, loss 1.34058, acc 0.75, prec 0.0319396, recall 0.73055
2017-12-09T15:45:04.316224: step 402, loss 1.27294, acc 0.65625, prec 0.0318814, recall 0.73055
2017-12-09T15:45:04.903960: step 403, loss 1.05673, acc 0.765625, prec 0.0318419, recall 0.73055
2017-12-09T15:45:05.480091: step 404, loss 5.18286, acc 0.765625, prec 0.031885, recall 0.729679
2017-12-09T15:45:06.053081: step 405, loss 1.07647, acc 0.734375, prec 0.0318403, recall 0.729679
2017-12-09T15:45:06.632870: step 406, loss 0.85214, acc 0.8125, prec 0.0318886, recall 0.730189
2017-12-09T15:45:07.228331: step 407, loss 1.55603, acc 0.8125, prec 0.0320165, recall 0.731203
2017-12-09T15:45:07.811929: step 408, loss 7.09624, acc 0.625, prec 0.031956, recall 0.729831
2017-12-09T15:45:08.394932: step 409, loss 1.51136, acc 0.71875, prec 0.0320676, recall 0.730841
2017-12-09T15:45:08.985424: step 410, loss 2.71221, acc 0.609375, prec 0.0320812, recall 0.731343
2017-12-09T15:45:09.560791: step 411, loss 1.40173, acc 0.6875, prec 0.0321078, recall 0.731844
2017-12-09T15:45:10.144682: step 412, loss 1.87358, acc 0.546875, prec 0.0321108, recall 0.732342
2017-12-09T15:45:10.738080: step 413, loss 1.73833, acc 0.578125, prec 0.0321977, recall 0.733333
2017-12-09T15:45:11.334255: step 414, loss 1.67778, acc 0.640625, prec 0.0321376, recall 0.733333
2017-12-09T15:45:11.935827: step 415, loss 2.30238, acc 0.5625, prec 0.0320648, recall 0.733333
2017-12-09T15:45:12.548851: step 416, loss 1.88777, acc 0.5625, prec 0.0320704, recall 0.733826
2017-12-09T15:45:13.149799: step 417, loss 4.8568, acc 0.5625, prec 0.0320006, recall 0.732472
2017-12-09T15:45:13.759913: step 418, loss 1.71561, acc 0.609375, prec 0.0319363, recall 0.732472
2017-12-09T15:45:14.359567: step 419, loss 5.92539, acc 0.609375, prec 0.0319525, recall 0.731618
2017-12-09T15:45:15.007384: step 420, loss 1.02726, acc 0.703125, prec 0.0319038, recall 0.731618
2017-12-09T15:45:15.619510: step 421, loss 2.33967, acc 0.53125, prec 0.0319047, recall 0.73211
2017-12-09T15:45:16.230186: step 422, loss 1.547, acc 0.65625, prec 0.0320804, recall 0.733577
2017-12-09T15:45:16.838431: step 423, loss 1.92821, acc 0.5625, prec 0.032086, recall 0.734062
2017-12-09T15:45:17.450475: step 424, loss 1.88269, acc 0.53125, prec 0.0320864, recall 0.734545
2017-12-09T15:45:18.041446: step 425, loss 1.75585, acc 0.671875, prec 0.0321097, recall 0.735027
2017-12-09T15:45:18.635776: step 426, loss 1.43092, acc 0.65625, prec 0.0321304, recall 0.735507
2017-12-09T15:45:19.225938: step 427, loss 1.78427, acc 0.578125, prec 0.0320619, recall 0.735507
2017-12-09T15:45:19.819545: step 428, loss 3.96562, acc 0.609375, prec 0.0320013, recall 0.734177
2017-12-09T15:45:20.414222: step 429, loss 2.19594, acc 0.515625, prec 0.0319994, recall 0.734657
2017-12-09T15:45:21.006060: step 430, loss 1.40352, acc 0.6875, prec 0.0319491, recall 0.734657
2017-12-09T15:45:21.603026: step 431, loss 0.744979, acc 0.765625, prec 0.0319875, recall 0.735135
2017-12-09T15:45:22.193149: step 432, loss 2.6968, acc 0.734375, prec 0.0319474, recall 0.733813
2017-12-09T15:45:22.787361: step 433, loss 1.19111, acc 0.6875, prec 0.0318974, recall 0.733813
2017-12-09T15:45:23.379142: step 434, loss 0.645298, acc 0.78125, prec 0.0318626, recall 0.733813
2017-12-09T15:45:23.972704: step 435, loss 13.7263, acc 0.703125, prec 0.0318958, recall 0.731664
2017-12-09T15:45:24.565124: step 436, loss 1.13512, acc 0.75, prec 0.0318561, recall 0.731664
2017-12-09T15:45:25.198964: step 437, loss 0.782421, acc 0.75, prec 0.0318917, recall 0.732143
2017-12-09T15:45:25.817957: step 438, loss 0.980026, acc 0.765625, prec 0.0318546, recall 0.732143
2017-12-09T15:45:26.415490: step 439, loss 1.87818, acc 0.625, prec 0.0319454, recall 0.733096
2017-12-09T15:45:27.005068: step 440, loss 1.52355, acc 0.625, prec 0.0318861, recall 0.733096
2017-12-09T15:45:27.591765: step 441, loss 1.8362, acc 0.703125, prec 0.0319141, recall 0.73357
2017-12-09T15:45:28.181188: step 442, loss 1.62781, acc 0.578125, prec 0.0318476, recall 0.73357
2017-12-09T15:45:28.771521: step 443, loss 1.40205, acc 0.625, prec 0.0317888, recall 0.73357
2017-12-09T15:45:29.359824: step 444, loss 10.0091, acc 0.703125, prec 0.0317448, recall 0.73227
2017-12-09T15:45:29.947630: step 445, loss 1.55893, acc 0.71875, prec 0.0317753, recall 0.732743
2017-12-09T15:45:30.532327: step 446, loss 1.80758, acc 0.625, prec 0.0317168, recall 0.732743
2017-12-09T15:45:31.127836: step 447, loss 1.47436, acc 0.671875, prec 0.03174, recall 0.733216
2017-12-09T15:45:31.715414: step 448, loss 1.44149, acc 0.640625, prec 0.0316842, recall 0.733216
2017-12-09T15:45:32.306388: step 449, loss 3.03462, acc 0.640625, prec 0.0318525, recall 0.733333
2017-12-09T15:45:32.894447: step 450, loss 1.30042, acc 0.6875, prec 0.031804, recall 0.733333
2017-12-09T15:45:33.482063: step 451, loss 17.1698, acc 0.59375, prec 0.0318171, recall 0.732517
2017-12-09T15:45:34.075215: step 452, loss 6.35122, acc 0.5, prec 0.0317448, recall 0.729965
2017-12-09T15:45:34.676194: step 453, loss 2.53765, acc 0.53125, prec 0.0316728, recall 0.729965
2017-12-09T15:45:35.263163: step 454, loss 2.51223, acc 0.5625, prec 0.031752, recall 0.730903
2017-12-09T15:45:35.853373: step 455, loss 2.68676, acc 0.515625, prec 0.031678, recall 0.730903
2017-12-09T15:45:36.438283: step 456, loss 2.71351, acc 0.421875, prec 0.0316627, recall 0.731369
2017-12-09T15:45:37.028946: step 457, loss 2.80725, acc 0.484375, prec 0.0317294, recall 0.732297
2017-12-09T15:45:37.615929: step 458, loss 2.30211, acc 0.375, prec 0.0316347, recall 0.732297
2017-12-09T15:45:38.207806: step 459, loss 2.779, acc 0.46875, prec 0.0316267, recall 0.732759
2017-12-09T15:45:38.797746: step 460, loss 2.8344, acc 0.421875, prec 0.0315399, recall 0.732759
2017-12-09T15:45:39.411075: step 461, loss 2.79369, acc 0.359375, prec 0.0315159, recall 0.733219
2017-12-09T15:45:40.020187: step 462, loss 1.86179, acc 0.625, prec 0.0315315, recall 0.733677
2017-12-09T15:45:40.629799: step 463, loss 3.83609, acc 0.65625, prec 0.0314827, recall 0.732419
2017-12-09T15:45:41.241108: step 464, loss 1.7636, acc 0.59375, prec 0.0314225, recall 0.732419
2017-12-09T15:45:41.828659: step 465, loss 1.23131, acc 0.59375, prec 0.0313625, recall 0.732419
2017-12-09T15:45:42.438389: step 466, loss 1.68676, acc 0.671875, prec 0.0313852, recall 0.732877
2017-12-09T15:45:43.035770: step 467, loss 3.90522, acc 0.625, prec 0.0314033, recall 0.732082
2017-12-09T15:45:43.625077: step 468, loss 2.59515, acc 0.609375, prec 0.031419, recall 0.731293
2017-12-09T15:45:44.214790: step 469, loss 2.82377, acc 0.5625, prec 0.0313571, recall 0.730051
2017-12-09T15:45:44.864038: step 470, loss 3.52665, acc 0.59375, prec 0.0313, recall 0.728814
2017-12-09T15:45:45.455925: step 471, loss 1.42719, acc 0.71875, prec 0.0312591, recall 0.728814
2017-12-09T15:45:46.045902: step 472, loss 1.53746, acc 0.6875, prec 0.031284, recall 0.729272
2017-12-09T15:45:46.646427: step 473, loss 2.08296, acc 0.578125, prec 0.0312228, recall 0.729272
2017-12-09T15:45:47.237999: step 474, loss 2.55132, acc 0.640625, prec 0.031241, recall 0.72973
2017-12-09T15:45:47.829964: step 475, loss 11.7988, acc 0.640625, prec 0.0312613, recall 0.728956
2017-12-09T15:45:48.421289: step 476, loss 1.7748, acc 0.640625, prec 0.0312793, recall 0.729412
2017-12-09T15:45:49.009449: step 477, loss 1.56267, acc 0.640625, prec 0.0312275, recall 0.729412
2017-12-09T15:45:49.597808: step 478, loss 5.13271, acc 0.53125, prec 0.0311625, recall 0.728188
2017-12-09T15:45:50.184166: step 479, loss 1.62404, acc 0.625, prec 0.0311783, recall 0.728643
2017-12-09T15:45:50.772911: step 480, loss 2.53879, acc 0.515625, prec 0.0311092, recall 0.728643
2017-12-09T15:45:51.360671: step 481, loss 2.56496, acc 0.546875, prec 0.031114, recall 0.729097
2017-12-09T15:45:51.955888: step 482, loss 2.46019, acc 0.4375, prec 0.0311032, recall 0.729549
2017-12-09T15:45:52.547123: step 483, loss 2.82864, acc 0.515625, prec 0.0312411, recall 0.730897
2017-12-09T15:45:53.139193: step 484, loss 7.53296, acc 0.59375, prec 0.0312544, recall 0.730132
2017-12-09T15:45:53.728392: step 485, loss 2.0358, acc 0.609375, prec 0.0313362, recall 0.731023
2017-12-09T15:45:54.317315: step 486, loss 3.21326, acc 0.421875, prec 0.0312544, recall 0.731023
2017-12-09T15:45:54.902645: step 487, loss 1.98227, acc 0.53125, prec 0.0311884, recall 0.731023
2017-12-09T15:45:55.489498: step 488, loss 3.49521, acc 0.625, prec 0.0312061, recall 0.730263
2017-12-09T15:45:56.078188: step 489, loss 1.83674, acc 0.625, prec 0.0311535, recall 0.730263
2017-12-09T15:45:56.673052: step 490, loss 1.38274, acc 0.640625, prec 0.0311712, recall 0.730706
2017-12-09T15:45:57.266218: step 491, loss 1.97043, acc 0.703125, prec 0.0312653, recall 0.731588
2017-12-09T15:45:57.855833: step 492, loss 1.36925, acc 0.71875, prec 0.0312937, recall 0.732026
2017-12-09T15:45:58.447721: step 493, loss 7.53138, acc 0.59375, prec 0.0313067, recall 0.73127
2017-12-09T15:45:59.045115: step 494, loss 13.9513, acc 0.53125, prec 0.0312457, recall 0.728896
2017-12-09T15:45:59.635535: step 495, loss 1.71835, acc 0.609375, prec 0.0312587, recall 0.729335
2017-12-09T15:46:00.226531: step 496, loss 2.73457, acc 0.46875, prec 0.0312522, recall 0.729773
2017-12-09T15:46:00.724000: step 497, loss 3.34054, acc 0.490196, prec 0.031196, recall 0.729773
2017-12-09T15:46:01.331630: step 498, loss 2.99954, acc 0.46875, prec 0.0311228, recall 0.729773
2017-12-09T15:46:01.916577: step 499, loss 2.84933, acc 0.4375, prec 0.0311123, recall 0.73021
2017-12-09T15:46:02.505148: step 500, loss 1.96476, acc 0.609375, prec 0.0311255, recall 0.730645
Saved model checkpoint to /Users/adb/Google Drive/Data Analytics/project/xtalkdb/Deep Learning/num_filter_128_fold_0/1512852011/checkpoints/model-500

2017-12-09T15:46:03.874099: step 501, loss 3.23726, acc 0.421875, prec 0.0311793, recall 0.731511
2017-12-09T15:46:04.458341: step 502, loss 3.10356, acc 0.484375, prec 0.0311752, recall 0.731942
2017-12-09T15:46:05.039188: step 503, loss 1.63968, acc 0.625, prec 0.0311903, recall 0.732372
2017-12-09T15:46:05.615464: step 504, loss 2.1221, acc 0.484375, prec 0.0311202, recall 0.732372
2017-12-09T15:46:06.198248: step 505, loss 1.94322, acc 0.484375, prec 0.0310504, recall 0.732372
2017-12-09T15:46:06.768432: step 506, loss 1.77852, acc 0.609375, prec 0.0310635, recall 0.7328
2017-12-09T15:46:07.354314: step 507, loss 1.25859, acc 0.75, prec 0.0310955, recall 0.733227
2017-12-09T15:46:07.942662: step 508, loss 1.74834, acc 0.625, prec 0.031045, recall 0.733227
2017-12-09T15:46:08.520095: step 509, loss 0.904044, acc 0.75, prec 0.0310769, recall 0.733652
2017-12-09T15:46:09.102757: step 510, loss 1.18266, acc 0.6875, prec 0.0311003, recall 0.734076
2017-12-09T15:46:09.693418: step 511, loss 1.13769, acc 0.671875, prec 0.0310563, recall 0.734076
2017-12-09T15:46:10.282558: step 512, loss 1.33908, acc 0.71875, prec 0.0310839, recall 0.734499
2017-12-09T15:46:10.866537: step 513, loss 0.619496, acc 0.8125, prec 0.0310588, recall 0.734499
2017-12-09T15:46:11.452240: step 514, loss 3.57156, acc 0.890625, prec 0.0311114, recall 0.733756
2017-12-09T15:46:12.047993: step 515, loss 0.168091, acc 0.921875, prec 0.031101, recall 0.733756
2017-12-09T15:46:12.637913: step 516, loss 0.457396, acc 0.8125, prec 0.0310759, recall 0.733756
2017-12-09T15:46:13.234744: step 517, loss 0.59677, acc 0.8125, prec 0.0310509, recall 0.733756
2017-12-09T15:46:13.822960: step 518, loss 4.73736, acc 0.921875, prec 0.0310426, recall 0.732595
2017-12-09T15:46:14.444294: step 519, loss 5.39143, acc 0.84375, prec 0.0310239, recall 0.731438
2017-12-09T15:46:15.042363: step 520, loss 0.430746, acc 0.90625, prec 0.0310763, recall 0.731861
2017-12-09T15:46:15.629365: step 521, loss 0.517232, acc 0.921875, prec 0.0311956, recall 0.732704
2017-12-09T15:46:16.249108: step 522, loss 0.783342, acc 0.8125, prec 0.0311706, recall 0.732704
2017-12-09T15:46:16.846744: step 523, loss 0.387181, acc 0.90625, prec 0.0311581, recall 0.732704
2017-12-09T15:46:17.456354: step 524, loss 0.67733, acc 0.75, prec 0.0311248, recall 0.732704
2017-12-09T15:46:18.049834: step 525, loss 5.49775, acc 0.828125, prec 0.0311687, recall 0.731975
2017-12-09T15:46:18.646861: step 526, loss 6.05386, acc 0.859375, prec 0.031152, recall 0.730829
2017-12-09T15:46:19.241067: step 527, loss 2.97811, acc 0.75, prec 0.03125, recall 0.73053
2017-12-09T15:46:19.836320: step 528, loss 6.33628, acc 0.75, prec 0.0313478, recall 0.730233
2017-12-09T15:46:20.449094: step 529, loss 1.29036, acc 0.703125, prec 0.0313726, recall 0.73065
2017-12-09T15:46:21.059357: step 530, loss 1.42219, acc 0.625, prec 0.0313869, recall 0.731066
2017-12-09T15:46:21.670690: step 531, loss 2.10795, acc 0.625, prec 0.031337, recall 0.731066
2017-12-09T15:46:22.275723: step 532, loss 1.9624, acc 0.609375, prec 0.0313492, recall 0.731481
2017-12-09T15:46:22.882486: step 533, loss 2.57092, acc 0.5, prec 0.031283, recall 0.731481
2017-12-09T15:46:23.476046: step 534, loss 2.31766, acc 0.5, prec 0.0312809, recall 0.731895
2017-12-09T15:46:24.069855: step 535, loss 2.23676, acc 0.453125, prec 0.0313362, recall 0.732719
2017-12-09T15:46:24.661022: step 536, loss 2.904, acc 0.46875, prec 0.0313299, recall 0.733129
2017-12-09T15:46:25.243896: step 537, loss 1.9432, acc 0.5625, prec 0.0312725, recall 0.733129
2017-12-09T15:46:25.832753: step 538, loss 2.67165, acc 0.578125, prec 0.0312806, recall 0.733537
2017-12-09T15:46:26.423237: step 539, loss 2.79943, acc 0.515625, prec 0.0312174, recall 0.733537
2017-12-09T15:46:27.015500: step 540, loss 2.68886, acc 0.65625, prec 0.0312988, recall 0.734351
2017-12-09T15:46:27.600430: step 541, loss 2.36318, acc 0.578125, prec 0.0313068, recall 0.734756
2017-12-09T15:46:28.193541: step 542, loss 1.71015, acc 0.65625, prec 0.031325, recall 0.73516
2017-12-09T15:46:28.786853: step 543, loss 3.72096, acc 0.71875, prec 0.0313532, recall 0.734446
2017-12-09T15:46:29.373945: step 544, loss 1.52324, acc 0.640625, prec 0.0314319, recall 0.73525
2017-12-09T15:46:29.962726: step 545, loss 0.707683, acc 0.734375, prec 0.0313974, recall 0.73525
2017-12-09T15:46:30.550629: step 546, loss 1.01585, acc 0.75, prec 0.031365, recall 0.73525
2017-12-09T15:46:31.141538: step 547, loss 1.09991, acc 0.6875, prec 0.0313245, recall 0.73525
2017-12-09T15:46:31.732960: step 548, loss 1.06739, acc 0.71875, prec 0.0312882, recall 0.73525
2017-12-09T15:46:32.322132: step 549, loss 0.552307, acc 0.796875, prec 0.0312621, recall 0.73525
2017-12-09T15:46:32.913726: step 550, loss 0.808923, acc 0.828125, prec 0.03124, recall 0.73525
2017-12-09T15:46:33.498604: step 551, loss 0.524254, acc 0.84375, prec 0.0312199, recall 0.73525
2017-12-09T15:46:34.083007: step 552, loss 0.586422, acc 0.796875, prec 0.0311938, recall 0.73525
2017-12-09T15:46:34.689423: step 553, loss 0.995821, acc 0.75, prec 0.031224, recall 0.73565
2017-12-09T15:46:35.306817: step 554, loss 0.705933, acc 0.796875, prec 0.031198, recall 0.73565
2017-12-09T15:46:35.890825: step 555, loss 10.3718, acc 0.828125, prec 0.031178, recall 0.73454
2017-12-09T15:46:36.480587: step 556, loss 0.227375, acc 0.90625, prec 0.031228, recall 0.73494
2017-12-09T15:46:37.079142: step 557, loss 4.56977, acc 0.796875, prec 0.031266, recall 0.734234
2017-12-09T15:46:37.679180: step 558, loss 0.70491, acc 0.796875, prec 0.0313019, recall 0.734633
2017-12-09T15:46:38.267585: step 559, loss 0.754272, acc 0.8125, prec 0.0312779, recall 0.734633
2017-12-09T15:46:38.864136: step 560, loss 0.687359, acc 0.796875, prec 0.031252, recall 0.734633
2017-12-09T15:46:39.452797: step 561, loss 0.514341, acc 0.875, prec 0.0313595, recall 0.735426
2017-12-09T15:46:40.049990: step 562, loss 0.673525, acc 0.796875, prec 0.0313336, recall 0.735426
2017-12-09T15:46:40.645010: step 563, loss 6.94848, acc 0.78125, prec 0.0313097, recall 0.733234
2017-12-09T15:46:41.240825: step 564, loss 0.832313, acc 0.84375, prec 0.0313514, recall 0.733631
2017-12-09T15:46:41.830136: step 565, loss 0.838034, acc 0.765625, prec 0.0313215, recall 0.733631
2017-12-09T15:46:42.453448: step 566, loss 0.72397, acc 0.734375, prec 0.0313492, recall 0.734027
2017-12-09T15:46:43.065722: step 567, loss 0.69649, acc 0.78125, prec 0.0313827, recall 0.734421
2017-12-09T15:46:43.666358: step 568, loss 3.52154, acc 0.71875, prec 0.0314103, recall 0.733728
2017-12-09T15:46:44.277394: step 569, loss 1.14596, acc 0.671875, prec 0.0313686, recall 0.733728
2017-12-09T15:46:44.923703: step 570, loss 1.53684, acc 0.65625, prec 0.031325, recall 0.733728
2017-12-09T15:46:45.534894: step 571, loss 0.964456, acc 0.734375, prec 0.0312914, recall 0.733728
2017-12-09T15:46:46.120631: step 572, loss 1.56739, acc 0.671875, prec 0.031311, recall 0.734121
2017-12-09T15:46:46.705221: step 573, loss 0.832583, acc 0.78125, prec 0.0314054, recall 0.734904
2017-12-09T15:46:47.290560: step 574, loss 1.73869, acc 0.671875, prec 0.0314248, recall 0.735294
2017-12-09T15:46:47.889396: step 575, loss 2.48454, acc 0.59375, prec 0.0314343, recall 0.735683
2017-12-09T15:46:48.482563: step 576, loss 1.10675, acc 0.734375, prec 0.0315829, recall 0.736842
2017-12-09T15:46:49.072852: step 577, loss 0.94673, acc 0.734375, prec 0.0316099, recall 0.737226
2017-12-09T15:46:49.659779: step 578, loss 1.99746, acc 0.625, prec 0.0315625, recall 0.737226
2017-12-09T15:46:50.253921: step 579, loss 0.845814, acc 0.75, prec 0.0315914, recall 0.737609
2017-12-09T15:46:50.838998: step 580, loss 0.683623, acc 0.796875, prec 0.0315658, recall 0.737609
2017-12-09T15:46:51.446301: step 581, loss 1.14488, acc 0.609375, prec 0.0315167, recall 0.737609
2017-12-09T15:46:52.048149: step 582, loss 1.19659, acc 0.6875, prec 0.0315377, recall 0.737991
2017-12-09T15:46:52.644349: step 583, loss 0.659618, acc 0.765625, prec 0.0315083, recall 0.737991
2017-12-09T15:46:53.244401: step 584, loss 6.22389, acc 0.890625, prec 0.0314966, recall 0.736919
2017-12-09T15:46:53.841468: step 585, loss 0.717538, acc 0.71875, prec 0.0315215, recall 0.7373
2017-12-09T15:46:54.434713: step 586, loss 0.727961, acc 0.765625, prec 0.0314922, recall 0.7373
2017-12-09T15:46:55.025153: step 587, loss 0.493123, acc 0.875, prec 0.0315366, recall 0.737681
2017-12-09T15:46:55.615177: step 588, loss 5.18109, acc 0.828125, prec 0.031517, recall 0.736614
2017-12-09T15:46:56.215031: step 589, loss 1.33581, acc 0.796875, prec 0.0316115, recall 0.737374
2017-12-09T15:46:56.805768: step 590, loss 0.784438, acc 0.859375, prec 0.0316538, recall 0.737752
2017-12-09T15:46:57.399458: step 591, loss 0.744861, acc 0.796875, prec 0.031748, recall 0.738506
2017-12-09T15:46:57.992999: step 592, loss 2.34258, acc 0.828125, prec 0.0317284, recall 0.737446
2017-12-09T15:46:58.584660: step 593, loss 0.913302, acc 0.828125, prec 0.0317666, recall 0.737822
2017-12-09T15:46:59.180204: step 594, loss 1.1375, acc 0.71875, prec 0.031791, recall 0.738197
2017-12-09T15:46:59.773700: step 595, loss 0.65187, acc 0.765625, prec 0.0317617, recall 0.738197
2017-12-09T15:47:00.374143: step 596, loss 10.7239, acc 0.765625, prec 0.0317939, recall 0.737518
2017-12-09T15:47:00.992954: step 597, loss 1.16779, acc 0.75, prec 0.0318221, recall 0.737892
2017-12-09T15:47:01.609202: step 598, loss 0.95883, acc 0.75, prec 0.0317908, recall 0.737892
2017-12-09T15:47:02.223006: step 599, loss 0.834619, acc 0.75, prec 0.031819, recall 0.738265
2017-12-09T15:47:02.831037: step 600, loss 1.18097, acc 0.75, prec 0.0319064, recall 0.739007

Evaluation:
2017-12-09T15:47:59.333355: step 600, loss 1.46165, acc 0.735918, prec 0.0343484, recall 0.760644

Saved model checkpoint to /Users/adb/Google Drive/Data Analytics/project/xtalkdb/Deep Learning/num_filter_128_fold_0/1512852011/checkpoints/model-600

2017-12-09T15:48:01.495072: step 601, loss 0.972757, acc 0.703125, prec 0.0343145, recall 0.760644
2017-12-09T15:48:02.083959: step 602, loss 1.23221, acc 0.734375, prec 0.0343844, recall 0.761194
2017-12-09T15:48:02.692704: step 603, loss 1.20278, acc 0.734375, prec 0.0344041, recall 0.761468
2017-12-09T15:48:03.392470: step 604, loss 1.12743, acc 0.71875, prec 0.0344221, recall 0.761741
2017-12-09T15:48:04.139971: step 605, loss 1.16626, acc 0.671875, prec 0.0343847, recall 0.761741
2017-12-09T15:48:04.922826: step 606, loss 1.19552, acc 0.6875, prec 0.0343991, recall 0.762014
2017-12-09T15:48:05.561780: step 607, loss 0.988103, acc 0.703125, prec 0.0344151, recall 0.762286
2017-12-09T15:48:06.155571: step 608, loss 0.838631, acc 0.734375, prec 0.034385, recall 0.762286
2017-12-09T15:48:06.762607: step 609, loss 1.03069, acc 0.75, prec 0.0344064, recall 0.762557
2017-12-09T15:48:07.355106: step 610, loss 0.889491, acc 0.734375, prec 0.0343763, recall 0.762557
2017-12-09T15:48:07.931311: step 611, loss 4.09647, acc 0.8125, prec 0.0343568, recall 0.761688
2017-12-09T15:48:08.506136: step 612, loss 0.425573, acc 0.84375, prec 0.0343392, recall 0.761688
2017-12-09T15:48:09.088401: step 613, loss 0.672511, acc 0.78125, prec 0.0343145, recall 0.761688
2017-12-09T15:48:09.660540: step 614, loss 0.89829, acc 0.8125, prec 0.0343429, recall 0.761959
2017-12-09T15:48:10.245061: step 615, loss 0.628269, acc 0.890625, prec 0.0343306, recall 0.761959
2017-12-09T15:48:10.834725: step 616, loss 9.02482, acc 0.78125, prec 0.0343077, recall 0.761092
2017-12-09T15:48:11.412445: step 617, loss 0.648276, acc 0.796875, prec 0.0343343, recall 0.761364
2017-12-09T15:48:12.000034: step 618, loss 0.340086, acc 0.859375, prec 0.0343185, recall 0.761364
2017-12-09T15:48:12.588934: step 619, loss 0.893508, acc 0.6875, prec 0.0342834, recall 0.761364
2017-12-09T15:48:13.175037: step 620, loss 0.16745, acc 0.90625, prec 0.0342729, recall 0.761364
2017-12-09T15:48:13.746888: step 621, loss 5.9444, acc 0.8125, prec 0.0343029, recall 0.760771
2017-12-09T15:48:14.325545: step 622, loss 0.619334, acc 0.78125, prec 0.0342784, recall 0.760771
2017-12-09T15:48:14.907557: step 623, loss 0.405957, acc 0.828125, prec 0.0342592, recall 0.760771
2017-12-09T15:48:15.495762: step 624, loss 0.887114, acc 0.734375, prec 0.0342787, recall 0.761042
2017-12-09T15:48:16.076660: step 625, loss 4.47767, acc 0.78125, prec 0.034256, recall 0.760181
2017-12-09T15:48:16.657302: step 626, loss 0.717643, acc 0.78125, prec 0.0342808, recall 0.760452
2017-12-09T15:48:17.239213: step 627, loss 0.740195, acc 0.8125, prec 0.0343581, recall 0.760992
2017-12-09T15:48:17.824345: step 628, loss 0.813362, acc 0.71875, prec 0.0343758, recall 0.761261
2017-12-09T15:48:18.444490: step 629, loss 3.80053, acc 0.65625, prec 0.0343391, recall 0.760405
2017-12-09T15:48:19.030886: step 630, loss 1.29265, acc 0.6875, prec 0.0343043, recall 0.760405
2017-12-09T15:48:19.614301: step 631, loss 1.15268, acc 0.734375, prec 0.0343237, recall 0.760674
2017-12-09T15:48:20.201053: step 632, loss 1.25972, acc 0.59375, prec 0.0343763, recall 0.761211
2017-12-09T15:48:20.794725: step 633, loss 1.11641, acc 0.71875, prec 0.0344426, recall 0.761745
2017-12-09T15:48:21.380227: step 634, loss 0.758592, acc 0.71875, prec 0.0344113, recall 0.761745
2017-12-09T15:48:21.973011: step 635, loss 1.18481, acc 0.6875, prec 0.0343766, recall 0.761745
2017-12-09T15:48:22.572250: step 636, loss 1.12259, acc 0.6875, prec 0.0343906, recall 0.762011
2017-12-09T15:48:23.160043: step 637, loss 1.17172, acc 0.625, prec 0.0344949, recall 0.762806
2017-12-09T15:48:23.748935: step 638, loss 1.14377, acc 0.65625, prec 0.0345053, recall 0.76307
2017-12-09T15:48:24.329948: step 639, loss 0.631379, acc 0.78125, prec 0.034481, recall 0.76307
2017-12-09T15:48:24.920020: step 640, loss 0.978394, acc 0.765625, prec 0.0345035, recall 0.763333
2017-12-09T15:48:25.511108: step 641, loss 0.75457, acc 0.8125, prec 0.0344828, recall 0.763333
2017-12-09T15:48:26.111088: step 642, loss 0.809793, acc 0.78125, prec 0.0344585, recall 0.763333
2017-12-09T15:48:26.706899: step 643, loss 0.480422, acc 0.828125, prec 0.0344395, recall 0.763333
2017-12-09T15:48:27.308882: step 644, loss 5.0371, acc 0.859375, prec 0.0344741, recall 0.762749
2017-12-09T15:48:27.927241: step 645, loss 0.296987, acc 0.890625, prec 0.0345104, recall 0.763012
2017-12-09T15:48:28.535993: step 646, loss 0.507976, acc 0.875, prec 0.0344966, recall 0.763012
2017-12-09T15:48:29.152391: step 647, loss 0.398076, acc 0.875, prec 0.0344828, recall 0.763012
2017-12-09T15:48:29.764812: step 648, loss 0.586857, acc 0.84375, prec 0.0344655, recall 0.763012
2017-12-09T15:48:30.379869: step 649, loss 0.296495, acc 0.90625, prec 0.0344552, recall 0.763012
2017-12-09T15:48:30.993810: step 650, loss 0.202158, acc 0.921875, prec 0.0344948, recall 0.763274
2017-12-09T15:48:31.602380: step 651, loss 8.31565, acc 0.828125, prec 0.0344776, recall 0.762431
2017-12-09T15:48:32.218546: step 652, loss 0.235099, acc 0.890625, prec 0.0344655, recall 0.762431
2017-12-09T15:48:32.829748: step 653, loss 0.477478, acc 0.890625, prec 0.0345017, recall 0.762693
2017-12-09T15:48:33.440022: step 654, loss 11.1384, acc 0.90625, prec 0.0344931, recall 0.761852
2017-12-09T15:48:34.059213: step 655, loss 5.40879, acc 0.828125, prec 0.034524, recall 0.761276
2017-12-09T15:48:34.664135: step 656, loss 0.750776, acc 0.8125, prec 0.0345515, recall 0.761538
2017-12-09T15:48:35.276774: step 657, loss 0.608555, acc 0.75, prec 0.0345721, recall 0.7618
2017-12-09T15:48:35.893541: step 658, loss 8.47704, acc 0.78125, prec 0.0345978, recall 0.761227
2017-12-09T15:48:36.489853: step 659, loss 1.02689, acc 0.734375, prec 0.0345685, recall 0.761227
2017-12-09T15:48:37.080603: step 660, loss 1.33824, acc 0.578125, prec 0.0346181, recall 0.761749
2017-12-09T15:48:37.669704: step 661, loss 1.015, acc 0.75, prec 0.0345906, recall 0.761749
2017-12-09T15:48:38.255317: step 662, loss 1.0965, acc 0.671875, prec 0.0345546, recall 0.761749
2017-12-09T15:48:38.843112: step 663, loss 1.74137, acc 0.59375, prec 0.0345579, recall 0.762009
2017-12-09T15:48:39.446886: step 664, loss 2.11642, acc 0.5625, prec 0.03451, recall 0.762009
2017-12-09T15:48:40.048548: step 665, loss 1.6239, acc 0.546875, prec 0.0344606, recall 0.762009
2017-12-09T15:48:40.666063: step 666, loss 1.5902, acc 0.5625, prec 0.0344607, recall 0.762268
2017-12-09T15:48:41.275705: step 667, loss 1.90198, acc 0.609375, prec 0.0345133, recall 0.762786
2017-12-09T15:48:41.888493: step 668, loss 0.961512, acc 0.71875, prec 0.0345777, recall 0.763301
2017-12-09T15:48:42.519776: step 669, loss 1.45106, acc 0.6875, prec 0.0345912, recall 0.763557
2017-12-09T15:48:43.131445: step 670, loss 1.20202, acc 0.65625, prec 0.0345538, recall 0.763557
2017-12-09T15:48:43.746887: step 671, loss 1.14461, acc 0.734375, prec 0.0345724, recall 0.763814
2017-12-09T15:48:44.358881: step 672, loss 1.14749, acc 0.703125, prec 0.0345402, recall 0.763814
2017-12-09T15:48:44.972844: step 673, loss 5.48914, acc 0.78125, prec 0.0345182, recall 0.762987
2017-12-09T15:48:45.584434: step 674, loss 0.684552, acc 0.8125, prec 0.0344979, recall 0.762987
2017-12-09T15:48:46.194606: step 675, loss 2.33905, acc 0.828125, prec 0.0345755, recall 0.762675
2017-12-09T15:48:46.808927: step 676, loss 8.09588, acc 0.796875, prec 0.0346024, recall 0.76211
2017-12-09T15:48:47.432461: step 677, loss 0.785802, acc 0.828125, prec 0.0346781, recall 0.762621
2017-12-09T15:48:48.039874: step 678, loss 0.794297, acc 0.78125, prec 0.0346544, recall 0.762621
2017-12-09T15:48:48.654152: step 679, loss 1.26831, acc 0.8125, prec 0.0346812, recall 0.762876
2017-12-09T15:48:49.246701: step 680, loss 0.72208, acc 0.734375, prec 0.0346995, recall 0.76313
2017-12-09T15:48:49.842604: step 681, loss 1.13088, acc 0.65625, prec 0.0346624, recall 0.76313
2017-12-09T15:48:50.424502: step 682, loss 0.964046, acc 0.734375, prec 0.0346807, recall 0.763383
2017-12-09T15:48:51.017370: step 683, loss 1.89794, acc 0.765625, prec 0.0347509, recall 0.763074
2017-12-09T15:48:51.646814: step 684, loss 0.802955, acc 0.71875, prec 0.0347205, recall 0.763074
2017-12-09T15:48:52.274574: step 685, loss 1.12217, acc 0.71875, prec 0.034737, recall 0.763326
2017-12-09T15:48:52.884840: step 686, loss 1.04006, acc 0.703125, prec 0.0347986, recall 0.76383
2017-12-09T15:48:53.499041: step 687, loss 0.76137, acc 0.828125, prec 0.0347801, recall 0.76383
2017-12-09T15:48:54.116160: step 688, loss 2.76903, acc 0.671875, prec 0.0347464, recall 0.763018
2017-12-09T15:48:54.736613: step 689, loss 0.847989, acc 0.734375, prec 0.0347179, recall 0.763018
2017-12-09T15:48:55.353175: step 690, loss 2.19365, acc 0.71875, prec 0.0347809, recall 0.763521
2017-12-09T15:48:55.960645: step 691, loss 0.830673, acc 0.796875, prec 0.0347591, recall 0.763521
2017-12-09T15:48:56.576741: step 692, loss 1.18746, acc 0.671875, prec 0.0347239, recall 0.763521
2017-12-09T15:48:57.187250: step 693, loss 0.84145, acc 0.703125, prec 0.0347386, recall 0.763771
2017-12-09T15:48:57.819016: step 694, loss 0.805143, acc 0.734375, prec 0.0347102, recall 0.763771
2017-12-09T15:48:58.470615: step 695, loss 1.06702, acc 0.75, prec 0.0347299, recall 0.764021
2017-12-09T15:48:59.080500: step 696, loss 6.58612, acc 0.8125, prec 0.0347579, recall 0.763464
2017-12-09T15:48:59.686250: step 697, loss 1.18682, acc 0.703125, prec 0.0348189, recall 0.763962
2017-12-09T15:49:00.292490: step 698, loss 0.694599, acc 0.796875, prec 0.0348435, recall 0.764211
2017-12-09T15:49:00.899653: step 699, loss 0.852156, acc 0.796875, prec 0.0348218, recall 0.764211
2017-12-09T15:49:01.514048: step 700, loss 0.754188, acc 0.75, prec 0.0348414, recall 0.764458
Saved model checkpoint to /Users/adb/Google Drive/Data Analytics/project/xtalkdb/Deep Learning/num_filter_128_fold_0/1512852011/checkpoints/model-700

2017-12-09T15:49:02.883886: step 701, loss 0.847712, acc 0.71875, prec 0.0348113, recall 0.764458
2017-12-09T15:49:03.463424: step 702, loss 0.885961, acc 0.75, prec 0.0348309, recall 0.764706
2017-12-09T15:49:04.058376: step 703, loss 0.429161, acc 0.84375, prec 0.0348604, recall 0.764953
2017-12-09T15:49:04.651625: step 704, loss 0.418603, acc 0.796875, prec 0.0348848, recall 0.765199
2017-12-09T15:49:05.242928: step 705, loss 0.591994, acc 0.828125, prec 0.0348665, recall 0.765199
2017-12-09T15:49:05.833225: step 706, loss 0.738753, acc 0.859375, prec 0.0348976, recall 0.765445
2017-12-09T15:49:06.418079: step 707, loss 0.531696, acc 0.859375, prec 0.0348826, recall 0.765445
2017-12-09T15:49:07.045141: step 708, loss 0.655438, acc 0.890625, prec 0.034963, recall 0.765935
2017-12-09T15:49:07.656665: step 709, loss 0.330477, acc 0.921875, prec 0.0350007, recall 0.76618
2017-12-09T15:49:08.265307: step 710, loss 0.53024, acc 0.84375, prec 0.03503, recall 0.766423
2017-12-09T15:49:08.874763: step 711, loss 0.279163, acc 0.859375, prec 0.035015, recall 0.766423
2017-12-09T15:49:09.479545: step 712, loss 0.315611, acc 0.875, prec 0.0350017, recall 0.766423
2017-12-09T15:49:10.091142: step 713, loss 0.540535, acc 0.84375, prec 0.034985, recall 0.766423
2017-12-09T15:49:10.704292: step 714, loss 0.372657, acc 0.921875, prec 0.0349767, recall 0.766423
2017-12-09T15:49:11.318525: step 715, loss 5.23205, acc 0.890625, prec 0.0349667, recall 0.765625
2017-12-09T15:49:11.937874: step 716, loss 0.484146, acc 0.859375, prec 0.0349517, recall 0.765625
2017-12-09T15:49:12.585034: step 717, loss 8.1118, acc 0.90625, prec 0.0349434, recall 0.764828
2017-12-09T15:49:13.205954: step 718, loss 0.704568, acc 0.859375, prec 0.0349743, recall 0.765073
2017-12-09T15:49:13.826765: step 719, loss 0.423464, acc 0.859375, prec 0.0349594, recall 0.765073
2017-12-09T15:49:14.438913: step 720, loss 0.464243, acc 0.875, prec 0.0350377, recall 0.76556
2017-12-09T15:49:15.072925: step 721, loss 0.614205, acc 0.796875, prec 0.0350619, recall 0.765803
2017-12-09T15:49:15.710433: step 722, loss 0.599016, acc 0.765625, prec 0.035037, recall 0.765803
2017-12-09T15:49:16.347413: step 723, loss 1.55443, acc 0.875, prec 0.0352066, recall 0.76677
2017-12-09T15:49:16.983763: step 724, loss 0.508097, acc 0.859375, prec 0.0352373, recall 0.76701
2017-12-09T15:49:17.615710: step 725, loss 0.608102, acc 0.796875, prec 0.0352156, recall 0.76701
2017-12-09T15:49:18.254753: step 726, loss 0.832101, acc 0.78125, prec 0.0352835, recall 0.76749
2017-12-09T15:49:18.885458: step 727, loss 0.756498, acc 0.8125, prec 0.0352635, recall 0.76749
2017-12-09T15:49:19.495774: step 728, loss 0.771529, acc 0.75, prec 0.035328, recall 0.767967
2017-12-09T15:49:20.104470: step 729, loss 7.90763, acc 0.8125, prec 0.0354007, recall 0.767656
2017-12-09T15:49:20.714553: step 730, loss 1.09206, acc 0.78125, prec 0.0353774, recall 0.767656
2017-12-09T15:49:21.318011: step 731, loss 0.899144, acc 0.75, prec 0.0353961, recall 0.767894
2017-12-09T15:49:21.928165: step 732, loss 1.06272, acc 0.734375, prec 0.0353678, recall 0.767894
2017-12-09T15:49:22.540392: step 733, loss 1.47992, acc 0.59375, prec 0.0353246, recall 0.767894
2017-12-09T15:49:23.150389: step 734, loss 0.86219, acc 0.703125, prec 0.035293, recall 0.767894
2017-12-09T15:49:23.759569: step 735, loss 0.959725, acc 0.734375, prec 0.0353554, recall 0.768367
2017-12-09T15:49:24.376760: step 736, loss 0.855622, acc 0.75, prec 0.0353289, recall 0.768367
2017-12-09T15:49:24.986568: step 737, loss 0.878669, acc 0.765625, prec 0.035304, recall 0.768367
2017-12-09T15:49:25.592354: step 738, loss 1.06916, acc 0.71875, prec 0.0352743, recall 0.768367
2017-12-09T15:49:26.200457: step 739, loss 0.320838, acc 0.859375, prec 0.0352594, recall 0.768367
2017-12-09T15:49:26.813146: step 740, loss 1.69113, acc 0.8125, prec 0.0352848, recall 0.768603
2017-12-09T15:49:27.423765: step 741, loss 0.860069, acc 0.75, prec 0.0353035, recall 0.768839
2017-12-09T15:49:28.036029: step 742, loss 1.39187, acc 0.828125, prec 0.0353304, recall 0.769074
2017-12-09T15:49:28.644242: step 743, loss 0.5233, acc 0.796875, prec 0.035309, recall 0.769074
2017-12-09T15:49:29.255514: step 744, loss 0.551687, acc 0.828125, prec 0.0353359, recall 0.769309
2017-12-09T15:49:29.862827: step 745, loss 0.51406, acc 0.828125, prec 0.0353177, recall 0.769309
2017-12-09T15:49:30.479602: step 746, loss 0.868488, acc 0.859375, prec 0.0353479, recall 0.769543
2017-12-09T15:49:31.121170: step 747, loss 0.477886, acc 0.796875, prec 0.0353714, recall 0.769777
2017-12-09T15:49:31.757828: step 748, loss 0.264574, acc 0.9375, prec 0.0354098, recall 0.77001
2017-12-09T15:49:32.395917: step 749, loss 0.82609, acc 0.8125, prec 0.0354349, recall 0.770243
2017-12-09T15:49:33.026244: step 750, loss 0.828651, acc 0.84375, prec 0.0355082, recall 0.770707
2017-12-09T15:49:33.663548: step 751, loss 8.14145, acc 0.796875, prec 0.0354884, recall 0.769929
2017-12-09T15:49:34.298760: step 752, loss 0.400087, acc 0.796875, prec 0.0355118, recall 0.770161
2017-12-09T15:49:34.933405: step 753, loss 0.53784, acc 0.875, prec 0.0355882, recall 0.770624
2017-12-09T15:49:35.568813: step 754, loss 1.37098, acc 0.875, prec 0.0357541, recall 0.771543
2017-12-09T15:49:36.180321: step 755, loss 0.415057, acc 0.859375, prec 0.0357839, recall 0.771772
2017-12-09T15:49:36.787969: step 756, loss 6.32247, acc 0.796875, prec 0.0358087, recall 0.771229
2017-12-09T15:49:37.398287: step 757, loss 0.53574, acc 0.875, prec 0.0358401, recall 0.771457
2017-12-09T15:49:38.007110: step 758, loss 1.15456, acc 0.703125, prec 0.0358533, recall 0.771685
2017-12-09T15:49:38.614388: step 759, loss 2.32969, acc 0.78125, prec 0.0359639, recall 0.772366
2017-12-09T15:49:39.232444: step 760, loss 1.5807, acc 0.6875, prec 0.0359752, recall 0.772592
2017-12-09T15:49:39.846801: step 761, loss 1.45118, acc 0.703125, prec 0.0359436, recall 0.772592
2017-12-09T15:49:40.460508: step 762, loss 1.21196, acc 0.640625, prec 0.03595, recall 0.772817
2017-12-09T15:49:41.091877: step 763, loss 1.29431, acc 0.609375, prec 0.035953, recall 0.773043
2017-12-09T15:49:41.717784: step 764, loss 1.38365, acc 0.625, prec 0.0359576, recall 0.773267
2017-12-09T15:49:42.361298: step 765, loss 1.30845, acc 0.671875, prec 0.0359229, recall 0.773267
2017-12-09T15:49:42.998750: step 766, loss 1.54579, acc 0.578125, prec 0.0359226, recall 0.773492
2017-12-09T15:49:43.634957: step 767, loss 1.64015, acc 0.5625, prec 0.0358765, recall 0.773492
2017-12-09T15:49:44.273545: step 768, loss 0.957068, acc 0.6875, prec 0.0358436, recall 0.773492
2017-12-09T15:49:44.905512: step 769, loss 0.974294, acc 0.71875, prec 0.0358141, recall 0.773492
2017-12-09T15:49:45.536570: step 770, loss 0.854294, acc 0.703125, prec 0.0357829, recall 0.773492
2017-12-09T15:49:46.187592: step 771, loss 0.802246, acc 0.75, prec 0.0357567, recall 0.773492
2017-12-09T15:49:46.815254: step 772, loss 0.523386, acc 0.859375, prec 0.0358742, recall 0.774162
2017-12-09T15:49:47.447205: step 773, loss 2.40301, acc 0.796875, prec 0.0358546, recall 0.773399
2017-12-09T15:49:48.088537: step 774, loss 0.389982, acc 0.796875, prec 0.0358333, recall 0.773399
2017-12-09T15:49:48.720170: step 775, loss 0.278562, acc 0.921875, prec 0.0358251, recall 0.773399
2017-12-09T15:49:49.369524: step 776, loss 13.6856, acc 0.84375, prec 0.0358137, recall 0.77112
2017-12-09T15:49:50.000153: step 777, loss 0.602022, acc 0.796875, prec 0.0357924, recall 0.77112
2017-12-09T15:49:50.637841: step 778, loss 1.53589, acc 0.65625, prec 0.0358005, recall 0.771344
2017-12-09T15:49:51.250682: step 779, loss 0.754306, acc 0.765625, prec 0.0357761, recall 0.771344
2017-12-09T15:49:51.868463: step 780, loss 2.16762, acc 0.671875, prec 0.0357857, recall 0.771569
2017-12-09T15:49:52.481761: step 781, loss 1.1928, acc 0.71875, prec 0.0357565, recall 0.771569
2017-12-09T15:49:53.094814: step 782, loss 1.31721, acc 0.609375, prec 0.0357597, recall 0.771792
2017-12-09T15:49:53.698589: step 783, loss 1.54516, acc 0.515625, prec 0.0357094, recall 0.771792
2017-12-09T15:49:54.312841: step 784, loss 1.53207, acc 0.671875, prec 0.0356755, recall 0.771792
2017-12-09T15:49:54.930170: step 785, loss 1.87382, acc 0.546875, prec 0.0356723, recall 0.772016
2017-12-09T15:49:55.562102: step 786, loss 1.74909, acc 0.5625, prec 0.0356272, recall 0.772016
2017-12-09T15:49:56.193341: step 787, loss 0.941912, acc 0.6875, prec 0.0356821, recall 0.772461
2017-12-09T15:49:56.818787: step 788, loss 0.853681, acc 0.734375, prec 0.0356982, recall 0.772683
2017-12-09T15:49:57.447675: step 789, loss 1.3964, acc 0.6875, prec 0.0357095, recall 0.772904
2017-12-09T15:49:58.082859: step 790, loss 1.26513, acc 0.625, prec 0.0357577, recall 0.773346
2017-12-09T15:49:58.720508: step 791, loss 0.527529, acc 0.828125, prec 0.0358267, recall 0.773786
2017-12-09T15:49:59.357193: step 792, loss 0.723093, acc 0.765625, prec 0.0358025, recall 0.773786
2017-12-09T15:49:59.988393: step 793, loss 1.17441, acc 0.703125, prec 0.0358153, recall 0.774006
2017-12-09T15:50:00.627323: step 794, loss 0.35078, acc 0.859375, prec 0.0358441, recall 0.774225
2017-12-09T15:50:01.262833: step 795, loss 4.94153, acc 0.8125, prec 0.0359145, recall 0.773166
2017-12-09T15:50:01.901818: step 796, loss 4.91618, acc 0.796875, prec 0.0358951, recall 0.77242
2017-12-09T15:50:02.537823: step 797, loss 2.02289, acc 0.78125, prec 0.0358742, recall 0.771676
2017-12-09T15:50:03.168471: step 798, loss 11.3511, acc 0.75, prec 0.0358502, recall 0.770934
2017-12-09T15:50:03.806615: step 799, loss 1.90613, acc 0.8125, prec 0.0358325, recall 0.770192
2017-12-09T15:50:04.447189: step 800, loss 1.74298, acc 0.53125, prec 0.0358276, recall 0.770413
Saved model checkpoint to /Users/adb/Google Drive/Data Analytics/project/xtalkdb/Deep Learning/num_filter_128_fold_0/1512852011/checkpoints/model-800

2017-12-09T15:50:05.858364: step 801, loss 1.65257, acc 0.546875, prec 0.0357812, recall 0.770413
2017-12-09T15:50:06.451169: step 802, loss 1.99252, acc 0.53125, prec 0.0357334, recall 0.770413
2017-12-09T15:50:07.054258: step 803, loss 1.93417, acc 0.5625, prec 0.0358605, recall 0.771292
2017-12-09T15:50:07.680700: step 804, loss 1.71875, acc 0.515625, prec 0.0359396, recall 0.771947
2017-12-09T15:50:08.287774: step 805, loss 1.95774, acc 0.546875, prec 0.0360216, recall 0.772598
2017-12-09T15:50:08.909247: step 806, loss 2.19275, acc 0.5, prec 0.0359706, recall 0.772598
2017-12-09T15:50:09.517738: step 807, loss 2.65397, acc 0.421875, prec 0.0359117, recall 0.772598
2017-12-09T15:50:10.135085: step 808, loss 2.58487, acc 0.421875, prec 0.0358956, recall 0.772814
2017-12-09T15:50:10.764452: step 809, loss 2.29594, acc 0.515625, prec 0.0358891, recall 0.773029
2017-12-09T15:50:11.395141: step 810, loss 1.34744, acc 0.6875, prec 0.0359848, recall 0.773674
2017-12-09T15:50:12.034019: step 811, loss 1.63357, acc 0.578125, prec 0.0359421, recall 0.773674
2017-12-09T15:50:12.680312: step 812, loss 1.11106, acc 0.609375, prec 0.0359026, recall 0.773674
2017-12-09T15:50:13.312572: step 813, loss 1.06807, acc 0.765625, prec 0.035879, recall 0.773674
2017-12-09T15:50:13.945705: step 814, loss 2.11525, acc 0.59375, prec 0.0358803, recall 0.773888
2017-12-09T15:50:14.580572: step 815, loss 0.750387, acc 0.75, prec 0.0358552, recall 0.773888
2017-12-09T15:50:15.218996: step 816, loss 0.589166, acc 0.796875, prec 0.0359192, recall 0.774315
2017-12-09T15:50:15.853120: step 817, loss 0.792486, acc 0.75, prec 0.0358941, recall 0.774315
2017-12-09T15:50:16.491435: step 818, loss 0.55759, acc 0.734375, prec 0.0358674, recall 0.774315
2017-12-09T15:50:17.151267: step 819, loss 5.10822, acc 0.84375, prec 0.0358954, recall 0.773798
2017-12-09T15:50:17.814449: step 820, loss 0.709473, acc 0.765625, prec 0.035914, recall 0.774011
2017-12-09T15:50:18.443066: step 821, loss 1.45655, acc 0.859375, prec 0.0359841, recall 0.774436
2017-12-09T15:50:19.075957: step 822, loss 0.921142, acc 0.734375, prec 0.0359995, recall 0.774648
2017-12-09T15:50:19.714446: step 823, loss 0.721533, acc 0.8125, prec 0.0360227, recall 0.774859
2017-12-09T15:50:20.346992: step 824, loss 0.437442, acc 0.84375, prec 0.036007, recall 0.774859
2017-12-09T15:50:20.986993: step 825, loss 0.879357, acc 0.859375, prec 0.0360349, recall 0.77507
2017-12-09T15:50:21.617510: step 826, loss 0.61672, acc 0.78125, prec 0.0360129, recall 0.77507
2017-12-09T15:50:22.251586: step 827, loss 13.7263, acc 0.890625, prec 0.0360454, recall 0.774556
2017-12-09T15:50:22.884499: step 828, loss 0.357276, acc 0.859375, prec 0.0360733, recall 0.774766
2017-12-09T15:50:23.523773: step 829, loss 0.51718, acc 0.859375, prec 0.0360592, recall 0.774766
2017-12-09T15:50:24.164765: step 830, loss 0.667766, acc 0.78125, prec 0.0360791, recall 0.774977
2017-12-09T15:50:24.798593: step 831, loss 1.73357, acc 0.828125, prec 0.0361053, recall 0.774464
2017-12-09T15:50:25.437632: step 832, loss 0.412217, acc 0.84375, prec 0.0361315, recall 0.774674
2017-12-09T15:50:26.070366: step 833, loss 0.54362, acc 0.796875, prec 0.0361111, recall 0.774674
2017-12-09T15:50:26.705339: step 834, loss 0.523754, acc 0.8125, prec 0.0361341, recall 0.774884
2017-12-09T15:50:27.339637: step 835, loss 1.08325, acc 0.859375, prec 0.0362872, recall 0.775718
2017-12-09T15:50:27.972521: step 836, loss 0.555761, acc 0.796875, prec 0.0362667, recall 0.775718
2017-12-09T15:50:28.600919: step 837, loss 8.86964, acc 0.84375, prec 0.0362526, recall 0.775
2017-12-09T15:50:29.241386: step 838, loss 0.456448, acc 0.796875, prec 0.0362739, recall 0.775208
2017-12-09T15:50:29.874415: step 839, loss 0.300597, acc 0.828125, prec 0.0362983, recall 0.775416
2017-12-09T15:50:30.509953: step 840, loss 1.66035, acc 0.765625, prec 0.0363581, recall 0.77583
2017-12-09T15:50:31.143217: step 841, loss 0.811772, acc 0.78125, prec 0.0363361, recall 0.77583
2017-12-09T15:50:31.773631: step 842, loss 0.82507, acc 0.765625, prec 0.0363542, recall 0.776037
2017-12-09T15:50:32.405834: step 843, loss 0.654738, acc 0.71875, prec 0.036326, recall 0.776037
2017-12-09T15:50:33.078279: step 844, loss 0.664312, acc 0.75, prec 0.0363009, recall 0.776037
2017-12-09T15:50:33.719318: step 845, loss 0.84993, acc 0.71875, prec 0.0362728, recall 0.776037
2017-12-09T15:50:34.354765: step 846, loss 0.626493, acc 0.796875, prec 0.0362525, recall 0.776037
2017-12-09T15:50:35.003393: step 847, loss 0.821714, acc 0.78125, prec 0.0363136, recall 0.776449
2017-12-09T15:50:35.654585: step 848, loss 2.88852, acc 0.765625, prec 0.036416, recall 0.776352
2017-12-09T15:50:36.281135: step 849, loss 0.883075, acc 0.734375, prec 0.0363894, recall 0.776352
2017-12-09T15:50:36.908394: step 850, loss 0.738624, acc 0.75, prec 0.0364058, recall 0.776557
2017-12-09T15:50:37.539522: step 851, loss 0.83043, acc 0.703125, prec 0.0364175, recall 0.776761
2017-12-09T15:50:38.176940: step 852, loss 0.663386, acc 0.796875, prec 0.0363972, recall 0.776761
2017-12-09T15:50:38.826443: step 853, loss 1.34937, acc 0.75, prec 0.0364135, recall 0.776965
2017-12-09T15:50:39.457653: step 854, loss 2.19183, acc 0.796875, prec 0.0364773, recall 0.776664
2017-12-09T15:50:40.091560: step 855, loss 0.470521, acc 0.890625, prec 0.0364664, recall 0.776664
2017-12-09T15:50:40.732089: step 856, loss 0.904689, acc 0.71875, prec 0.0364795, recall 0.776867
2017-12-09T15:50:41.363357: step 857, loss 0.663594, acc 0.734375, prec 0.036453, recall 0.776867
2017-12-09T15:50:41.988316: step 858, loss 0.779485, acc 0.8125, prec 0.0364755, recall 0.77707
2017-12-09T15:50:42.613205: step 859, loss 0.94808, acc 0.734375, prec 0.036449, recall 0.77707
2017-12-09T15:50:43.239979: step 860, loss 0.766148, acc 0.75, prec 0.0365063, recall 0.777475
2017-12-09T15:50:43.881974: step 861, loss 0.435531, acc 0.796875, prec 0.0365271, recall 0.777677
2017-12-09T15:50:44.511227: step 862, loss 0.839376, acc 0.78125, prec 0.0365464, recall 0.777879
2017-12-09T15:50:45.135641: step 863, loss 0.981007, acc 0.71875, prec 0.0365594, recall 0.77808
2017-12-09T15:50:45.764772: step 864, loss 0.729409, acc 0.75, prec 0.0365345, recall 0.77808
2017-12-09T15:50:46.393841: step 865, loss 1.01351, acc 0.828125, prec 0.0366403, recall 0.778681
2017-12-09T15:50:47.021494: step 866, loss 0.470234, acc 0.828125, prec 0.0366232, recall 0.778681
2017-12-09T15:50:47.654516: step 867, loss 0.265506, acc 0.875, prec 0.0366107, recall 0.778681
2017-12-09T15:50:48.267141: step 868, loss 1.37644, acc 0.90625, prec 0.0366439, recall 0.778179
2017-12-09T15:50:48.884074: step 869, loss 1.75319, acc 0.875, prec 0.0366739, recall 0.777678
2017-12-09T15:50:49.490745: step 870, loss 0.435378, acc 0.859375, prec 0.0366599, recall 0.777678
2017-12-09T15:50:50.135652: step 871, loss 0.322856, acc 0.921875, prec 0.0366521, recall 0.777678
2017-12-09T15:50:50.738414: step 872, loss 0.527623, acc 0.90625, prec 0.0367245, recall 0.778077
2017-12-09T15:50:51.353721: step 873, loss 0.783798, acc 0.828125, prec 0.0367482, recall 0.778277
2017-12-09T15:50:51.968252: step 874, loss 0.595787, acc 0.828125, prec 0.0367719, recall 0.778475
2017-12-09T15:50:52.601039: step 875, loss 0.507511, acc 0.84375, prec 0.0367971, recall 0.778674
2017-12-09T15:50:53.234189: step 876, loss 0.280482, acc 0.890625, prec 0.0367862, recall 0.778674
2017-12-09T15:50:53.863924: step 877, loss 0.457446, acc 0.859375, prec 0.0368129, recall 0.778872
2017-12-09T15:50:54.496524: step 878, loss 0.181557, acc 0.953125, prec 0.0368083, recall 0.778872
2017-12-09T15:50:55.122954: step 879, loss 2.1596, acc 0.859375, prec 0.0367958, recall 0.778175
2017-12-09T15:50:55.760815: step 880, loss 0.584744, acc 0.875, prec 0.0368241, recall 0.778374
2017-12-09T15:50:56.391627: step 881, loss 3.3902, acc 0.84375, prec 0.0368116, recall 0.776985
2017-12-09T15:50:57.018434: step 882, loss 15.3929, acc 0.78125, prec 0.036793, recall 0.775601
2017-12-09T15:50:57.660814: step 883, loss 0.58787, acc 0.78125, prec 0.0367712, recall 0.775601
2017-12-09T15:50:58.300896: step 884, loss 0.795974, acc 0.75, prec 0.0367464, recall 0.775601
2017-12-09T15:50:58.934769: step 885, loss 1.22132, acc 0.640625, prec 0.0367108, recall 0.775601
2017-12-09T15:50:59.564332: step 886, loss 1.35502, acc 0.609375, prec 0.0366721, recall 0.775601
2017-12-09T15:51:00.196624: step 887, loss 1.00535, acc 0.671875, prec 0.0367208, recall 0.776
2017-12-09T15:51:00.825007: step 888, loss 2.01507, acc 0.46875, prec 0.0366683, recall 0.776
2017-12-09T15:51:01.449448: step 889, loss 2.10791, acc 0.4375, prec 0.0366534, recall 0.776199
2017-12-09T15:51:02.078663: step 890, loss 1.59559, acc 0.484375, prec 0.0366027, recall 0.776199
2017-12-09T15:51:02.714040: step 891, loss 2.06392, acc 0.546875, prec 0.0366389, recall 0.776596
2017-12-09T15:51:03.338295: step 892, loss 2.10742, acc 0.421875, prec 0.0366225, recall 0.776794
2017-12-09T15:51:03.959666: step 893, loss 1.91227, acc 0.515625, prec 0.0366154, recall 0.776991
2017-12-09T15:51:04.592299: step 894, loss 1.85197, acc 0.515625, prec 0.0365681, recall 0.776991
2017-12-09T15:51:05.219257: step 895, loss 1.32719, acc 0.609375, prec 0.0365701, recall 0.777188
2017-12-09T15:51:05.845175: step 896, loss 1.43911, acc 0.578125, prec 0.0365691, recall 0.777385
2017-12-09T15:51:06.472605: step 897, loss 1.19505, acc 0.609375, prec 0.0365312, recall 0.777385
2017-12-09T15:51:07.087327: step 898, loss 0.774624, acc 0.75, prec 0.0365469, recall 0.777582
2017-12-09T15:51:07.695106: step 899, loss 0.617455, acc 0.8125, prec 0.0365287, recall 0.777582
2017-12-09T15:51:08.303298: step 900, loss 0.622281, acc 0.765625, prec 0.036506, recall 0.777582

Evaluation:
2017-12-09T15:51:59.183848: step 900, loss 1.46825, acc 0.869799, prec 0.0387579, recall 0.764071

Saved model checkpoint to /Users/adb/Google Drive/Data Analytics/project/xtalkdb/Deep Learning/num_filter_128_fold_0/1512852011/checkpoints/model-900

2017-12-09T15:52:01.025027: step 901, loss 0.334904, acc 0.890625, prec 0.0387473, recall 0.764071
2017-12-09T15:52:01.650577: step 902, loss 1.1311, acc 0.84375, prec 0.0388073, recall 0.764434
2017-12-09T15:52:02.285392: step 903, loss 3.94944, acc 0.90625, prec 0.0388372, recall 0.764028
2017-12-09T15:52:02.916496: step 904, loss 0.218835, acc 0.9375, prec 0.0388312, recall 0.764028
2017-12-09T15:52:03.534940: step 905, loss 0.22156, acc 0.921875, prec 0.0388987, recall 0.76439
2017-12-09T15:52:04.150237: step 906, loss 0.441768, acc 0.84375, prec 0.0388835, recall 0.76439
2017-12-09T15:52:04.769844: step 907, loss 0.922466, acc 0.828125, prec 0.0389793, recall 0.764931
2017-12-09T15:52:05.390729: step 908, loss 0.957524, acc 0.890625, prec 0.0390061, recall 0.765111
2017-12-09T15:52:06.016204: step 909, loss 8.44207, acc 0.890625, prec 0.0390719, recall 0.764885
2017-12-09T15:52:06.688640: step 910, loss 0.465533, acc 0.84375, prec 0.0390567, recall 0.764885
2017-12-09T15:52:07.317031: step 911, loss 0.794081, acc 0.765625, prec 0.0390339, recall 0.764885
2017-12-09T15:52:07.967236: step 912, loss 0.816839, acc 0.78125, prec 0.0390874, recall 0.765244
2017-12-09T15:52:08.608129: step 913, loss 0.795509, acc 0.75, prec 0.0390631, recall 0.765244
2017-12-09T15:52:09.248938: step 914, loss 0.797977, acc 0.765625, prec 0.0391524, recall 0.765779
2017-12-09T15:52:09.876490: step 915, loss 6.39504, acc 0.6875, prec 0.0391235, recall 0.765198
2017-12-09T15:52:10.513954: step 916, loss 1.37409, acc 0.71875, prec 0.0392081, recall 0.765732
2017-12-09T15:52:11.150697: step 917, loss 0.723617, acc 0.734375, prec 0.0391822, recall 0.765732
2017-12-09T15:52:11.790602: step 918, loss 1.22428, acc 0.671875, prec 0.0391503, recall 0.765732
2017-12-09T15:52:12.444987: step 919, loss 1.28023, acc 0.59375, prec 0.0391481, recall 0.765909
2017-12-09T15:52:13.074341: step 920, loss 1.03024, acc 0.625, prec 0.0391861, recall 0.766263
2017-12-09T15:52:13.710137: step 921, loss 0.903897, acc 0.71875, prec 0.039196, recall 0.76644
2017-12-09T15:52:14.348055: step 922, loss 1.1786, acc 0.609375, prec 0.0391581, recall 0.76644
2017-12-09T15:52:14.983321: step 923, loss 1.19021, acc 0.546875, prec 0.0391143, recall 0.76644
2017-12-09T15:52:15.613184: step 924, loss 1.1042, acc 0.65625, prec 0.0391182, recall 0.766616
2017-12-09T15:52:16.245829: step 925, loss 1.16377, acc 0.71875, prec 0.0391651, recall 0.766968
2017-12-09T15:52:16.875678: step 926, loss 0.699336, acc 0.78125, prec 0.039144, recall 0.766968
2017-12-09T15:52:17.507622: step 927, loss 0.690228, acc 0.78125, prec 0.0391229, recall 0.766968
2017-12-09T15:52:18.136311: step 928, loss 5.17592, acc 0.75, prec 0.0391373, recall 0.766566
2017-12-09T15:52:18.767749: step 929, loss 0.728737, acc 0.796875, prec 0.0391547, recall 0.766742
2017-12-09T15:52:19.396543: step 930, loss 0.804988, acc 0.796875, prec 0.0393196, recall 0.767616
2017-12-09T15:52:20.027833: step 931, loss 0.976499, acc 0.671875, prec 0.0392879, recall 0.767616
2017-12-09T15:52:20.653464: step 932, loss 5.27918, acc 0.71875, prec 0.0392623, recall 0.767041
2017-12-09T15:52:21.294601: step 933, loss 1.25275, acc 0.8125, prec 0.0392811, recall 0.767216
2017-12-09T15:52:21.955627: step 934, loss 1.06858, acc 0.75, prec 0.039257, recall 0.767216
2017-12-09T15:52:22.609994: step 935, loss 0.847156, acc 0.734375, prec 0.0392314, recall 0.767216
2017-12-09T15:52:23.245294: step 936, loss 1.21627, acc 0.59375, prec 0.0391924, recall 0.767216
2017-12-09T15:52:23.879290: step 937, loss 1.25245, acc 0.6875, prec 0.0391992, recall 0.76739
2017-12-09T15:52:24.508840: step 938, loss 0.77738, acc 0.734375, prec 0.0391738, recall 0.76739
2017-12-09T15:52:25.141948: step 939, loss 0.681335, acc 0.859375, prec 0.0392336, recall 0.767737
2017-12-09T15:52:25.769348: step 940, loss 0.773295, acc 0.78125, prec 0.0392127, recall 0.767737
2017-12-09T15:52:26.401688: step 941, loss 0.538768, acc 0.78125, prec 0.039265, recall 0.768084
2017-12-09T15:52:27.033633: step 942, loss 0.489528, acc 0.8125, prec 0.0392837, recall 0.768256
2017-12-09T15:52:27.669757: step 943, loss 0.659928, acc 0.78125, prec 0.0392627, recall 0.768256
2017-12-09T15:52:28.299536: step 944, loss 0.608824, acc 0.765625, prec 0.0393134, recall 0.768601
2017-12-09T15:52:28.939869: step 945, loss 3.25476, acc 0.84375, prec 0.0393365, recall 0.768202
2017-12-09T15:52:29.616814: step 946, loss 0.818041, acc 0.84375, prec 0.0393581, recall 0.768374
2017-12-09T15:52:30.252710: step 947, loss 0.435695, acc 0.875, prec 0.0393827, recall 0.768546
2017-12-09T15:52:30.880901: step 948, loss 3.59013, acc 0.859375, prec 0.0393707, recall 0.767976
2017-12-09T15:52:31.513415: step 949, loss 9.63082, acc 0.78125, prec 0.0393892, recall 0.767012
2017-12-09T15:52:32.143908: step 950, loss 0.528782, acc 0.796875, prec 0.0393698, recall 0.767012
2017-12-09T15:52:32.773515: step 951, loss 1.10705, acc 0.671875, prec 0.0393384, recall 0.767012
2017-12-09T15:52:33.408242: step 952, loss 0.695066, acc 0.78125, prec 0.0393175, recall 0.767012
2017-12-09T15:52:34.035521: step 953, loss 0.912603, acc 0.796875, prec 0.0392982, recall 0.767012
2017-12-09T15:52:34.670807: step 954, loss 1.19997, acc 0.65625, prec 0.0394109, recall 0.767699
2017-12-09T15:52:35.306663: step 955, loss 1.97547, acc 0.5625, prec 0.0393692, recall 0.767699
2017-12-09T15:52:35.941727: step 956, loss 1.35247, acc 0.6875, prec 0.0393394, recall 0.767699
2017-12-09T15:52:36.576665: step 957, loss 1.33313, acc 0.65625, prec 0.0393068, recall 0.767699
2017-12-09T15:52:37.206418: step 958, loss 1.50346, acc 0.59375, prec 0.0392682, recall 0.767699
2017-12-09T15:52:37.831399: step 959, loss 2.28161, acc 0.609375, prec 0.0392674, recall 0.76787
2017-12-09T15:52:38.490745: step 960, loss 2.35297, acc 0.703125, prec 0.0393117, recall 0.768212
2017-12-09T15:52:39.113008: step 961, loss 1.41261, acc 0.640625, prec 0.0393138, recall 0.768382
2017-12-09T15:52:39.777448: step 962, loss 1.28348, acc 0.65625, prec 0.0393174, recall 0.768553
2017-12-09T15:52:40.409704: step 963, loss 0.909089, acc 0.75, prec 0.0393299, recall 0.768722
2017-12-09T15:52:41.037657: step 964, loss 1.19418, acc 0.65625, prec 0.0392974, recall 0.768722
2017-12-09T15:52:41.667554: step 965, loss 1.12278, acc 0.71875, prec 0.0393069, recall 0.768892
2017-12-09T15:52:42.302128: step 966, loss 1.86905, acc 0.640625, prec 0.039309, recall 0.769062
2017-12-09T15:52:42.936324: step 967, loss 8.14816, acc 0.734375, prec 0.0393214, recall 0.768668
2017-12-09T15:52:43.563556: step 968, loss 1.71346, acc 0.59375, prec 0.0393191, recall 0.768837
2017-12-09T15:52:44.197718: step 969, loss 0.897237, acc 0.734375, prec 0.03933, recall 0.769006
2017-12-09T15:52:44.824830: step 970, loss 0.584874, acc 0.765625, prec 0.0393439, recall 0.769175
2017-12-09T15:52:45.454978: step 971, loss 1.51581, acc 0.65625, prec 0.0393474, recall 0.769343
2017-12-09T15:52:46.086827: step 972, loss 6.19215, acc 0.75, prec 0.0393254, recall 0.768782
2017-12-09T15:52:46.729070: step 973, loss 2.28745, acc 0.703125, prec 0.0393692, recall 0.769119
2017-12-09T15:52:47.359355: step 974, loss 1.09354, acc 0.75, prec 0.0394173, recall 0.769455
2017-12-09T15:52:47.985915: step 975, loss 1.84354, acc 0.765625, prec 0.0394668, recall 0.769789
2017-12-09T15:52:48.619292: step 976, loss 1.23912, acc 0.640625, prec 0.0394331, recall 0.769789
2017-12-09T15:52:49.253635: step 977, loss 1.41387, acc 0.609375, prec 0.0394321, recall 0.769956
2017-12-09T15:52:49.889266: step 978, loss 1.53725, acc 0.59375, prec 0.0394654, recall 0.77029
2017-12-09T15:52:50.513376: step 979, loss 2.04237, acc 0.640625, prec 0.039503, recall 0.770622
2017-12-09T15:52:51.142646: step 980, loss 1.28834, acc 0.6875, prec 0.0395449, recall 0.770954
2017-12-09T15:52:51.785852: step 981, loss 1.45579, acc 0.671875, prec 0.0395497, recall 0.771119
2017-12-09T15:52:52.451912: step 982, loss 0.70463, acc 0.765625, prec 0.0395633, recall 0.771284
2017-12-09T15:52:53.079604: step 983, loss 0.773338, acc 0.75, prec 0.0395754, recall 0.771449
2017-12-09T15:52:53.711601: step 984, loss 1.23083, acc 0.703125, prec 0.0395831, recall 0.771614
2017-12-09T15:52:54.337543: step 985, loss 0.699547, acc 0.765625, prec 0.0395966, recall 0.771778
2017-12-09T15:52:54.975755: step 986, loss 10.8815, acc 0.640625, prec 0.0395999, recall 0.771388
2017-12-09T15:52:55.608828: step 987, loss 1.0128, acc 0.671875, prec 0.0396047, recall 0.771552
2017-12-09T15:52:56.231752: step 988, loss 0.784174, acc 0.828125, prec 0.039624, recall 0.771716
2017-12-09T15:52:56.864903: step 989, loss 5.65763, acc 0.671875, prec 0.0395948, recall 0.771162
2017-12-09T15:52:57.503659: step 990, loss 1.02022, acc 0.71875, prec 0.0395686, recall 0.771162
2017-12-09T15:52:58.134230: step 991, loss 0.802982, acc 0.75, prec 0.039616, recall 0.77149
2017-12-09T15:52:58.763340: step 992, loss 1.64088, acc 0.78125, prec 0.0396662, recall 0.771817
2017-12-09T15:52:59.392601: step 993, loss 1.07737, acc 0.71875, prec 0.0396753, recall 0.77198
2017-12-09T15:52:59.919437: step 994, loss 1.50514, acc 0.764706, prec 0.039693, recall 0.772143
2017-12-09T15:53:00.571657: step 995, loss 0.797203, acc 0.75, prec 0.0396697, recall 0.772143
2017-12-09T15:53:01.202808: step 996, loss 0.815516, acc 0.75, prec 0.0397873, recall 0.772792
2017-12-09T15:53:01.838656: step 997, loss 0.999588, acc 0.71875, prec 0.0398666, recall 0.773276
2017-12-09T15:53:02.477119: step 998, loss 0.823246, acc 0.71875, prec 0.0398403, recall 0.773276
2017-12-09T15:53:03.103675: step 999, loss 1.27789, acc 0.734375, prec 0.039921, recall 0.773759
2017-12-09T15:53:03.732424: step 1000, loss 0.756302, acc 0.796875, prec 0.039902, recall 0.773759
Saved model checkpoint to /Users/adb/Google Drive/Data Analytics/project/xtalkdb/Deep Learning/num_filter_128_fold_0/1512852011/checkpoints/model-1000

2017-12-09T15:53:05.220696: step 1001, loss 0.724486, acc 0.8125, prec 0.0399196, recall 0.773919
2017-12-09T15:53:05.820623: step 1002, loss 0.276119, acc 0.828125, prec 0.0399035, recall 0.773919
2017-12-09T15:53:06.415309: step 1003, loss 0.542647, acc 0.8125, prec 0.0399211, recall 0.774079
2017-12-09T15:53:07.018685: step 1004, loss 1.15671, acc 0.828125, prec 0.0399401, recall 0.774239
2017-12-09T15:53:07.635100: step 1005, loss 0.609792, acc 0.828125, prec 0.0399241, recall 0.774239
2017-12-09T15:53:08.247907: step 1006, loss 0.573221, acc 0.75, prec 0.0399008, recall 0.774239
2017-12-09T15:53:08.860453: step 1007, loss 0.663613, acc 0.796875, prec 0.0398819, recall 0.774239
2017-12-09T15:53:09.478787: step 1008, loss 5.70025, acc 0.90625, prec 0.0398746, recall 0.773692
2017-12-09T15:53:10.120795: step 1009, loss 0.185159, acc 0.9375, prec 0.0399038, recall 0.773852
2017-12-09T15:53:10.753251: step 1010, loss 0.309963, acc 0.890625, prec 0.0398936, recall 0.773852
2017-12-09T15:53:11.395644: step 1011, loss 0.283888, acc 0.890625, prec 0.0398834, recall 0.773852
2017-12-09T15:53:12.031542: step 1012, loss 0.401141, acc 0.859375, prec 0.0399053, recall 0.774011
2017-12-09T15:53:12.668414: step 1013, loss 0.344461, acc 0.859375, prec 0.0399272, recall 0.774171
2017-12-09T15:53:13.302938: step 1014, loss 2.72642, acc 0.84375, prec 0.0400189, recall 0.774103
2017-12-09T15:53:13.933114: step 1015, loss 0.264022, acc 0.90625, prec 0.0400102, recall 0.774103
2017-12-09T15:53:14.562432: step 1016, loss 0.454665, acc 0.8125, prec 0.0400276, recall 0.774262
2017-12-09T15:53:15.195902: step 1017, loss 0.355846, acc 0.90625, prec 0.0400538, recall 0.77442
2017-12-09T15:53:15.825265: step 1018, loss 0.515945, acc 0.796875, prec 0.0400349, recall 0.77442
2017-12-09T15:53:16.471126: step 1019, loss 0.381842, acc 0.875, prec 0.040093, recall 0.774737
2017-12-09T15:53:17.111122: step 1020, loss 0.321583, acc 0.875, prec 0.0400813, recall 0.774737
2017-12-09T15:53:17.765042: step 1021, loss 0.222942, acc 0.953125, prec 0.0401118, recall 0.774895
2017-12-09T15:53:18.418210: step 1022, loss 0.305847, acc 0.875, prec 0.0401002, recall 0.774895
2017-12-09T15:53:19.072511: step 1023, loss 0.548406, acc 0.828125, prec 0.0400842, recall 0.774895
2017-12-09T15:53:19.719151: step 1024, loss 0.969602, acc 0.890625, prec 0.0401088, recall 0.775053
2017-12-09T15:53:20.371426: step 1025, loss 0.517663, acc 0.9375, prec 0.0401726, recall 0.775367
2017-12-09T15:53:21.023830: step 1026, loss 0.507839, acc 0.890625, prec 0.0401624, recall 0.775367
2017-12-09T15:53:21.652700: step 1027, loss 0.242826, acc 0.90625, prec 0.0401537, recall 0.775367
2017-12-09T15:53:22.277602: step 1028, loss 0.432696, acc 0.796875, prec 0.0401347, recall 0.775367
2017-12-09T15:53:22.934052: step 1029, loss 0.325565, acc 0.90625, prec 0.040126, recall 0.775367
2017-12-09T15:53:23.560245: step 1030, loss 0.447009, acc 0.828125, prec 0.0401448, recall 0.775524
2017-12-09T15:53:24.188853: step 1031, loss 0.520862, acc 0.84375, prec 0.0401303, recall 0.775524
2017-12-09T15:53:24.818609: step 1032, loss 4.04548, acc 0.890625, prec 0.0401216, recall 0.774983
2017-12-09T15:53:25.452782: step 1033, loss 1.41909, acc 0.890625, prec 0.0401823, recall 0.774756
2017-12-09T15:53:26.080475: step 1034, loss 0.405156, acc 0.84375, prec 0.0401678, recall 0.774756
2017-12-09T15:53:26.714150: step 1035, loss 0.239041, acc 0.921875, prec 0.0402299, recall 0.77507
2017-12-09T15:53:27.348401: step 1036, loss 0.0616599, acc 0.984375, prec 0.0402631, recall 0.775226
2017-12-09T15:53:27.982568: step 1037, loss 0.384648, acc 0.875, prec 0.0402515, recall 0.775226
2017-12-09T15:53:28.608106: step 1038, loss 0.648063, acc 0.78125, prec 0.0402658, recall 0.775382
2017-12-09T15:53:29.239292: step 1039, loss 0.360109, acc 0.875, prec 0.0402542, recall 0.775382
2017-12-09T15:53:29.868185: step 1040, loss 0.386932, acc 0.859375, prec 0.0402411, recall 0.775382
2017-12-09T15:53:30.499825: step 1041, loss 0.481767, acc 0.8125, prec 0.0402583, recall 0.775539
2017-12-09T15:53:31.122689: step 1042, loss 0.339306, acc 0.90625, prec 0.0402496, recall 0.775539
2017-12-09T15:53:31.748037: step 1043, loss 0.490438, acc 0.8125, prec 0.0402322, recall 0.775539
2017-12-09T15:53:32.380976: step 1044, loss 0.274308, acc 0.859375, prec 0.0402883, recall 0.77585
2017-12-09T15:53:33.005574: step 1045, loss 0.362664, acc 0.890625, prec 0.0402781, recall 0.77585
2017-12-09T15:53:33.630083: step 1046, loss 0.32088, acc 0.921875, prec 0.0403054, recall 0.776006
2017-12-09T15:53:34.255043: step 1047, loss 0.42042, acc 0.90625, prec 0.0403313, recall 0.776161
2017-12-09T15:53:34.882134: step 1048, loss 2.29984, acc 0.859375, prec 0.0403197, recall 0.775623
2017-12-09T15:53:35.512703: step 1049, loss 0.887456, acc 0.96875, prec 0.0403513, recall 0.775779
2017-12-09T15:53:36.143759: step 1050, loss 7.41188, acc 0.84375, prec 0.0403383, recall 0.775242
2017-12-09T15:53:36.781448: step 1051, loss 0.337768, acc 0.875, prec 0.0403266, recall 0.775242
2017-12-09T15:53:37.409291: step 1052, loss 0.589732, acc 0.8125, prec 0.0403092, recall 0.775242
2017-12-09T15:53:38.042284: step 1053, loss 0.619501, acc 0.71875, prec 0.0402832, recall 0.775242
2017-12-09T15:53:38.669885: step 1054, loss 0.545161, acc 0.8125, prec 0.0402658, recall 0.775242
2017-12-09T15:53:39.300138: step 1055, loss 0.620178, acc 0.796875, prec 0.0403159, recall 0.775553
2017-12-09T15:53:39.923164: step 1056, loss 0.437328, acc 0.8125, prec 0.0402986, recall 0.775553
2017-12-09T15:53:40.602857: step 1057, loss 0.775216, acc 0.71875, prec 0.0402725, recall 0.775553
2017-12-09T15:53:41.254158: step 1058, loss 3.03471, acc 0.6875, prec 0.0402795, recall 0.775172
2017-12-09T15:53:41.898604: step 1059, loss 0.797505, acc 0.78125, prec 0.0403281, recall 0.775482
2017-12-09T15:53:42.565525: step 1060, loss 0.965232, acc 0.6875, prec 0.0402992, recall 0.775482
2017-12-09T15:53:43.218550: step 1061, loss 0.642182, acc 0.765625, prec 0.0403119, recall 0.775637
2017-12-09T15:53:43.863150: step 1062, loss 0.694628, acc 0.71875, prec 0.0403546, recall 0.775945
2017-12-09T15:53:44.519611: step 1063, loss 0.628341, acc 0.828125, prec 0.0403387, recall 0.775945
2017-12-09T15:53:45.168730: step 1064, loss 0.515144, acc 0.8125, prec 0.0403214, recall 0.775945
2017-12-09T15:53:45.813644: step 1065, loss 0.684614, acc 0.765625, prec 0.0403683, recall 0.776253
2017-12-09T15:53:46.444332: step 1066, loss 0.456358, acc 0.859375, prec 0.0404239, recall 0.776559
2017-12-09T15:53:47.070715: step 1067, loss 1.00665, acc 0.875, prec 0.0404466, recall 0.776712
2017-12-09T15:53:47.707299: step 1068, loss 0.688285, acc 0.84375, prec 0.0405006, recall 0.777018
2017-12-09T15:53:48.340397: step 1069, loss 0.562308, acc 0.859375, prec 0.040556, recall 0.777322
2017-12-09T15:53:48.970124: step 1070, loss 0.515416, acc 0.8125, prec 0.0405386, recall 0.777322
2017-12-09T15:53:49.595132: step 1071, loss 2.91192, acc 0.78125, prec 0.040554, recall 0.776944
2017-12-09T15:53:50.249998: step 1072, loss 0.574303, acc 0.8125, prec 0.040605, recall 0.777248
2017-12-09T15:53:50.879940: step 1073, loss 0.622073, acc 0.734375, prec 0.0405804, recall 0.777248
2017-12-09T15:53:51.511821: step 1074, loss 0.672572, acc 0.75, prec 0.0405574, recall 0.777248
2017-12-09T15:53:52.146594: step 1075, loss 0.675855, acc 0.734375, prec 0.0405329, recall 0.777248
2017-12-09T15:53:52.777860: step 1076, loss 0.369001, acc 0.859375, prec 0.040554, recall 0.7774
2017-12-09T15:53:53.410526: step 1077, loss 0.570679, acc 0.828125, prec 0.0405381, recall 0.7774
2017-12-09T15:53:54.037423: step 1078, loss 0.36844, acc 0.890625, prec 0.0405281, recall 0.7774
2017-12-09T15:53:54.682957: step 1079, loss 0.677843, acc 0.890625, prec 0.040552, recall 0.777551
2017-12-09T15:53:55.322656: step 1080, loss 0.528413, acc 0.84375, prec 0.0405377, recall 0.777551
2017-12-09T15:53:55.952513: step 1081, loss 0.449298, acc 0.84375, prec 0.0405573, recall 0.777702
2017-12-09T15:53:56.595301: step 1082, loss 0.541082, acc 0.875, prec 0.0405458, recall 0.777702
2017-12-09T15:53:57.245922: step 1083, loss 0.471058, acc 0.859375, prec 0.0405669, recall 0.777853
2017-12-09T15:53:57.903330: step 1084, loss 0.366532, acc 0.90625, prec 0.0405583, recall 0.777853
2017-12-09T15:53:58.555301: step 1085, loss 0.310491, acc 0.890625, prec 0.0405822, recall 0.778004
2017-12-09T15:53:59.213428: step 1086, loss 0.310575, acc 0.921875, prec 0.040575, recall 0.778004
2017-12-09T15:53:59.863932: step 1087, loss 2.21966, acc 0.890625, prec 0.0405664, recall 0.777476
2017-12-09T15:54:00.523968: step 1088, loss 0.358317, acc 0.953125, prec 0.040596, recall 0.777627
2017-12-09T15:54:01.174933: step 1089, loss 3.35578, acc 0.859375, prec 0.0406185, recall 0.777251
2017-12-09T15:54:01.833051: step 1090, loss 0.475442, acc 0.859375, prec 0.0406395, recall 0.777402
2017-12-09T15:54:02.488461: step 1091, loss 0.178583, acc 0.953125, prec 0.0406691, recall 0.777552
2017-12-09T15:54:03.124147: step 1092, loss 0.248655, acc 0.890625, prec 0.0406929, recall 0.777703
2017-12-09T15:54:03.754503: step 1093, loss 3.90944, acc 0.8125, prec 0.040711, recall 0.777328
2017-12-09T15:54:04.391240: step 1094, loss 0.606641, acc 0.796875, prec 0.0406923, recall 0.777328
2017-12-09T15:54:05.024879: step 1095, loss 0.435287, acc 0.796875, prec 0.0406737, recall 0.777328
2017-12-09T15:54:05.651555: step 1096, loss 1.52872, acc 0.796875, prec 0.0407227, recall 0.777628
2017-12-09T15:54:06.278704: step 1097, loss 1.01187, acc 0.8125, prec 0.0407731, recall 0.777927
2017-12-09T15:54:06.902642: step 1098, loss 0.718306, acc 0.78125, prec 0.0407868, recall 0.778077
2017-12-09T15:54:07.527558: step 1099, loss 0.328236, acc 0.859375, prec 0.0407739, recall 0.778077
2017-12-09T15:54:08.161087: step 1100, loss 0.41346, acc 0.859375, prec 0.040761, recall 0.778077
Saved model checkpoint to /Users/adb/Google Drive/Data Analytics/project/xtalkdb/Deep Learning/num_filter_128_fold_0/1512852011/checkpoints/model-1100

2017-12-09T15:54:09.666899: step 1101, loss 1.92672, acc 0.875, prec 0.0407509, recall 0.777554
2017-12-09T15:54:10.280286: step 1102, loss 0.976945, acc 0.71875, prec 0.0407589, recall 0.777703
2017-12-09T15:54:10.888325: step 1103, loss 0.670976, acc 0.84375, prec 0.040812, recall 0.778001
2017-12-09T15:54:11.501705: step 1104, loss 0.814865, acc 0.8125, prec 0.0408285, recall 0.77815
2017-12-09T15:54:12.121769: step 1105, loss 0.900456, acc 0.703125, prec 0.0408687, recall 0.778447
2017-12-09T15:54:12.739266: step 1106, loss 1.14984, acc 0.65625, prec 0.0408708, recall 0.778595
2017-12-09T15:54:13.352515: step 1107, loss 0.537322, acc 0.75, prec 0.0408815, recall 0.778743
2017-12-09T15:54:13.978318: step 1108, loss 0.627554, acc 0.71875, prec 0.0408557, recall 0.778743
2017-12-09T15:54:14.614567: step 1109, loss 0.406641, acc 0.84375, prec 0.040875, recall 0.778891
2017-12-09T15:54:15.246293: step 1110, loss 0.444755, acc 0.796875, prec 0.0408564, recall 0.778891
2017-12-09T15:54:15.878397: step 1111, loss 0.794442, acc 0.78125, prec 0.0408363, recall 0.778891
2017-12-09T15:54:16.508522: step 1112, loss 0.795474, acc 0.828125, prec 0.0408878, recall 0.779186
2017-12-09T15:54:17.140825: step 1113, loss 1.023, acc 0.84375, prec 0.0410077, recall 0.779774
2017-12-09T15:54:17.769541: step 1114, loss 0.489715, acc 0.875, prec 0.0409962, recall 0.779774
2017-12-09T15:54:18.404716: step 1115, loss 0.741871, acc 0.765625, prec 0.0410753, recall 0.780212
2017-12-09T15:54:19.031624: step 1116, loss 0.583185, acc 0.796875, prec 0.0410566, recall 0.780212
2017-12-09T15:54:19.660232: step 1117, loss 0.721826, acc 0.890625, prec 0.0410801, recall 0.780358
2017-12-09T15:54:20.296317: step 1118, loss 7.16396, acc 0.875, prec 0.0411385, recall 0.779616
2017-12-09T15:54:20.949757: step 1119, loss 0.395323, acc 0.84375, prec 0.0411241, recall 0.779616
2017-12-09T15:54:21.603560: step 1120, loss 0.530342, acc 0.921875, prec 0.0411504, recall 0.779762
2017-12-09T15:54:22.260280: step 1121, loss 0.650229, acc 0.8125, prec 0.0412001, recall 0.780053
2017-12-09T15:54:22.908187: step 1122, loss 0.584507, acc 0.78125, prec 0.04118, recall 0.780053
2017-12-09T15:54:23.607883: step 1123, loss 1.47051, acc 0.859375, prec 0.0412339, recall 0.780343
2017-12-09T15:54:24.264450: step 1124, loss 0.606834, acc 0.78125, prec 0.0412806, recall 0.780632
2017-12-09T15:54:24.917935: step 1125, loss 0.998431, acc 0.796875, prec 0.041362, recall 0.781065
2017-12-09T15:54:25.574528: step 1126, loss 0.73821, acc 0.703125, prec 0.0413347, recall 0.781065
2017-12-09T15:54:26.228708: step 1127, loss 0.611702, acc 0.734375, prec 0.0413102, recall 0.781065
2017-12-09T15:54:26.856386: step 1128, loss 0.870652, acc 0.65625, prec 0.041312, recall 0.781209
2017-12-09T15:54:27.484133: step 1129, loss 1.39938, acc 0.703125, prec 0.0413513, recall 0.781496
2017-12-09T15:54:28.117336: step 1130, loss 1.12977, acc 0.59375, prec 0.041314, recall 0.781496
2017-12-09T15:54:28.744585: step 1131, loss 2.74577, acc 0.65625, prec 0.0412839, recall 0.780984
2017-12-09T15:54:29.407680: step 1132, loss 0.592037, acc 0.71875, prec 0.0412582, recall 0.780984
2017-12-09T15:54:30.206113: step 1133, loss 1.06517, acc 0.71875, prec 0.0412325, recall 0.780984
2017-12-09T15:54:30.994685: step 1134, loss 0.993009, acc 0.671875, prec 0.0412025, recall 0.780984
2017-12-09T15:54:31.819858: step 1135, loss 0.839081, acc 0.703125, prec 0.0412417, recall 0.78127
2017-12-09T15:54:32.674344: step 1136, loss 0.70171, acc 0.78125, prec 0.0412218, recall 0.78127
2017-12-09T15:54:33.538525: step 1137, loss 1.05246, acc 0.609375, prec 0.0412193, recall 0.781414
2017-12-09T15:54:34.411150: step 1138, loss 0.628027, acc 0.8125, prec 0.0412023, recall 0.781414
2017-12-09T15:54:35.262940: step 1139, loss 0.860763, acc 0.734375, prec 0.0412442, recall 0.781699
2017-12-09T15:54:36.003206: step 1140, loss 0.685355, acc 0.828125, prec 0.0412947, recall 0.781984
2017-12-09T15:54:36.751677: step 1141, loss 1.02453, acc 0.734375, prec 0.0413365, recall 0.782269
2017-12-09T15:54:37.541179: step 1142, loss 1.04621, acc 0.859375, prec 0.0413898, recall 0.782552
2017-12-09T15:54:38.251640: step 1143, loss 0.57779, acc 0.828125, prec 0.0414401, recall 0.782835
2017-12-09T15:54:38.952160: step 1144, loss 1.38415, acc 0.84375, prec 0.0415577, recall 0.783398
2017-12-09T15:54:39.634653: step 1145, loss 4.44876, acc 0.828125, prec 0.0415764, recall 0.783031
2017-12-09T15:54:40.321503: step 1146, loss 0.620343, acc 0.84375, prec 0.0415621, recall 0.783031
2017-12-09T15:54:40.994079: step 1147, loss 0.594529, acc 0.796875, prec 0.0415435, recall 0.783031
2017-12-09T15:54:41.664705: step 1148, loss 0.725472, acc 0.828125, prec 0.0415278, recall 0.783031
2017-12-09T15:54:42.349931: step 1149, loss 1.33639, acc 0.734375, prec 0.0415365, recall 0.783172
2017-12-09T15:54:43.022297: step 1150, loss 0.612218, acc 0.84375, prec 0.0415223, recall 0.783172
2017-12-09T15:54:43.675792: step 1151, loss 0.563365, acc 0.8125, prec 0.041538, recall 0.783312
2017-12-09T15:54:44.325695: step 1152, loss 0.703156, acc 0.796875, prec 0.0415195, recall 0.783312
2017-12-09T15:54:44.977411: step 1153, loss 0.805264, acc 0.796875, prec 0.041501, recall 0.783312
2017-12-09T15:54:45.624569: step 1154, loss 0.872996, acc 0.765625, prec 0.0415125, recall 0.783452
2017-12-09T15:54:46.270664: step 1155, loss 0.647864, acc 0.78125, prec 0.0415255, recall 0.783592
2017-12-09T15:54:46.922787: step 1156, loss 0.636559, acc 0.8125, prec 0.0415084, recall 0.783592
2017-12-09T15:54:47.569507: step 1157, loss 0.411535, acc 0.84375, prec 0.0414942, recall 0.783592
2017-12-09T15:54:48.218215: step 1158, loss 0.731604, acc 0.734375, prec 0.0415356, recall 0.783871
2017-12-09T15:54:48.865484: step 1159, loss 0.57233, acc 0.875, prec 0.041557, recall 0.78401
2017-12-09T15:54:49.517253: step 1160, loss 0.582228, acc 0.8125, prec 0.0415727, recall 0.784149
2017-12-09T15:54:50.155544: step 1161, loss 0.448573, acc 0.84375, prec 0.0415585, recall 0.784149
2017-12-09T15:54:50.826293: step 1162, loss 0.745977, acc 0.890625, prec 0.041614, recall 0.784427
2017-12-09T15:54:51.470078: step 1163, loss 0.612167, acc 0.875, prec 0.0416681, recall 0.784704
2017-12-09T15:54:52.111136: step 1164, loss 1.4628, acc 0.875, prec 0.0416894, recall 0.784843
2017-12-09T15:54:52.744660: step 1165, loss 0.686413, acc 0.890625, prec 0.0417121, recall 0.784981
2017-12-09T15:54:53.389649: step 1166, loss 0.635525, acc 0.8125, prec 0.0416951, recall 0.784981
2017-12-09T15:54:54.080147: step 1167, loss 0.709043, acc 0.828125, prec 0.0417121, recall 0.785119
2017-12-09T15:54:54.742172: step 1168, loss 0.459553, acc 0.84375, prec 0.0416979, recall 0.785119
2017-12-09T15:54:55.394670: step 1169, loss 0.21121, acc 0.90625, prec 0.041722, recall 0.785256
2017-12-09T15:54:56.048847: step 1170, loss 0.658214, acc 0.796875, prec 0.0417362, recall 0.785394
2017-12-09T15:54:56.708810: step 1171, loss 0.895335, acc 0.90625, prec 0.0417603, recall 0.785531
2017-12-09T15:54:57.367450: step 1172, loss 0.326684, acc 0.921875, prec 0.0417532, recall 0.785531
2017-12-09T15:54:58.024349: step 1173, loss 0.273625, acc 0.90625, prec 0.0417446, recall 0.785531
2017-12-09T15:54:58.686071: step 1174, loss 0.37738, acc 0.859375, prec 0.0417644, recall 0.785669
2017-12-09T15:54:59.345049: step 1175, loss 0.15183, acc 0.96875, prec 0.0417616, recall 0.785669
2017-12-09T15:54:59.996124: step 1176, loss 6.72623, acc 0.859375, prec 0.0417502, recall 0.785166
2017-12-09T15:55:00.648285: step 1177, loss 0.240934, acc 0.90625, prec 0.0417417, recall 0.785166
2017-12-09T15:55:01.300620: step 1178, loss 0.486105, acc 0.890625, prec 0.0417644, recall 0.785304
2017-12-09T15:55:01.952536: step 1179, loss 1.39146, acc 0.875, prec 0.0417856, recall 0.785441
2017-12-09T15:55:02.585292: step 1180, loss 1.11497, acc 0.890625, prec 0.0418082, recall 0.785578
2017-12-09T15:55:03.217877: step 1181, loss 0.343377, acc 0.84375, prec 0.0418265, recall 0.785714
2017-12-09T15:55:03.843466: step 1182, loss 0.320906, acc 0.84375, prec 0.0418123, recall 0.785714
2017-12-09T15:55:04.472444: step 1183, loss 0.610186, acc 0.8125, prec 0.0417953, recall 0.785714
2017-12-09T15:55:05.124077: step 1184, loss 0.448044, acc 0.859375, prec 0.0417825, recall 0.785714
2017-12-09T15:55:05.755856: step 1185, loss 1.11958, acc 0.734375, prec 0.0418234, recall 0.785987
2017-12-09T15:55:06.384665: step 1186, loss 0.802207, acc 0.75, prec 0.0418657, recall 0.78626
2017-12-09T15:55:07.010458: step 1187, loss 0.942505, acc 0.765625, prec 0.0419417, recall 0.786667
2017-12-09T15:55:07.646217: step 1188, loss 0.846512, acc 0.75, prec 0.0419514, recall 0.786802
2017-12-09T15:55:08.300581: step 1189, loss 0.448805, acc 0.859375, prec 0.0419386, recall 0.786802
2017-12-09T15:55:08.948861: step 1190, loss 0.410612, acc 0.84375, prec 0.0419569, recall 0.786937
2017-12-09T15:55:09.598368: step 1191, loss 0.657218, acc 0.796875, prec 0.0419384, recall 0.786937
2017-12-09T15:55:10.245617: step 1192, loss 0.484493, acc 0.796875, prec 0.04192, recall 0.786937
2017-12-09T15:55:10.891614: step 1193, loss 0.388783, acc 0.875, prec 0.0419734, recall 0.787207
2017-12-09T15:55:11.542893: step 1194, loss 0.329874, acc 0.90625, prec 0.0420296, recall 0.787476
2017-12-09T15:55:12.218315: step 1195, loss 1.09994, acc 0.90625, prec 0.0420534, recall 0.787611
2017-12-09T15:55:12.872159: step 1196, loss 0.588987, acc 0.796875, prec 0.042035, recall 0.787611
2017-12-09T15:55:13.528665: step 1197, loss 1.22705, acc 0.8125, prec 0.0420502, recall 0.787745
2017-12-09T15:55:14.160654: step 1198, loss 0.398012, acc 0.8125, prec 0.0420332, recall 0.787745
2017-12-09T15:55:14.790823: step 1199, loss 0.408726, acc 0.84375, prec 0.0420514, recall 0.787879
2017-12-09T15:55:15.428344: step 1200, loss 0.723398, acc 0.796875, prec 0.0420329, recall 0.787879

Evaluation:
2017-12-09T15:56:12.866368: step 1200, loss 1.59656, acc 0.888291, prec 0.0437862, recall 0.7746

Saved model checkpoint to /Users/adb/Google Drive/Data Analytics/project/xtalkdb/Deep Learning/num_filter_128_fold_0/1512852011/checkpoints/model-1200

2017-12-09T15:56:14.603952: step 1201, loss 0.416852, acc 0.875, prec 0.0438676, recall 0.774986
2017-12-09T15:56:15.199613: step 1202, loss 0.35551, acc 0.890625, prec 0.0438886, recall 0.775114
2017-12-09T15:56:15.813960: step 1203, loss 0.19033, acc 0.921875, prec 0.0438815, recall 0.775114
2017-12-09T15:56:16.565412: step 1204, loss 0.269445, acc 0.90625, prec 0.043873, recall 0.775114
2017-12-09T15:56:17.193981: step 1205, loss 0.38704, acc 0.90625, prec 0.0438645, recall 0.775114
2017-12-09T15:56:17.812851: step 1206, loss 0.2643, acc 0.875, prec 0.0438531, recall 0.775114
2017-12-09T15:56:18.439252: step 1207, loss 0.131054, acc 0.953125, prec 0.0438489, recall 0.775114
2017-12-09T15:56:19.059416: step 1208, loss 0.311132, acc 0.859375, prec 0.0438361, recall 0.775114
2017-12-09T15:56:19.692040: step 1209, loss 8.47849, acc 0.875, prec 0.0438262, recall 0.774672
2017-12-09T15:56:20.346667: step 1210, loss 0.217085, acc 0.953125, prec 0.043822, recall 0.774672
2017-12-09T15:56:20.984670: step 1211, loss 0.991046, acc 0.90625, prec 0.0438444, recall 0.7748
2017-12-09T15:56:21.634566: step 1212, loss 0.256524, acc 0.953125, prec 0.043871, recall 0.774929
2017-12-09T15:56:22.281766: step 1213, loss 0.34741, acc 0.890625, prec 0.0438611, recall 0.774929
2017-12-09T15:56:22.924793: step 1214, loss 0.225, acc 0.921875, prec 0.0439157, recall 0.775185
2017-12-09T15:56:23.570659: step 1215, loss 2.22356, acc 0.84375, prec 0.0439337, recall 0.774872
2017-12-09T15:56:24.210464: step 1216, loss 6.45352, acc 0.875, prec 0.0439238, recall 0.774432
2017-12-09T15:56:24.877780: step 1217, loss 0.258008, acc 0.859375, prec 0.0439111, recall 0.774432
2017-12-09T15:56:25.544110: step 1218, loss 0.633859, acc 0.796875, prec 0.0438927, recall 0.774432
2017-12-09T15:56:26.219132: step 1219, loss 0.695434, acc 0.796875, prec 0.0439359, recall 0.774688
2017-12-09T15:56:26.909955: step 1220, loss 0.599632, acc 0.765625, prec 0.0439454, recall 0.774816
2017-12-09T15:56:27.591580: step 1221, loss 0.387841, acc 0.828125, prec 0.0439299, recall 0.774816
2017-12-09T15:56:28.268493: step 1222, loss 0.737382, acc 0.828125, prec 0.0439451, recall 0.774943
2017-12-09T15:56:28.937006: step 1223, loss 0.572429, acc 0.8125, prec 0.0439281, recall 0.774943
2017-12-09T15:56:29.602263: step 1224, loss 0.746811, acc 0.71875, prec 0.0439642, recall 0.775198
2017-12-09T15:56:30.270063: step 1225, loss 1.17783, acc 0.78125, prec 0.0440058, recall 0.775452
2017-12-09T15:56:30.927345: step 1226, loss 2.43854, acc 0.6875, prec 0.043979, recall 0.775014
2017-12-09T15:56:31.579873: step 1227, loss 0.67893, acc 0.703125, prec 0.0440135, recall 0.775268
2017-12-09T15:56:32.227357: step 1228, loss 0.652539, acc 0.703125, prec 0.0439867, recall 0.775268
2017-12-09T15:56:32.907425: step 1229, loss 0.712742, acc 0.78125, prec 0.0440588, recall 0.775648
2017-12-09T15:56:33.556704: step 1230, loss 0.8169, acc 0.75, prec 0.0440362, recall 0.775648
2017-12-09T15:56:34.222369: step 1231, loss 1.04283, acc 0.6875, prec 0.0440386, recall 0.775775
2017-12-09T15:56:34.881456: step 1232, loss 0.559906, acc 0.78125, prec 0.0440495, recall 0.775901
2017-12-09T15:56:35.520989: step 1233, loss 0.532298, acc 0.78125, prec 0.0440298, recall 0.775901
2017-12-09T15:56:36.156800: step 1234, loss 1.20409, acc 0.671875, prec 0.0440308, recall 0.776027
2017-12-09T15:56:36.803732: step 1235, loss 0.530977, acc 0.859375, prec 0.0440486, recall 0.776153
2017-12-09T15:56:37.450201: step 1236, loss 0.497874, acc 0.765625, prec 0.0440581, recall 0.776279
2017-12-09T15:56:38.112568: step 1237, loss 1.46579, acc 0.859375, prec 0.0440759, recall 0.776405
2017-12-09T15:56:38.772770: step 1238, loss 4.18638, acc 0.828125, prec 0.0440923, recall 0.776094
2017-12-09T15:56:39.441602: step 1239, loss 0.509548, acc 0.8125, prec 0.0441059, recall 0.77622
2017-12-09T15:56:40.096556: step 1240, loss 0.699217, acc 0.828125, prec 0.0441209, recall 0.776345
2017-12-09T15:56:40.764297: step 1241, loss 1.4414, acc 0.828125, prec 0.0441359, recall 0.776471
2017-12-09T15:56:41.443348: step 1242, loss 0.895904, acc 0.734375, prec 0.0441425, recall 0.776596
2017-12-09T15:56:42.120041: step 1243, loss 0.787899, acc 0.765625, prec 0.0442126, recall 0.77697
2017-12-09T15:56:42.780735: step 1244, loss 0.923421, acc 0.734375, prec 0.0441887, recall 0.77697
2017-12-09T15:56:43.438264: step 1245, loss 0.61072, acc 0.78125, prec 0.044169, recall 0.77697
2017-12-09T15:56:44.093049: step 1246, loss 0.649599, acc 0.796875, prec 0.0442722, recall 0.777468
2017-12-09T15:56:44.758042: step 1247, loss 0.88977, acc 0.71875, prec 0.0443076, recall 0.777716
2017-12-09T15:56:45.414460: step 1248, loss 0.414023, acc 0.84375, prec 0.0442936, recall 0.777716
2017-12-09T15:56:46.075731: step 1249, loss 0.815139, acc 0.78125, prec 0.0443042, recall 0.77784
2017-12-09T15:56:46.727498: step 1250, loss 0.742604, acc 0.796875, prec 0.0443162, recall 0.777963
2017-12-09T15:56:47.392887: step 1251, loss 0.531887, acc 0.796875, prec 0.044298, recall 0.777963
2017-12-09T15:56:48.027510: step 1252, loss 2.60684, acc 0.796875, prec 0.0443114, recall 0.777654
2017-12-09T15:56:48.665013: step 1253, loss 0.80736, acc 0.8125, prec 0.0443248, recall 0.777778
2017-12-09T15:56:49.297222: step 1254, loss 0.434234, acc 0.875, prec 0.0443741, recall 0.778024
2017-12-09T15:56:49.933894: step 1255, loss 0.830851, acc 0.78125, prec 0.0443545, recall 0.778024
2017-12-09T15:56:50.559840: step 1256, loss 0.423633, acc 0.859375, prec 0.0443721, recall 0.778148
2017-12-09T15:56:51.194045: step 1257, loss 0.837613, acc 0.8125, prec 0.0443552, recall 0.778148
2017-12-09T15:56:51.836274: step 1258, loss 0.501698, acc 0.875, prec 0.044344, recall 0.778148
2017-12-09T15:56:52.493369: step 1259, loss 1.08725, acc 0.765625, prec 0.0443532, recall 0.77827
2017-12-09T15:56:53.147100: step 1260, loss 1.53311, acc 0.890625, prec 0.0444037, recall 0.778516
2017-12-09T15:56:53.811426: step 1261, loss 0.63611, acc 0.78125, prec 0.0444143, recall 0.778639
2017-12-09T15:56:54.461896: step 1262, loss 0.601595, acc 0.75, prec 0.0443919, recall 0.778639
2017-12-09T15:56:55.115558: step 1263, loss 3.11921, acc 0.671875, prec 0.0444543, recall 0.778575
2017-12-09T15:56:55.770364: step 1264, loss 2.1734, acc 0.8125, prec 0.0444991, recall 0.77839
2017-12-09T15:56:56.454618: step 1265, loss 0.699723, acc 0.75, prec 0.0444766, recall 0.77839
2017-12-09T15:56:57.119248: step 1266, loss 0.412727, acc 0.84375, prec 0.0445228, recall 0.778634
2017-12-09T15:56:57.769994: step 1267, loss 0.699148, acc 0.8125, prec 0.0445361, recall 0.778756
2017-12-09T15:56:58.419698: step 1268, loss 0.671167, acc 0.6875, prec 0.0445682, recall 0.778999
2017-12-09T15:56:59.067070: step 1269, loss 0.541492, acc 0.875, prec 0.0445569, recall 0.778999
2017-12-09T15:56:59.715090: step 1270, loss 0.945767, acc 0.75, prec 0.0445946, recall 0.779242
2017-12-09T15:57:00.369517: step 1271, loss 0.369886, acc 0.84375, prec 0.0446106, recall 0.779363
2017-12-09T15:57:01.015915: step 1272, loss 0.568662, acc 0.796875, prec 0.0445924, recall 0.779363
2017-12-09T15:57:01.668741: step 1273, loss 0.408031, acc 0.828125, prec 0.044577, recall 0.779363
2017-12-09T15:57:02.319506: step 1274, loss 0.57866, acc 0.78125, prec 0.0445574, recall 0.779363
2017-12-09T15:57:02.972250: step 1275, loss 0.795004, acc 0.78125, prec 0.0445378, recall 0.779363
2017-12-09T15:57:03.601472: step 1276, loss 0.504899, acc 0.859375, prec 0.0445253, recall 0.779363
2017-12-09T15:57:04.232666: step 1277, loss 0.336425, acc 0.859375, prec 0.0445427, recall 0.779484
2017-12-09T15:57:04.860017: step 1278, loss 0.646787, acc 0.8125, prec 0.0445559, recall 0.779605
2017-12-09T15:57:05.493963: step 1279, loss 0.335265, acc 0.890625, prec 0.0445461, recall 0.779605
2017-12-09T15:57:06.122382: step 1280, loss 0.21157, acc 0.9375, prec 0.0445405, recall 0.779605
2017-12-09T15:57:06.753899: step 1281, loss 1.39083, acc 0.875, prec 0.0445307, recall 0.779178
2017-12-09T15:57:07.391626: step 1282, loss 1.27858, acc 0.9375, prec 0.0445266, recall 0.778751
2017-12-09T15:57:08.023080: step 1283, loss 0.330747, acc 0.90625, prec 0.0445481, recall 0.778872
2017-12-09T15:57:08.664811: step 1284, loss 0.242988, acc 0.9375, prec 0.0445425, recall 0.778872
2017-12-09T15:57:09.319508: step 1285, loss 0.214962, acc 0.9375, prec 0.0445369, recall 0.778872
2017-12-09T15:57:09.974218: step 1286, loss 0.154901, acc 0.90625, prec 0.0445286, recall 0.778872
2017-12-09T15:57:10.627955: step 1287, loss 0.28873, acc 0.9375, prec 0.044523, recall 0.778872
2017-12-09T15:57:11.282395: step 1288, loss 0.344553, acc 0.921875, prec 0.044516, recall 0.778872
2017-12-09T15:57:11.951419: step 1289, loss 1.06811, acc 0.984375, prec 0.0445744, recall 0.779114
2017-12-09T15:57:12.671371: step 1290, loss 0.19863, acc 0.921875, prec 0.0445973, recall 0.779235
2017-12-09T15:57:13.325295: step 1291, loss 1.46178, acc 0.84375, prec 0.0446147, recall 0.77893
2017-12-09T15:57:13.984983: step 1292, loss 0.226183, acc 0.921875, prec 0.0446077, recall 0.77893
2017-12-09T15:57:14.633831: step 1293, loss 0.302285, acc 0.84375, prec 0.0445938, recall 0.77893
2017-12-09T15:57:15.284421: step 1294, loss 0.511354, acc 0.8125, prec 0.0446367, recall 0.779171
2017-12-09T15:57:15.945566: step 1295, loss 2.04889, acc 0.84375, prec 0.0446242, recall 0.778747
2017-12-09T15:57:16.602461: step 1296, loss 0.567497, acc 0.84375, prec 0.0446401, recall 0.778867
2017-12-09T15:57:17.251142: step 1297, loss 1.63042, acc 0.890625, prec 0.0446913, recall 0.778684
2017-12-09T15:57:17.900922: step 1298, loss 0.614246, acc 0.859375, prec 0.0447682, recall 0.779045
2017-12-09T15:57:18.558303: step 1299, loss 0.634848, acc 0.765625, prec 0.0447771, recall 0.779164
2017-12-09T15:57:19.221040: step 1300, loss 0.57211, acc 0.875, prec 0.0447957, recall 0.779284
Saved model checkpoint to /Users/adb/Google Drive/Data Analytics/project/xtalkdb/Deep Learning/num_filter_128_fold_0/1512852011/checkpoints/model-1300

2017-12-09T15:57:20.661247: step 1301, loss 0.530501, acc 0.875, prec 0.0447845, recall 0.779284
2017-12-09T15:57:21.256011: step 1302, loss 2.26037, acc 0.875, prec 0.0448045, recall 0.778982
2017-12-09T15:57:21.893685: step 1303, loss 0.988286, acc 0.78125, prec 0.0448444, recall 0.779221
2017-12-09T15:57:22.500712: step 1304, loss 0.91719, acc 0.703125, prec 0.0448477, recall 0.77934
2017-12-09T15:57:23.113215: step 1305, loss 1.07087, acc 0.640625, prec 0.0449938, recall 0.780054
2017-12-09T15:57:23.739380: step 1306, loss 0.940149, acc 0.78125, prec 0.0449742, recall 0.780054
2017-12-09T15:57:24.368049: step 1307, loss 0.813283, acc 0.734375, prec 0.0449801, recall 0.780172
2017-12-09T15:57:24.996483: step 1308, loss 0.527011, acc 0.78125, prec 0.0449606, recall 0.780172
2017-12-09T15:57:25.618311: step 1309, loss 0.836176, acc 0.796875, prec 0.0449424, recall 0.780172
2017-12-09T15:57:26.240619: step 1310, loss 0.869407, acc 0.796875, prec 0.0449243, recall 0.780172
2017-12-09T15:57:26.873685: step 1311, loss 0.853562, acc 0.75, prec 0.0449316, recall 0.780291
2017-12-09T15:57:27.527497: step 1312, loss 1.06316, acc 0.78125, prec 0.0449417, recall 0.780409
2017-12-09T15:57:28.175399: step 1313, loss 0.706643, acc 0.71875, prec 0.0449167, recall 0.780409
2017-12-09T15:57:28.826120: step 1314, loss 0.770992, acc 0.796875, prec 0.0448986, recall 0.780409
2017-12-09T15:57:29.476328: step 1315, loss 0.460725, acc 0.859375, prec 0.0448861, recall 0.780409
2017-12-09T15:57:30.124895: step 1316, loss 0.605365, acc 0.78125, prec 0.0448962, recall 0.780527
2017-12-09T15:57:30.775170: step 1317, loss 0.582893, acc 0.8125, prec 0.0448795, recall 0.780527
2017-12-09T15:57:31.433613: step 1318, loss 0.463992, acc 0.859375, prec 0.0449261, recall 0.780763
2017-12-09T15:57:32.077285: step 1319, loss 0.216014, acc 0.953125, prec 0.0449219, recall 0.780763
2017-12-09T15:57:32.727627: step 1320, loss 0.503454, acc 0.84375, prec 0.0449376, recall 0.780881
2017-12-09T15:57:33.380175: step 1321, loss 1.34569, acc 0.875, prec 0.0449855, recall 0.781116
2017-12-09T15:57:34.034773: step 1322, loss 0.284025, acc 0.890625, prec 0.0450347, recall 0.78135
2017-12-09T15:57:34.692059: step 1323, loss 0.528719, acc 0.875, prec 0.0450531, recall 0.781468
2017-12-09T15:57:35.363717: step 1324, loss 2.91968, acc 0.9375, prec 0.0450489, recall 0.781049
2017-12-09T15:57:36.018758: step 1325, loss 2.44714, acc 0.828125, prec 0.0450645, recall 0.780749
2017-12-09T15:57:36.677660: step 1326, loss 0.21992, acc 0.875, prec 0.0450534, recall 0.780749
2017-12-09T15:57:37.342102: step 1327, loss 0.737692, acc 0.71875, prec 0.0450284, recall 0.780749
2017-12-09T15:57:38.003938: step 1328, loss 0.498031, acc 0.78125, prec 0.0450089, recall 0.780749
2017-12-09T15:57:38.661921: step 1329, loss 1.56675, acc 0.8125, prec 0.04511, recall 0.781217
2017-12-09T15:57:39.320000: step 1330, loss 0.479631, acc 0.796875, prec 0.0451508, recall 0.78145
2017-12-09T15:57:39.973501: step 1331, loss 0.447764, acc 0.78125, prec 0.0451313, recall 0.78145
2017-12-09T15:57:40.625206: step 1332, loss 0.351707, acc 0.84375, prec 0.0451762, recall 0.781683
2017-12-09T15:57:41.280064: step 1333, loss 3.16091, acc 0.8125, prec 0.0451609, recall 0.781267
2017-12-09T15:57:41.943447: step 1334, loss 0.577398, acc 0.75, prec 0.0451387, recall 0.781267
2017-12-09T15:57:42.595981: step 1335, loss 0.919968, acc 0.734375, prec 0.0451151, recall 0.781267
2017-12-09T15:57:43.247902: step 1336, loss 0.560736, acc 0.84375, prec 0.0451306, recall 0.781383
2017-12-09T15:57:43.899066: step 1337, loss 0.580473, acc 0.796875, prec 0.0451126, recall 0.781383
2017-12-09T15:57:44.558429: step 1338, loss 0.84301, acc 0.734375, prec 0.0451183, recall 0.781499
2017-12-09T15:57:45.215264: step 1339, loss 0.584663, acc 0.8125, prec 0.0451017, recall 0.781499
2017-12-09T15:57:45.862432: step 1340, loss 1.46923, acc 0.65625, prec 0.0451006, recall 0.781615
2017-12-09T15:57:46.512021: step 1341, loss 2.60405, acc 0.75, prec 0.0450798, recall 0.7812
2017-12-09T15:57:47.160995: step 1342, loss 0.427985, acc 0.875, prec 0.0450688, recall 0.7812
2017-12-09T15:57:47.809222: step 1343, loss 0.390166, acc 0.859375, prec 0.0450564, recall 0.7812
2017-12-09T15:57:48.455856: step 1344, loss 0.845636, acc 0.78125, prec 0.045037, recall 0.7812
2017-12-09T15:57:49.107411: step 1345, loss 0.608522, acc 0.828125, prec 0.0450511, recall 0.781316
2017-12-09T15:57:49.754920: step 1346, loss 0.685834, acc 0.75, prec 0.0450291, recall 0.781316
2017-12-09T15:57:50.429041: step 1347, loss 0.984563, acc 0.765625, prec 0.0450084, recall 0.781316
2017-12-09T15:57:51.089262: step 1348, loss 0.572542, acc 0.84375, prec 0.0449947, recall 0.781316
2017-12-09T15:57:51.752649: step 1349, loss 0.659523, acc 0.765625, prec 0.044974, recall 0.781316
2017-12-09T15:57:52.418254: step 1350, loss 0.38717, acc 0.859375, prec 0.0449617, recall 0.781316
2017-12-09T15:57:53.177878: step 1351, loss 0.982617, acc 0.75, prec 0.0449689, recall 0.781432
2017-12-09T15:57:53.824830: step 1352, loss 0.583151, acc 0.8125, prec 0.0450107, recall 0.781664
2017-12-09T15:57:54.469961: step 1353, loss 0.277593, acc 0.875, prec 0.0450288, recall 0.78178
2017-12-09T15:57:55.120155: step 1354, loss 0.380274, acc 0.828125, prec 0.0450137, recall 0.78178
2017-12-09T15:57:55.775294: step 1355, loss 1.12195, acc 0.84375, prec 0.0450291, recall 0.781895
2017-12-09T15:57:56.433409: step 1356, loss 0.459816, acc 0.875, prec 0.0450763, recall 0.782126
2017-12-09T15:57:57.083290: step 1357, loss 0.174983, acc 0.921875, prec 0.0450695, recall 0.782126
2017-12-09T15:57:57.775528: step 1358, loss 0.492479, acc 0.875, prec 0.0450876, recall 0.782241
2017-12-09T15:57:58.429297: step 1359, loss 0.304663, acc 0.890625, prec 0.045078, recall 0.782241
2017-12-09T15:57:59.077115: step 1360, loss 0.346097, acc 0.859375, prec 0.0450656, recall 0.782241
2017-12-09T15:57:59.727217: step 1361, loss 0.230289, acc 0.9375, prec 0.0450892, recall 0.782356
2017-12-09T15:58:00.387109: step 1362, loss 0.230868, acc 0.96875, prec 0.0452027, recall 0.782815
2017-12-09T15:58:01.042715: step 1363, loss 0.334164, acc 0.9375, prec 0.0451972, recall 0.782815
2017-12-09T15:58:01.696378: step 1364, loss 0.237547, acc 0.9375, prec 0.0451917, recall 0.782815
2017-12-09T15:58:02.350362: step 1365, loss 9.02469, acc 0.9375, prec 0.045218, recall 0.782105
2017-12-09T15:58:03.007613: step 1366, loss 0.140349, acc 0.9375, prec 0.0452125, recall 0.782105
2017-12-09T15:58:03.661992: step 1367, loss 0.319283, acc 0.890625, prec 0.0452029, recall 0.782105
2017-12-09T15:58:04.322780: step 1368, loss 2.10672, acc 0.859375, prec 0.04525, recall 0.781923
2017-12-09T15:58:04.981243: step 1369, loss 0.357771, acc 0.921875, prec 0.0452431, recall 0.781923
2017-12-09T15:58:05.638516: step 1370, loss 4.47567, acc 0.796875, prec 0.0452846, recall 0.781742
2017-12-09T15:58:06.299499: step 1371, loss 1.55058, acc 0.84375, prec 0.0453869, recall 0.782199
2017-12-09T15:58:06.960398: step 1372, loss 0.775642, acc 0.734375, prec 0.0453924, recall 0.782313
2017-12-09T15:58:07.610181: step 1373, loss 1.33463, acc 0.578125, prec 0.0453842, recall 0.782427
2017-12-09T15:58:08.272319: step 1374, loss 1.44585, acc 0.578125, prec 0.0454049, recall 0.782654
2017-12-09T15:58:08.924968: step 1375, loss 1.25872, acc 0.65625, prec 0.0454614, recall 0.782994
2017-12-09T15:58:09.576000: step 1376, loss 1.67685, acc 0.5625, prec 0.0454518, recall 0.783107
2017-12-09T15:58:10.224895: step 1377, loss 1.09542, acc 0.65625, prec 0.0454793, recall 0.783333
2017-12-09T15:58:10.872819: step 1378, loss 1.57603, acc 0.53125, prec 0.0454669, recall 0.783446
2017-12-09T15:58:11.533130: step 1379, loss 1.49014, acc 0.578125, prec 0.0455163, recall 0.783784
2017-12-09T15:58:12.206818: step 1380, loss 1.08093, acc 0.5625, prec 0.0454778, recall 0.783784
2017-12-09T15:58:12.865138: step 1381, loss 1.49556, acc 0.59375, prec 0.0454997, recall 0.784008
2017-12-09T15:58:13.518431: step 1382, loss 1.60353, acc 0.53125, prec 0.0454874, recall 0.78412
2017-12-09T15:58:14.177104: step 1383, loss 0.954252, acc 0.734375, prec 0.0454928, recall 0.784232
2017-12-09T15:58:14.833719: step 1384, loss 1.56321, acc 0.65625, prec 0.0455201, recall 0.784456
2017-12-09T15:58:15.485619: step 1385, loss 1.15993, acc 0.703125, prec 0.0455228, recall 0.784568
2017-12-09T15:58:16.135717: step 1386, loss 1.04473, acc 0.671875, prec 0.0455801, recall 0.784902
2017-12-09T15:58:16.785697: step 1387, loss 0.923217, acc 0.703125, prec 0.0455541, recall 0.784902
2017-12-09T15:58:17.444245: step 1388, loss 0.75329, acc 0.8125, prec 0.045595, recall 0.785124
2017-12-09T15:58:18.103556: step 1389, loss 0.527683, acc 0.8125, prec 0.0455786, recall 0.785124
2017-12-09T15:58:18.764383: step 1390, loss 0.592331, acc 0.90625, prec 0.045599, recall 0.785235
2017-12-09T15:58:19.420277: step 1391, loss 0.429157, acc 0.828125, prec 0.045584, recall 0.785235
2017-12-09T15:58:20.079083: step 1392, loss 0.473282, acc 0.828125, prec 0.0455975, recall 0.785346
2017-12-09T15:58:20.737934: step 1393, loss 5.36758, acc 0.78125, prec 0.0456084, recall 0.785052
2017-12-09T15:58:21.391832: step 1394, loss 0.155317, acc 0.9375, prec 0.0456315, recall 0.785162
2017-12-09T15:58:22.053964: step 1395, loss 0.381635, acc 0.8125, prec 0.0456436, recall 0.785273
2017-12-09T15:58:22.730616: step 1396, loss 0.581931, acc 0.875, prec 0.0456613, recall 0.785383
2017-12-09T15:58:23.378462: step 1397, loss 0.239827, acc 0.953125, prec 0.0456572, recall 0.785383
2017-12-09T15:58:24.031076: step 1398, loss 0.289629, acc 0.890625, prec 0.0456762, recall 0.785494
2017-12-09T15:58:24.679526: step 1399, loss 1.14142, acc 0.9375, prec 0.0456992, recall 0.785604
2017-12-09T15:58:25.338169: step 1400, loss 5.01942, acc 0.921875, prec 0.0457223, recall 0.785311
Saved model checkpoint to /Users/adb/Google Drive/Data Analytics/project/xtalkdb/Deep Learning/num_filter_128_fold_0/1512852011/checkpoints/model-1400

2017-12-09T15:58:26.798198: step 1401, loss 0.245918, acc 0.90625, prec 0.0457141, recall 0.785311
2017-12-09T15:58:27.402826: step 1402, loss 1.75218, acc 0.890625, prec 0.0457344, recall 0.785018
2017-12-09T15:58:28.039106: step 1403, loss 0.453336, acc 0.828125, prec 0.0457479, recall 0.785128
2017-12-09T15:58:28.657257: step 1404, loss 0.582062, acc 0.84375, prec 0.0457343, recall 0.785128
2017-12-09T15:58:29.288849: step 1405, loss 0.566781, acc 0.859375, prec 0.0458075, recall 0.785458
2017-12-09T15:58:29.921599: step 1406, loss 1.23454, acc 0.8125, prec 0.0458195, recall 0.785568
2017-12-09T15:58:30.551642: step 1407, loss 0.601559, acc 0.78125, prec 0.0458004, recall 0.785568
2017-12-09T15:58:31.196201: step 1408, loss 0.794251, acc 0.796875, prec 0.0457826, recall 0.785568
2017-12-09T15:58:31.854665: step 1409, loss 1.82469, acc 0.703125, prec 0.0457851, recall 0.785678
2017-12-09T15:58:32.518104: step 1410, loss 0.438559, acc 0.859375, prec 0.0457729, recall 0.785678
2017-12-09T15:58:33.172524: step 1411, loss 0.680474, acc 0.75, prec 0.0457511, recall 0.785678
2017-12-09T15:58:33.824821: step 1412, loss 0.439383, acc 0.875, prec 0.0457401, recall 0.785678
2017-12-09T15:58:34.483034: step 1413, loss 0.808142, acc 0.734375, prec 0.045717, recall 0.785678
2017-12-09T15:58:35.136014: step 1414, loss 0.554051, acc 0.78125, prec 0.045698, recall 0.785678
2017-12-09T15:58:35.786506: step 1415, loss 0.554464, acc 0.828125, prec 0.0457114, recall 0.785787
2017-12-09T15:58:36.445862: step 1416, loss 0.779777, acc 0.703125, prec 0.0457139, recall 0.785897
2017-12-09T15:58:37.099772: step 1417, loss 0.437824, acc 0.8125, prec 0.0456976, recall 0.785897
2017-12-09T15:58:37.759214: step 1418, loss 0.363284, acc 0.875, prec 0.0456868, recall 0.785897
2017-12-09T15:58:38.413366: step 1419, loss 0.534886, acc 0.8125, prec 0.0456705, recall 0.785897
2017-12-09T15:58:39.068652: step 1420, loss 0.419659, acc 0.90625, prec 0.0456624, recall 0.785897
2017-12-09T15:58:39.730509: step 1421, loss 0.614123, acc 0.765625, prec 0.045642, recall 0.785897
2017-12-09T15:58:40.386837: step 1422, loss 0.456307, acc 0.84375, prec 0.0456285, recall 0.785897
2017-12-09T15:58:41.035284: step 1423, loss 0.452853, acc 0.84375, prec 0.045615, recall 0.785897
2017-12-09T15:58:41.687913: step 1424, loss 0.28289, acc 0.921875, prec 0.0456365, recall 0.786006
2017-12-09T15:58:42.355999: step 1425, loss 0.449088, acc 0.875, prec 0.0456257, recall 0.786006
2017-12-09T15:58:43.005752: step 1426, loss 0.121783, acc 0.953125, prec 0.0456499, recall 0.786115
2017-12-09T15:58:43.657040: step 1427, loss 0.626548, acc 0.9375, prec 0.0457011, recall 0.786334
2017-12-09T15:58:44.312374: step 1428, loss 0.46601, acc 0.90625, prec 0.0457212, recall 0.786442
2017-12-09T15:58:44.992675: step 1429, loss 0.210082, acc 0.953125, prec 0.0457454, recall 0.786551
2017-12-09T15:58:45.652726: step 1430, loss 1.42022, acc 0.921875, prec 0.04574, recall 0.786151
2017-12-09T15:58:46.312804: step 1431, loss 0.440483, acc 0.953125, prec 0.0458207, recall 0.786477
2017-12-09T15:58:46.963265: step 1432, loss 0.349197, acc 0.921875, prec 0.0458422, recall 0.786585
2017-12-09T15:58:47.619249: step 1433, loss 0.0861715, acc 0.96875, prec 0.0458395, recall 0.786585
2017-12-09T15:58:48.264619: step 1434, loss 1.09032, acc 0.875, prec 0.0458569, recall 0.786694
2017-12-09T15:58:48.916161: step 1435, loss 0.313041, acc 0.84375, prec 0.0458433, recall 0.786694
2017-12-09T15:58:49.568869: step 1436, loss 0.835343, acc 0.90625, prec 0.0459481, recall 0.787126
2017-12-09T15:58:50.225066: step 1437, loss 0.127911, acc 0.953125, prec 0.0459723, recall 0.787234
2017-12-09T15:58:50.878020: step 1438, loss 1.75188, acc 0.828125, prec 0.0459587, recall 0.786835
2017-12-09T15:58:51.543416: step 1439, loss 0.681836, acc 0.921875, prec 0.0459801, recall 0.786943
2017-12-09T15:58:52.201804: step 1440, loss 0.596236, acc 0.890625, prec 0.0459988, recall 0.787051
2017-12-09T15:58:52.855168: step 1441, loss 0.396992, acc 0.84375, prec 0.0459852, recall 0.787051
2017-12-09T15:58:53.507823: step 1442, loss 0.363814, acc 0.890625, prec 0.0459757, recall 0.787051
2017-12-09T15:58:54.159580: step 1443, loss 0.348936, acc 0.890625, prec 0.0459943, recall 0.787159
2017-12-09T15:58:54.810050: step 1444, loss 0.457955, acc 0.828125, prec 0.0460076, recall 0.787266
2017-12-09T15:58:55.463564: step 1445, loss 0.780031, acc 0.8125, prec 0.0460194, recall 0.787374
2017-12-09T15:58:56.114385: step 1446, loss 0.486504, acc 0.84375, prec 0.0460058, recall 0.787374
2017-12-09T15:58:56.766882: step 1447, loss 0.383714, acc 0.84375, prec 0.0460204, recall 0.787481
2017-12-09T15:58:57.413471: step 1448, loss 0.446544, acc 0.875, prec 0.0460377, recall 0.787588
2017-12-09T15:58:58.066295: step 1449, loss 0.315776, acc 0.859375, prec 0.0460255, recall 0.787588
2017-12-09T15:58:58.732397: step 1450, loss 0.440669, acc 0.875, prec 0.0460146, recall 0.787588
2017-12-09T15:58:59.382508: step 1451, loss 0.4227, acc 0.890625, prec 0.0460051, recall 0.787588
2017-12-09T15:59:00.032046: step 1452, loss 0.426342, acc 0.875, prec 0.0460224, recall 0.787695
2017-12-09T15:59:00.681998: step 1453, loss 0.408329, acc 0.875, prec 0.0460115, recall 0.787695
2017-12-09T15:59:01.330524: step 1454, loss 0.829305, acc 0.765625, prec 0.0459912, recall 0.787695
2017-12-09T15:59:01.978645: step 1455, loss 3.46153, acc 0.84375, prec 0.045979, recall 0.787298
2017-12-09T15:59:02.624310: step 1456, loss 0.341246, acc 0.90625, prec 0.0460271, recall 0.787513
2017-12-09T15:59:03.280477: step 1457, loss 0.465064, acc 0.859375, prec 0.046043, recall 0.78762
2017-12-09T15:59:03.929962: step 1458, loss 0.277271, acc 0.90625, prec 0.0460348, recall 0.78762
2017-12-09T15:59:04.583526: step 1459, loss 0.22139, acc 0.9375, prec 0.0460575, recall 0.787726
2017-12-09T15:59:05.234933: step 1460, loss 2.52924, acc 0.8125, prec 0.0460426, recall 0.78733
2017-12-09T15:59:05.888016: step 1461, loss 0.131582, acc 0.9375, prec 0.0460372, recall 0.78733
2017-12-09T15:59:06.546937: step 1462, loss 0.357917, acc 0.875, prec 0.0460544, recall 0.787437
2017-12-09T15:59:07.196978: step 1463, loss 0.523663, acc 0.859375, prec 0.0460982, recall 0.787651
2017-12-09T15:59:07.850252: step 1464, loss 0.214702, acc 0.953125, prec 0.0460942, recall 0.787651
2017-12-09T15:59:08.498217: step 1465, loss 0.144939, acc 0.96875, prec 0.0460915, recall 0.787651
2017-12-09T15:59:09.150668: step 1466, loss 0.427992, acc 0.90625, prec 0.0461114, recall 0.787757
2017-12-09T15:59:09.802196: step 1467, loss 0.996171, acc 0.921875, prec 0.0461886, recall 0.788076
2017-12-09T15:59:10.455626: step 1468, loss 0.618371, acc 0.859375, prec 0.0462044, recall 0.788182
2017-12-09T15:59:11.103229: step 1469, loss 0.496648, acc 0.875, prec 0.0461936, recall 0.788182
2017-12-09T15:59:11.749092: step 1470, loss 0.543054, acc 0.875, prec 0.0462107, recall 0.788288
2017-12-09T15:59:12.419439: step 1471, loss 0.363101, acc 0.875, prec 0.0462558, recall 0.7885
2017-12-09T15:59:13.072687: step 1472, loss 1.96556, acc 0.8125, prec 0.0462409, recall 0.788106
2017-12-09T15:59:13.736108: step 1473, loss 0.255116, acc 0.90625, prec 0.0462607, recall 0.788212
2017-12-09T15:59:14.415575: step 1474, loss 0.59412, acc 0.875, prec 0.0463058, recall 0.788423
2017-12-09T15:59:15.096810: step 1475, loss 0.464257, acc 0.90625, prec 0.0463256, recall 0.788529
2017-12-09T15:59:15.771408: step 1476, loss 0.492509, acc 0.84375, prec 0.04634, recall 0.788634
2017-12-09T15:59:16.454339: step 1477, loss 0.44826, acc 0.890625, prec 0.0464142, recall 0.78895
2017-12-09T15:59:17.127115: step 1478, loss 0.28614, acc 0.890625, prec 0.0464047, recall 0.78895
2017-12-09T15:59:17.803315: step 1479, loss 0.198601, acc 0.890625, prec 0.0463952, recall 0.78895
2017-12-09T15:59:18.447857: step 1480, loss 0.350072, acc 0.890625, prec 0.0464136, recall 0.789055
2017-12-09T15:59:19.098217: step 1481, loss 0.548176, acc 0.8125, prec 0.0463973, recall 0.789055
2017-12-09T15:59:19.745740: step 1482, loss 0.422834, acc 0.859375, prec 0.046413, recall 0.78916
2017-12-09T15:59:20.390960: step 1483, loss 0.572369, acc 0.84375, prec 0.0464552, recall 0.789369
2017-12-09T15:59:21.034498: step 1484, loss 0.390642, acc 0.875, prec 0.0464443, recall 0.789369
2017-12-09T15:59:21.684477: step 1485, loss 0.435781, acc 0.875, prec 0.0464613, recall 0.789474
2017-12-09T15:59:22.334362: step 1486, loss 0.335952, acc 0.921875, prec 0.0464546, recall 0.789474
2017-12-09T15:59:22.978682: step 1487, loss 0.328846, acc 0.875, prec 0.0464437, recall 0.789474
2017-12-09T15:59:23.628711: step 1488, loss 0.20812, acc 0.9375, prec 0.0464661, recall 0.789578
2017-12-09T15:59:24.284341: step 1489, loss 0.17414, acc 0.9375, prec 0.0464885, recall 0.789683
2017-12-09T15:59:24.949966: step 1490, loss 0.234269, acc 0.921875, prec 0.0465096, recall 0.789787
2017-12-09T15:59:25.512704: step 1491, loss 1.19989, acc 0.921569, prec 0.046532, recall 0.789891
2017-12-09T15:59:26.188915: step 1492, loss 0.354543, acc 0.921875, prec 0.046553, recall 0.789995
2017-12-09T15:59:26.844045: step 1493, loss 0.167084, acc 0.90625, prec 0.0465449, recall 0.789995
2017-12-09T15:59:27.499272: step 1494, loss 0.664282, acc 0.796875, prec 0.046555, recall 0.790099
2017-12-09T15:59:28.153950: step 1495, loss 0.142893, acc 0.953125, prec 0.0465788, recall 0.790203
2017-12-09T15:59:28.848277: step 1496, loss 0.282118, acc 0.921875, prec 0.0465998, recall 0.790307
2017-12-09T15:59:29.506127: step 1497, loss 1.46259, acc 0.875, prec 0.0465903, recall 0.789916
2017-12-09T15:59:30.164215: step 1498, loss 0.203127, acc 0.9375, prec 0.0466126, recall 0.79002
2017-12-09T15:59:30.828991: step 1499, loss 0.196917, acc 0.953125, prec 0.0466641, recall 0.790227
2017-12-09T15:59:31.491517: step 1500, loss 0.446158, acc 0.9375, prec 0.0466865, recall 0.790331

Evaluation:
2017-12-09T16:00:23.224713: step 1500, loss 1.73699, acc 0.904708, prec 0.0482612, recall 0.779096

Saved model checkpoint to /Users/adb/Google Drive/Data Analytics/project/xtalkdb/Deep Learning/num_filter_128_fold_0/1512852011/checkpoints/model-1500

2017-12-09T16:00:25.081857: step 1501, loss 0.919173, acc 0.859375, prec 0.0483028, recall 0.779298
2017-12-09T16:00:25.699714: step 1502, loss 0.546227, acc 0.921875, prec 0.0483497, recall 0.779499
2017-12-09T16:00:26.334410: step 1503, loss 0.675384, acc 0.859375, prec 0.0483643, recall 0.779599
2017-12-09T16:00:26.954452: step 1504, loss 0.199666, acc 0.90625, prec 0.0483561, recall 0.779599
2017-12-09T16:00:27.584846: step 1505, loss 0.368546, acc 0.84375, prec 0.0483693, recall 0.7797
2017-12-09T16:00:28.229491: step 1506, loss 0.826788, acc 0.75, prec 0.0484281, recall 0.78
2017-12-09T16:00:28.881557: step 1507, loss 0.360005, acc 0.859375, prec 0.0484158, recall 0.78
2017-12-09T16:00:29.586658: step 1508, loss 0.42931, acc 0.859375, prec 0.0484035, recall 0.78
2017-12-09T16:00:30.256963: step 1509, loss 0.373954, acc 0.84375, prec 0.0483898, recall 0.78
2017-12-09T16:00:30.911980: step 1510, loss 0.216905, acc 0.921875, prec 0.0484098, recall 0.7801
2017-12-09T16:00:31.570278: step 1511, loss 0.425131, acc 0.859375, prec 0.0484244, recall 0.7802
2017-12-09T16:00:32.227195: step 1512, loss 0.467789, acc 0.859375, prec 0.0484389, recall 0.7803
2017-12-09T16:00:32.880515: step 1513, loss 0.300736, acc 0.890625, prec 0.0484294, recall 0.7803
2017-12-09T16:00:33.541511: step 1514, loss 0.355117, acc 0.859375, prec 0.0484171, recall 0.7803
2017-12-09T16:00:34.201010: step 1515, loss 0.213812, acc 0.921875, prec 0.0484103, recall 0.7803
2017-12-09T16:00:34.858039: step 1516, loss 0.310541, acc 0.9375, prec 0.0484048, recall 0.7803
2017-12-09T16:00:35.513688: step 1517, loss 0.208621, acc 0.921875, prec 0.048398, recall 0.7803
2017-12-09T16:00:36.168427: step 1518, loss 0.76668, acc 0.859375, prec 0.0484393, recall 0.780499
2017-12-09T16:00:36.824188: step 1519, loss 0.0513444, acc 0.96875, prec 0.0484366, recall 0.780499
2017-12-09T16:00:37.478166: step 1520, loss 0.303876, acc 0.9375, prec 0.0484847, recall 0.780698
2017-12-09T16:00:38.136591: step 1521, loss 0.263549, acc 0.921875, prec 0.0485314, recall 0.780896
2017-12-09T16:00:38.806746: step 1522, loss 0.189124, acc 0.953125, prec 0.0485273, recall 0.780896
2017-12-09T16:00:39.455161: step 1523, loss 0.210814, acc 0.953125, prec 0.0485232, recall 0.780896
2017-12-09T16:00:40.104324: step 1524, loss 0.26095, acc 0.921875, prec 0.0485431, recall 0.780995
2017-12-09T16:00:40.760143: step 1525, loss 0.123067, acc 0.921875, prec 0.0485363, recall 0.780995
2017-12-09T16:00:41.408934: step 1526, loss 0.0622488, acc 0.96875, prec 0.0485336, recall 0.780995
2017-12-09T16:00:42.077912: step 1527, loss 0.139799, acc 0.9375, prec 0.0485281, recall 0.780995
2017-12-09T16:00:42.739606: step 1528, loss 5.32551, acc 0.921875, prec 0.0485227, recall 0.780642
2017-12-09T16:00:43.450287: step 1529, loss 0.142718, acc 0.953125, prec 0.0485453, recall 0.780741
2017-12-09T16:00:44.132055: step 1530, loss 0.217315, acc 0.921875, prec 0.0485652, recall 0.780841
2017-12-09T16:00:44.799377: step 1531, loss 0.0780011, acc 0.984375, prec 0.0485639, recall 0.780841
2017-12-09T16:00:45.461353: step 1532, loss 0.166459, acc 0.9375, prec 0.0485852, recall 0.780939
2017-12-09T16:00:46.108617: step 1533, loss 0.142877, acc 0.9375, prec 0.0485797, recall 0.780939
2017-12-09T16:00:46.764197: step 1534, loss 1.14014, acc 0.96875, prec 0.0486304, recall 0.781137
2017-12-09T16:00:47.421589: step 1535, loss 0.117333, acc 0.96875, prec 0.0486544, recall 0.781236
2017-12-09T16:00:48.071672: step 1536, loss 3.45902, acc 0.9375, prec 0.0486503, recall 0.780884
2017-12-09T16:00:48.736650: step 1537, loss 0.147772, acc 0.984375, prec 0.048649, recall 0.780884
2017-12-09T16:00:49.398337: step 1538, loss 0.667179, acc 0.765625, prec 0.0486819, recall 0.781081
2017-12-09T16:00:50.052532: step 1539, loss 0.652445, acc 0.8125, prec 0.0486655, recall 0.781081
2017-12-09T16:00:50.706152: step 1540, loss 0.334873, acc 0.859375, prec 0.0486799, recall 0.78118
2017-12-09T16:00:51.379307: step 1541, loss 0.447526, acc 0.796875, prec 0.0486621, recall 0.78118
2017-12-09T16:00:52.040037: step 1542, loss 1.85213, acc 0.828125, prec 0.0486752, recall 0.780927
2017-12-09T16:00:52.699682: step 1543, loss 0.835586, acc 0.84375, prec 0.0487149, recall 0.781124
2017-12-09T16:00:53.354457: step 1544, loss 0.387837, acc 0.859375, prec 0.0487292, recall 0.781222
2017-12-09T16:00:54.053192: step 1545, loss 0.307669, acc 0.875, prec 0.0487183, recall 0.781222
2017-12-09T16:00:54.728801: step 1546, loss 0.587065, acc 0.734375, prec 0.0486951, recall 0.781222
2017-12-09T16:00:55.405881: step 1547, loss 0.632188, acc 0.78125, prec 0.048676, recall 0.781222
2017-12-09T16:00:56.086062: step 1548, loss 0.587798, acc 0.75, prec 0.0486542, recall 0.781222
2017-12-09T16:00:56.759732: step 1549, loss 0.565099, acc 0.8125, prec 0.0486645, recall 0.78132
2017-12-09T16:00:57.440623: step 1550, loss 0.754535, acc 0.8125, prec 0.0486482, recall 0.78132
2017-12-09T16:00:58.091385: step 1551, loss 0.637378, acc 0.8125, prec 0.0486585, recall 0.781418
2017-12-09T16:00:58.750899: step 1552, loss 0.623911, acc 0.78125, prec 0.048666, recall 0.781516
2017-12-09T16:00:59.403871: step 1553, loss 0.362779, acc 0.890625, prec 0.0486565, recall 0.781516
2017-12-09T16:01:00.059148: step 1554, loss 0.717012, acc 0.8125, prec 0.0486668, recall 0.781614
2017-12-09T16:01:00.711585: step 1555, loss 0.398001, acc 0.828125, prec 0.0486518, recall 0.781614
2017-12-09T16:01:01.364439: step 1556, loss 0.225853, acc 0.90625, prec 0.0486702, recall 0.781712
2017-12-09T16:01:02.012564: step 1557, loss 0.319696, acc 0.90625, prec 0.0486621, recall 0.781712
2017-12-09T16:01:02.659077: step 1558, loss 0.404497, acc 0.890625, prec 0.0486791, recall 0.78181
2017-12-09T16:01:03.309782: step 1559, loss 0.179773, acc 0.90625, prec 0.0486975, recall 0.781908
2017-12-09T16:01:03.959209: step 1560, loss 0.177146, acc 0.953125, prec 0.0486934, recall 0.781908
2017-12-09T16:01:04.603241: step 1561, loss 0.179983, acc 0.96875, prec 0.0487438, recall 0.782103
2017-12-09T16:01:05.250961: step 1562, loss 0.295401, acc 0.859375, prec 0.0487315, recall 0.782103
2017-12-09T16:01:05.902355: step 1563, loss 0.078356, acc 0.984375, prec 0.0487302, recall 0.782103
2017-12-09T16:01:06.558323: step 1564, loss 0.402002, acc 0.96875, prec 0.048754, recall 0.7822
2017-12-09T16:01:07.210758: step 1565, loss 0.186039, acc 0.953125, prec 0.0487499, recall 0.7822
2017-12-09T16:01:07.861598: step 1566, loss 4.09959, acc 0.890625, prec 0.0487417, recall 0.781851
2017-12-09T16:01:08.514529: step 1567, loss 0.290004, acc 0.90625, prec 0.0487866, recall 0.782046
2017-12-09T16:01:09.162035: step 1568, loss 0.507601, acc 0.9375, prec 0.0488077, recall 0.782143
2017-12-09T16:01:09.819488: step 1569, loss 0.228951, acc 0.859375, prec 0.0487954, recall 0.782143
2017-12-09T16:01:10.467317: step 1570, loss 1.2268, acc 0.9375, prec 0.0488695, recall 0.782434
2017-12-09T16:01:11.141172: step 1571, loss 0.305054, acc 0.875, prec 0.0489115, recall 0.782628
2017-12-09T16:01:11.799579: step 1572, loss 0.803941, acc 0.96875, prec 0.0489882, recall 0.782918
2017-12-09T16:01:12.477411: step 1573, loss 0.43136, acc 0.875, prec 0.0489773, recall 0.782918
2017-12-09T16:01:13.138510: step 1574, loss 0.240745, acc 0.890625, prec 0.0489678, recall 0.782918
2017-12-09T16:01:13.793651: step 1575, loss 0.208931, acc 0.9375, prec 0.0490152, recall 0.783111
2017-12-09T16:01:14.448298: step 1576, loss 0.366145, acc 0.890625, prec 0.0490057, recall 0.783111
2017-12-09T16:01:15.098523: step 1577, loss 0.401511, acc 0.859375, prec 0.0490463, recall 0.783304
2017-12-09T16:01:15.759080: step 1578, loss 0.828287, acc 0.84375, prec 0.0490591, recall 0.7834
2017-12-09T16:01:16.409787: step 1579, loss 0.327315, acc 0.875, prec 0.0490482, recall 0.7834
2017-12-09T16:01:17.065906: step 1580, loss 0.304481, acc 0.890625, prec 0.0490387, recall 0.7834
2017-12-09T16:01:17.727093: step 1581, loss 0.520885, acc 0.84375, prec 0.0490515, recall 0.783496
2017-12-09T16:01:18.385667: step 1582, loss 0.330899, acc 0.953125, prec 0.0490738, recall 0.783592
2017-12-09T16:01:19.050692: step 1583, loss 0.912646, acc 0.90625, prec 0.0491184, recall 0.783784
2017-12-09T16:01:19.711969: step 1584, loss 0.38031, acc 0.84375, prec 0.0491312, recall 0.78388
2017-12-09T16:01:20.367626: step 1585, loss 0.415575, acc 0.828125, prec 0.0491426, recall 0.783975
2017-12-09T16:01:21.023323: step 1586, loss 0.640873, acc 0.796875, prec 0.0491249, recall 0.783975
2017-12-09T16:01:21.674744: step 1587, loss 0.100864, acc 0.96875, prec 0.0491221, recall 0.783975
2017-12-09T16:01:22.334783: step 1588, loss 0.523915, acc 0.859375, prec 0.0491362, recall 0.784071
2017-12-09T16:01:22.988866: step 1589, loss 0.531768, acc 0.84375, prec 0.049149, recall 0.784166
2017-12-09T16:01:23.645811: step 1590, loss 0.152865, acc 0.953125, prec 0.0491712, recall 0.784262
2017-12-09T16:01:24.295229: step 1591, loss 0.565199, acc 0.828125, prec 0.0491826, recall 0.784357
2017-12-09T16:01:24.946638: step 1592, loss 0.271032, acc 0.90625, prec 0.0491744, recall 0.784357
2017-12-09T16:01:25.592688: step 1593, loss 0.532867, acc 0.875, prec 0.0491899, recall 0.784452
2017-12-09T16:01:26.257323: step 1594, loss 0.225427, acc 0.921875, prec 0.0491831, recall 0.784452
2017-12-09T16:01:26.913034: step 1595, loss 0.392577, acc 0.875, prec 0.0491722, recall 0.784452
2017-12-09T16:01:27.560054: step 1596, loss 0.809111, acc 0.96875, prec 0.0491958, recall 0.784547
2017-12-09T16:01:28.208994: step 1597, loss 0.279025, acc 0.875, prec 0.0492375, recall 0.784738
2017-12-09T16:01:28.858570: step 1598, loss 0.608172, acc 0.90625, prec 0.0493082, recall 0.785022
2017-12-09T16:01:29.515349: step 1599, loss 1.13861, acc 0.953125, prec 0.0493568, recall 0.785211
2017-12-09T16:01:30.170174: step 1600, loss 0.327687, acc 0.84375, prec 0.0493431, recall 0.785211
Saved model checkpoint to /Users/adb/Google Drive/Data Analytics/project/xtalkdb/Deep Learning/num_filter_128_fold_0/1512852011/checkpoints/model-1600

2017-12-09T16:01:31.662827: step 1601, loss 0.242576, acc 0.9375, prec 0.0493639, recall 0.785306
2017-12-09T16:01:32.274514: step 1602, loss 2.33904, acc 0.90625, prec 0.0493834, recall 0.785055
2017-12-09T16:01:32.883848: step 1603, loss 0.502981, acc 0.90625, prec 0.0494278, recall 0.785244
2017-12-09T16:01:33.495697: step 1604, loss 0.383, acc 0.84375, prec 0.0494141, recall 0.785244
2017-12-09T16:01:34.110922: step 1605, loss 0.480384, acc 0.890625, prec 0.0494308, recall 0.785338
2017-12-09T16:01:34.741656: step 1606, loss 0.333018, acc 0.828125, prec 0.049442, recall 0.785432
2017-12-09T16:01:35.362659: step 1607, loss 0.51282, acc 0.875, prec 0.0494574, recall 0.785526
2017-12-09T16:01:35.991602: step 1608, loss 0.547294, acc 0.796875, prec 0.0494659, recall 0.78562
2017-12-09T16:01:36.628843: step 1609, loss 0.640029, acc 0.796875, prec 0.0494744, recall 0.785714
2017-12-09T16:01:37.267095: step 1610, loss 0.406699, acc 0.84375, prec 0.0494869, recall 0.785808
2017-12-09T16:01:37.914810: step 1611, loss 0.391857, acc 0.859375, prec 0.0494746, recall 0.785808
2017-12-09T16:01:38.564058: step 1612, loss 0.577289, acc 0.8125, prec 0.0495107, recall 0.785996
2017-12-09T16:01:39.211265: step 1613, loss 0.326015, acc 0.890625, prec 0.0495273, recall 0.786089
2017-12-09T16:01:39.856713: step 1614, loss 0.611208, acc 0.78125, prec 0.0495344, recall 0.786183
2017-12-09T16:01:40.504389: step 1615, loss 0.443732, acc 0.828125, prec 0.0495194, recall 0.786183
2017-12-09T16:01:41.155744: step 1616, loss 0.776404, acc 0.84375, prec 0.0495319, recall 0.786276
2017-12-09T16:01:41.810323: step 1617, loss 0.475597, acc 0.875, prec 0.049521, recall 0.786276
2017-12-09T16:01:42.478667: step 1618, loss 0.550496, acc 0.8125, prec 0.0495308, recall 0.78637
2017-12-09T16:01:43.132602: step 1619, loss 0.180895, acc 0.921875, prec 0.049524, recall 0.78637
2017-12-09T16:01:43.785464: step 1620, loss 0.33276, acc 0.859375, prec 0.0495118, recall 0.78637
2017-12-09T16:01:44.430020: step 1621, loss 0.262193, acc 0.890625, prec 0.0495284, recall 0.786463
2017-12-09T16:01:45.075537: step 1622, loss 1.13949, acc 0.921875, prec 0.0495477, recall 0.786556
2017-12-09T16:01:45.737181: step 1623, loss 0.250752, acc 0.921875, prec 0.0495409, recall 0.786556
2017-12-09T16:01:46.390217: step 1624, loss 0.248063, acc 0.96875, prec 0.0495643, recall 0.786649
2017-12-09T16:01:47.045231: step 1625, loss 0.260627, acc 0.953125, prec 0.0496124, recall 0.786835
2017-12-09T16:01:47.692454: step 1626, loss 2.28567, acc 0.921875, prec 0.0496592, recall 0.786678
2017-12-09T16:01:48.339076: step 1627, loss 0.348234, acc 0.90625, prec 0.0497033, recall 0.786864
2017-12-09T16:01:48.989316: step 1628, loss 0.383696, acc 0.875, prec 0.0497184, recall 0.786957
2017-12-09T16:01:49.645782: step 1629, loss 0.156861, acc 0.953125, prec 0.0497665, recall 0.787142
2017-12-09T16:01:50.295507: step 1630, loss 0.690116, acc 0.90625, prec 0.0498105, recall 0.787326
2017-12-09T16:01:50.961377: step 1631, loss 0.505955, acc 0.953125, prec 0.0498325, recall 0.787419
2017-12-09T16:01:51.641924: step 1632, loss 0.245285, acc 0.90625, prec 0.0498243, recall 0.787419
2017-12-09T16:01:52.324375: step 1633, loss 0.803997, acc 0.765625, prec 0.0498559, recall 0.787603
2017-12-09T16:01:52.988208: step 1634, loss 0.52718, acc 0.828125, prec 0.0498409, recall 0.787603
2017-12-09T16:01:53.646036: step 1635, loss 0.577717, acc 0.8125, prec 0.0498245, recall 0.787603
2017-12-09T16:01:54.346371: step 1636, loss 0.508031, acc 0.859375, prec 0.0498383, recall 0.787695
2017-12-09T16:01:55.025092: step 1637, loss 0.31063, acc 0.84375, prec 0.0499027, recall 0.787971
2017-12-09T16:01:55.697644: step 1638, loss 0.220623, acc 0.9375, prec 0.0499493, recall 0.788154
2017-12-09T16:01:56.372483: step 1639, loss 0.366414, acc 0.859375, prec 0.049937, recall 0.788154
2017-12-09T16:01:57.045804: step 1640, loss 0.342304, acc 0.90625, prec 0.0499288, recall 0.788154
2017-12-09T16:01:57.730222: step 1641, loss 0.396304, acc 0.859375, prec 0.0499685, recall 0.788337
2017-12-09T16:01:58.406261: step 1642, loss 0.227556, acc 0.875, prec 0.0500096, recall 0.78852
2017-12-09T16:01:59.117376: step 1643, loss 0.537598, acc 0.828125, prec 0.0500205, recall 0.788611
2017-12-09T16:01:59.799180: step 1644, loss 0.211062, acc 0.890625, prec 0.0500109, recall 0.788611
2017-12-09T16:02:00.457275: step 1645, loss 0.46379, acc 0.859375, prec 0.0499986, recall 0.788611
2017-12-09T16:02:01.143342: step 1646, loss 0.313416, acc 0.921875, prec 0.0499918, recall 0.788611
2017-12-09T16:02:01.800103: step 1647, loss 0.390665, acc 0.9375, prec 0.0500123, recall 0.788702
2017-12-09T16:02:02.452770: step 1648, loss 0.200958, acc 0.921875, prec 0.0500055, recall 0.788702
2017-12-09T16:02:03.102073: step 1649, loss 0.201693, acc 0.90625, prec 0.0499973, recall 0.788702
2017-12-09T16:02:03.747209: step 1650, loss 0.468541, acc 0.9375, prec 0.0500178, recall 0.788793
2017-12-09T16:02:04.406622: step 1651, loss 0.441122, acc 0.90625, prec 0.0500615, recall 0.788975
2017-12-09T16:02:05.054251: step 1652, loss 0.142392, acc 0.96875, prec 0.0501107, recall 0.789157
2017-12-09T16:02:05.688036: step 1653, loss 0.079081, acc 0.96875, prec 0.0501079, recall 0.789157
2017-12-09T16:02:06.320774: step 1654, loss 0.299942, acc 0.90625, prec 0.0500997, recall 0.789157
2017-12-09T16:02:06.955844: step 1655, loss 0.783925, acc 0.953125, prec 0.0501475, recall 0.789338
2017-12-09T16:02:07.591788: step 1656, loss 0.580054, acc 0.90625, prec 0.0501652, recall 0.789428
2017-12-09T16:02:08.226488: step 1657, loss 0.277369, acc 0.921875, prec 0.0502102, recall 0.789609
2017-12-09T16:02:08.864167: step 1658, loss 0.144693, acc 0.921875, prec 0.0502034, recall 0.789609
2017-12-09T16:02:09.501246: step 1659, loss 0.906247, acc 0.9375, prec 0.0502238, recall 0.7897
2017-12-09T16:02:10.136336: step 1660, loss 1.85201, acc 0.921875, prec 0.0502443, recall 0.789451
2017-12-09T16:02:10.775430: step 1661, loss 0.360115, acc 0.9375, prec 0.0502647, recall 0.789541
2017-12-09T16:02:11.402503: step 1662, loss 3.4207, acc 0.9375, prec 0.0502606, recall 0.789203
2017-12-09T16:02:12.047995: step 1663, loss 0.219987, acc 0.890625, prec 0.050251, recall 0.789203
2017-12-09T16:02:12.684981: step 1664, loss 0.445728, acc 0.84375, prec 0.0502891, recall 0.789384
2017-12-09T16:02:13.325039: step 1665, loss 0.269196, acc 0.9375, prec 0.0502836, recall 0.789384
2017-12-09T16:02:13.958972: step 1666, loss 0.899267, acc 0.875, prec 0.0503244, recall 0.789564
2017-12-09T16:02:14.621644: step 1667, loss 0.405637, acc 0.828125, prec 0.0503352, recall 0.789654
2017-12-09T16:02:15.262620: step 1668, loss 1.39793, acc 0.828125, prec 0.0503719, recall 0.789833
2017-12-09T16:02:15.904177: step 1669, loss 0.449975, acc 0.8125, prec 0.0503813, recall 0.789923
2017-12-09T16:02:16.509501: step 1670, loss 0.564731, acc 0.8125, prec 0.0503648, recall 0.789923
2017-12-09T16:02:17.116962: step 1671, loss 0.515043, acc 0.78125, prec 0.0503456, recall 0.789923
2017-12-09T16:02:17.723234: step 1672, loss 1.00155, acc 0.8125, prec 0.0503808, recall 0.790102
2017-12-09T16:02:18.345819: step 1673, loss 1.88853, acc 0.796875, prec 0.0504405, recall 0.790371
2017-12-09T16:02:18.956787: step 1674, loss 0.849478, acc 0.65625, prec 0.0504103, recall 0.790371
2017-12-09T16:02:19.561209: step 1675, loss 1.00335, acc 0.703125, prec 0.0504359, recall 0.790549
2017-12-09T16:02:20.168440: step 1676, loss 1.02704, acc 0.640625, prec 0.0504044, recall 0.790549
2017-12-09T16:02:20.779197: step 1677, loss 2.13407, acc 0.75, prec 0.0504354, recall 0.790391
2017-12-09T16:02:21.390326: step 1678, loss 0.804182, acc 0.8125, prec 0.0504448, recall 0.79048
2017-12-09T16:02:22.001030: step 1679, loss 1.20982, acc 0.609375, prec 0.0504621, recall 0.790658
2017-12-09T16:02:22.604627: step 1680, loss 0.930739, acc 0.75, prec 0.0504402, recall 0.790658
2017-12-09T16:02:23.208174: step 1681, loss 0.53565, acc 0.75, prec 0.0504183, recall 0.790658
2017-12-09T16:02:23.815965: step 1682, loss 0.746283, acc 0.71875, prec 0.0503938, recall 0.790658
2017-12-09T16:02:24.426492: step 1683, loss 1.13683, acc 0.625, prec 0.0503868, recall 0.790747
2017-12-09T16:02:25.038496: step 1684, loss 0.792467, acc 0.734375, prec 0.0504149, recall 0.790924
2017-12-09T16:02:25.646577: step 1685, loss 0.99551, acc 0.71875, prec 0.0504417, recall 0.791102
2017-12-09T16:02:26.257501: step 1686, loss 0.573281, acc 0.796875, prec 0.050424, recall 0.791102
2017-12-09T16:02:26.861988: step 1687, loss 0.495133, acc 0.84375, prec 0.050436, recall 0.79119
2017-12-09T16:02:27.453206: step 1688, loss 3.96269, acc 0.828125, prec 0.0504224, recall 0.790855
2017-12-09T16:02:28.048375: step 1689, loss 0.466695, acc 0.796875, prec 0.0504047, recall 0.790855
2017-12-09T16:02:28.637768: step 1690, loss 0.563944, acc 0.828125, prec 0.0504154, recall 0.790944
2017-12-09T16:02:29.231374: step 1691, loss 0.175624, acc 0.921875, prec 0.0504342, recall 0.791032
2017-12-09T16:02:29.819939: step 1692, loss 2.79049, acc 0.796875, prec 0.0504435, recall 0.790786
2017-12-09T16:02:30.407702: step 1693, loss 0.604307, acc 0.859375, prec 0.0504569, recall 0.790875
2017-12-09T16:02:30.996372: step 1694, loss 0.422407, acc 0.84375, prec 0.0504689, recall 0.790963
2017-12-09T16:02:31.606893: step 1695, loss 0.390192, acc 0.84375, prec 0.0504553, recall 0.790963
2017-12-09T16:02:32.191779: step 1696, loss 0.683961, acc 0.78125, prec 0.0504362, recall 0.790963
2017-12-09T16:02:32.782370: step 1697, loss 0.653859, acc 0.78125, prec 0.0504683, recall 0.791139
2017-12-09T16:02:33.376431: step 1698, loss 0.46933, acc 0.859375, prec 0.0504561, recall 0.791139
2017-12-09T16:02:33.972100: step 1699, loss 0.317728, acc 0.90625, prec 0.0504735, recall 0.791227
2017-12-09T16:02:34.557307: step 1700, loss 0.699983, acc 0.796875, prec 0.0504814, recall 0.791315
Saved model checkpoint to /Users/adb/Google Drive/Data Analytics/project/xtalkdb/Deep Learning/num_filter_128_fold_0/1512852011/checkpoints/model-1700

2017-12-09T16:02:35.928269: step 1701, loss 0.321701, acc 0.90625, prec 0.0504988, recall 0.791403
2017-12-09T16:02:36.492362: step 1702, loss 0.355253, acc 0.84375, prec 0.0505363, recall 0.791579
2017-12-09T16:02:37.055069: step 1703, loss 0.437522, acc 0.890625, prec 0.0505268, recall 0.791579
2017-12-09T16:02:37.612477: step 1704, loss 0.453231, acc 0.84375, prec 0.0505132, recall 0.791579
2017-12-09T16:02:38.167629: step 1705, loss 0.31913, acc 0.890625, prec 0.0505292, recall 0.791667
2017-12-09T16:02:38.735198: step 1706, loss 0.383338, acc 0.828125, prec 0.0505398, recall 0.791754
2017-12-09T16:02:39.311497: step 1707, loss 0.353366, acc 0.90625, prec 0.0505316, recall 0.791754
2017-12-09T16:02:39.882569: step 1708, loss 0.92524, acc 0.890625, prec 0.0505476, recall 0.791842
2017-12-09T16:02:40.458393: step 1709, loss 0.19805, acc 0.921875, prec 0.0505408, recall 0.791842
2017-12-09T16:02:41.032165: step 1710, loss 0.81812, acc 0.921875, prec 0.0506105, recall 0.792104
2017-12-09T16:02:41.602333: step 1711, loss 0.178301, acc 0.9375, prec 0.0506305, recall 0.792191
2017-12-09T16:02:42.184861: step 1712, loss 0.197537, acc 0.9375, prec 0.0506506, recall 0.792279
2017-12-09T16:02:42.762266: step 1713, loss 0.288005, acc 0.921875, prec 0.0506438, recall 0.792279
2017-12-09T16:02:43.335360: step 1714, loss 1.76791, acc 0.96875, prec 0.0506424, recall 0.791946
2017-12-09T16:02:43.916285: step 1715, loss 0.204533, acc 0.9375, prec 0.0506624, recall 0.792034
2017-12-09T16:02:44.487658: step 1716, loss 0.21311, acc 0.90625, prec 0.0506798, recall 0.792121
2017-12-09T16:02:45.062975: step 1717, loss 0.328003, acc 0.859375, prec 0.0506675, recall 0.792121
2017-12-09T16:02:45.632002: step 1718, loss 0.193635, acc 0.953125, prec 0.0506634, recall 0.792121
2017-12-09T16:02:46.208181: step 1719, loss 0.379495, acc 0.953125, prec 0.0507103, recall 0.792295
2017-12-09T16:02:46.784020: step 1720, loss 0.336364, acc 0.953125, prec 0.0507316, recall 0.792382
2017-12-09T16:02:47.357099: step 1721, loss 0.261365, acc 0.90625, prec 0.0507235, recall 0.792382
2017-12-09T16:02:47.933386: step 1722, loss 0.657081, acc 0.890625, prec 0.0507394, recall 0.792469
2017-12-09T16:02:48.507727: step 1723, loss 0.273643, acc 0.875, prec 0.0507539, recall 0.792555
2017-12-09T16:02:49.079097: step 1724, loss 0.145832, acc 0.96875, prec 0.0507766, recall 0.792642
2017-12-09T16:02:49.651370: step 1725, loss 0.2274, acc 0.90625, prec 0.0507939, recall 0.792729
2017-12-09T16:02:50.227692: step 1726, loss 0.390008, acc 0.890625, prec 0.0508098, recall 0.792815
2017-12-09T16:02:50.803930: step 1727, loss 0.301458, acc 0.90625, prec 0.050827, recall 0.792902
2017-12-09T16:02:51.368459: step 1728, loss 0.626515, acc 0.921875, prec 0.050871, recall 0.793075
2017-12-09T16:02:51.944205: step 1729, loss 0.433167, acc 0.859375, prec 0.0508842, recall 0.793161
2017-12-09T16:02:52.524205: step 1730, loss 0.359772, acc 0.921875, prec 0.0509028, recall 0.793247
2017-12-09T16:02:53.090262: step 1731, loss 0.229124, acc 0.921875, prec 0.050896, recall 0.793247
2017-12-09T16:02:53.656910: step 1732, loss 0.323409, acc 0.875, prec 0.0508851, recall 0.793247
2017-12-09T16:02:54.222002: step 1733, loss 0.354177, acc 0.875, prec 0.0508996, recall 0.793333
2017-12-09T16:02:54.792057: step 1734, loss 0.337283, acc 0.875, prec 0.0508887, recall 0.793333
2017-12-09T16:02:55.368368: step 1735, loss 0.246455, acc 0.890625, prec 0.0508792, recall 0.793333
2017-12-09T16:02:55.944196: step 1736, loss 0.611796, acc 0.875, prec 0.0508936, recall 0.793419
2017-12-09T16:02:56.529009: step 1737, loss 0.189331, acc 0.921875, prec 0.0508868, recall 0.793419
2017-12-09T16:02:57.099825: step 1738, loss 0.122324, acc 0.96875, prec 0.0509095, recall 0.793505
2017-12-09T16:02:57.665137: step 1739, loss 0.283797, acc 0.921875, prec 0.0509534, recall 0.793677
2017-12-09T16:02:58.231129: step 1740, loss 0.31014, acc 0.890625, prec 0.0509439, recall 0.793677
2017-12-09T16:02:58.804714: step 1741, loss 1.10642, acc 0.96875, prec 0.0509918, recall 0.793849
2017-12-09T16:02:59.373776: step 1742, loss 0.188891, acc 0.9375, prec 0.0509864, recall 0.793849
2017-12-09T16:02:59.937932: step 1743, loss 0.229143, acc 0.9375, prec 0.0510062, recall 0.793934
2017-12-09T16:03:00.501953: step 1744, loss 1.12989, acc 0.96875, prec 0.0510795, recall 0.794191
2017-12-09T16:03:01.067536: step 1745, loss 0.151232, acc 0.921875, prec 0.051098, recall 0.794276
2017-12-09T16:03:01.666446: step 1746, loss 0.17056, acc 0.96875, prec 0.0510953, recall 0.794276
2017-12-09T16:03:02.235110: step 1747, loss 0.531336, acc 0.9375, prec 0.0511151, recall 0.794362
2017-12-09T16:03:02.806134: step 1748, loss 0.117628, acc 0.9375, prec 0.0511097, recall 0.794362
2017-12-09T16:03:03.377751: step 1749, loss 0.187197, acc 0.9375, prec 0.0511295, recall 0.794447
2017-12-09T16:03:03.944723: step 1750, loss 0.0661596, acc 0.984375, prec 0.0511282, recall 0.794447
2017-12-09T16:03:04.526905: step 1751, loss 0.238517, acc 0.90625, prec 0.05112, recall 0.794447
2017-12-09T16:03:05.121329: step 1752, loss 0.291128, acc 0.859375, prec 0.0511077, recall 0.794447
2017-12-09T16:03:05.698076: step 1753, loss 0.374055, acc 0.828125, prec 0.0510928, recall 0.794447
2017-12-09T16:03:06.255286: step 1754, loss 0.557133, acc 0.828125, prec 0.0510778, recall 0.794447
2017-12-09T16:03:06.823858: step 1755, loss 0.304411, acc 0.859375, prec 0.0511161, recall 0.794617
2017-12-09T16:03:07.392668: step 1756, loss 1.80639, acc 0.953125, prec 0.0512131, recall 0.794957
2017-12-09T16:03:07.959117: step 1757, loss 0.314438, acc 0.890625, prec 0.0512035, recall 0.794957
2017-12-09T16:03:08.526198: step 1758, loss 0.462234, acc 0.84375, prec 0.0512909, recall 0.795295
2017-12-09T16:03:09.096607: step 1759, loss 1.63012, acc 0.890625, prec 0.0513319, recall 0.795464
2017-12-09T16:03:09.669595: step 1760, loss 0.315154, acc 0.90625, prec 0.0513237, recall 0.795464
2017-12-09T16:03:10.238497: step 1761, loss 2.23839, acc 0.90625, prec 0.0513673, recall 0.795305
2017-12-09T16:03:10.808985: step 1762, loss 0.574372, acc 0.796875, prec 0.0513496, recall 0.795305
2017-12-09T16:03:11.371520: step 1763, loss 0.495173, acc 0.828125, prec 0.0513345, recall 0.795305
2017-12-09T16:03:11.931461: step 1764, loss 0.214383, acc 0.921875, prec 0.0513277, recall 0.795305
2017-12-09T16:03:12.519537: step 1765, loss 0.534977, acc 0.796875, prec 0.05131, recall 0.795305
2017-12-09T16:03:13.089523: step 1766, loss 0.358254, acc 0.84375, prec 0.0512964, recall 0.795305
2017-12-09T16:03:13.658747: step 1767, loss 0.629481, acc 0.796875, prec 0.0512786, recall 0.795305
2017-12-09T16:03:14.236857: step 1768, loss 0.943793, acc 0.734375, prec 0.0512555, recall 0.795305
2017-12-09T16:03:14.830159: step 1769, loss 0.626287, acc 0.78125, prec 0.0512616, recall 0.795389
2017-12-09T16:03:15.402122: step 1770, loss 0.509198, acc 0.765625, prec 0.0513167, recall 0.795641
2017-12-09T16:03:15.976695: step 1771, loss 0.673152, acc 0.765625, prec 0.0512963, recall 0.795641
2017-12-09T16:03:16.552230: step 1772, loss 0.414706, acc 0.890625, prec 0.051312, recall 0.795725
2017-12-09T16:03:17.123526: step 1773, loss 0.416367, acc 0.875, prec 0.0513011, recall 0.795725
2017-12-09T16:03:17.701579: step 1774, loss 0.760108, acc 0.90625, prec 0.0513432, recall 0.795893
2017-12-09T16:03:18.281507: step 1775, loss 0.537233, acc 0.828125, prec 0.0513534, recall 0.795977
2017-12-09T16:03:18.849908: step 1776, loss 0.494061, acc 0.84375, prec 0.0513649, recall 0.796061
2017-12-09T16:03:19.430771: step 1777, loss 0.484104, acc 0.890625, prec 0.0513805, recall 0.796144
2017-12-09T16:03:20.013741: step 1778, loss 0.983111, acc 0.84375, prec 0.0514422, recall 0.796395
2017-12-09T16:03:20.605696: step 1779, loss 0.301836, acc 0.921875, prec 0.0514605, recall 0.796478
2017-12-09T16:03:21.190549: step 1780, loss 1.11989, acc 0.921875, prec 0.0514788, recall 0.796562
2017-12-09T16:03:21.780173: step 1781, loss 0.257703, acc 0.921875, prec 0.0515221, recall 0.796728
2017-12-09T16:03:22.366104: step 1782, loss 0.388656, acc 0.875, prec 0.0515363, recall 0.796811
2017-12-09T16:03:22.955419: step 1783, loss 0.292326, acc 0.875, prec 0.0515254, recall 0.796811
2017-12-09T16:03:23.547079: step 1784, loss 0.271597, acc 0.875, prec 0.0515145, recall 0.796811
2017-12-09T16:03:24.132133: step 1785, loss 0.306167, acc 0.90625, prec 0.0515063, recall 0.796811
2017-12-09T16:03:24.718906: step 1786, loss 0.433782, acc 0.875, prec 0.0514955, recall 0.796811
2017-12-09T16:03:25.311293: step 1787, loss 0.595809, acc 0.796875, prec 0.0515028, recall 0.796894
2017-12-09T16:03:25.901851: step 1788, loss 0.147793, acc 0.96875, prec 0.0515001, recall 0.796894
2017-12-09T16:03:26.494841: step 1789, loss 0.256786, acc 0.859375, prec 0.051538, recall 0.79706
2017-12-09T16:03:27.080731: step 1790, loss 0.168345, acc 0.890625, prec 0.0515284, recall 0.79706
2017-12-09T16:03:27.665962: step 1791, loss 0.306339, acc 0.90625, prec 0.0515203, recall 0.79706
2017-12-09T16:03:28.254636: step 1792, loss 0.234299, acc 0.90625, prec 0.0515121, recall 0.79706
2017-12-09T16:03:28.844951: step 1793, loss 0.103196, acc 0.984375, prec 0.0515358, recall 0.797143
2017-12-09T16:03:29.436144: step 1794, loss 0.127896, acc 0.96875, prec 0.0515331, recall 0.797143
2017-12-09T16:03:30.021655: step 1795, loss 1.73171, acc 0.96875, prec 0.0516304, recall 0.797473
2017-12-09T16:03:30.619192: step 1796, loss 0.160449, acc 0.90625, prec 0.0516473, recall 0.797556
2017-12-09T16:03:31.211235: step 1797, loss 0.139714, acc 0.921875, prec 0.0516655, recall 0.797638
2017-12-09T16:03:31.812134: step 1798, loss 0.183074, acc 0.921875, prec 0.0516587, recall 0.797638
2017-12-09T16:03:32.397175: step 1799, loss 0.583443, acc 0.890625, prec 0.0516741, recall 0.797721
2017-12-09T16:03:32.981373: step 1800, loss 0.345986, acc 0.890625, prec 0.0516896, recall 0.797803

Evaluation:
2017-12-09T16:04:19.407629: step 1800, loss 2.20623, acc 0.938768, prec 0.0531306, recall 0.782227

Saved model checkpoint to /Users/adb/Google Drive/Data Analytics/project/xtalkdb/Deep Learning/num_filter_128_fold_0/1512852011/checkpoints/model-1800

2017-12-09T16:04:21.082265: step 1801, loss 0.247302, acc 0.921875, prec 0.0531237, recall 0.782227
2017-12-09T16:04:21.650583: step 1802, loss 0.690282, acc 0.875, prec 0.0531617, recall 0.782393
2017-12-09T16:04:22.217715: step 1803, loss 0.330998, acc 0.921875, prec 0.0531794, recall 0.782476
2017-12-09T16:04:22.793660: step 1804, loss 0.206094, acc 0.921875, prec 0.0531725, recall 0.782476
2017-12-09T16:04:23.366764: step 1805, loss 0.253391, acc 0.9375, prec 0.0531915, recall 0.782559
2017-12-09T16:04:23.940879: step 1806, loss 0.410027, acc 0.96875, prec 0.0532622, recall 0.782807
2017-12-09T16:04:24.527869: step 1807, loss 0.132189, acc 0.96875, prec 0.053284, recall 0.78289
2017-12-09T16:04:25.114402: step 1808, loss 0.163484, acc 0.921875, prec 0.0532771, recall 0.78289
2017-12-09T16:04:25.720597: step 1809, loss 0.152896, acc 0.953125, prec 0.0532975, recall 0.782972
2017-12-09T16:04:26.294489: step 1810, loss 0.274897, acc 0.875, prec 0.0532864, recall 0.782972
2017-12-09T16:04:26.872892: step 1811, loss 0.109279, acc 0.953125, prec 0.0533068, recall 0.783055
2017-12-09T16:04:27.459560: step 1812, loss 0.385222, acc 0.890625, prec 0.0533461, recall 0.783219
2017-12-09T16:04:28.042952: step 1813, loss 0.636365, acc 0.953125, prec 0.0533909, recall 0.783384
2017-12-09T16:04:28.655160: step 1814, loss 0.363534, acc 0.875, prec 0.0533799, recall 0.783384
2017-12-09T16:04:29.236466: step 1815, loss 0.471513, acc 0.84375, prec 0.0533905, recall 0.783466
2017-12-09T16:04:29.816127: step 1816, loss 0.189533, acc 0.9375, prec 0.053385, recall 0.783466
2017-12-09T16:04:30.406344: step 1817, loss 0.930582, acc 0.921875, prec 0.053427, recall 0.78363
2017-12-09T16:04:30.994734: step 1818, loss 0.208553, acc 0.9375, prec 0.053446, recall 0.783712
2017-12-09T16:04:31.580141: step 1819, loss 0.271563, acc 0.90625, prec 0.0534377, recall 0.783712
2017-12-09T16:04:32.162706: step 1820, loss 0.451341, acc 0.96875, prec 0.0534594, recall 0.783794
2017-12-09T16:04:32.747704: step 1821, loss 0.166214, acc 0.90625, prec 0.0534755, recall 0.783876
2017-12-09T16:04:33.340474: step 1822, loss 1.18016, acc 0.953125, prec 0.0534728, recall 0.783579
2017-12-09T16:04:33.929388: step 1823, loss 0.27499, acc 0.921875, prec 0.0534903, recall 0.783661
2017-12-09T16:04:34.507914: step 1824, loss 0.16419, acc 0.921875, prec 0.0534834, recall 0.783661
2017-12-09T16:04:35.090623: step 1825, loss 0.175809, acc 0.9375, prec 0.0535023, recall 0.783743
2017-12-09T16:04:35.682548: step 1826, loss 0.202451, acc 0.9375, prec 0.0534968, recall 0.783743
2017-12-09T16:04:36.299447: step 1827, loss 0.401619, acc 0.875, prec 0.0534857, recall 0.783743
2017-12-09T16:04:36.892419: step 1828, loss 0.814833, acc 0.859375, prec 0.0535221, recall 0.783906
2017-12-09T16:04:37.494911: step 1829, loss 0.343687, acc 0.90625, prec 0.0535383, recall 0.783988
2017-12-09T16:04:38.091062: step 1830, loss 0.159747, acc 0.921875, prec 0.0535558, recall 0.784069
2017-12-09T16:04:38.685161: step 1831, loss 0.391279, acc 0.90625, prec 0.0535475, recall 0.784069
2017-12-09T16:04:39.281192: step 1832, loss 0.160823, acc 0.96875, prec 0.0535691, recall 0.784151
2017-12-09T16:04:39.878161: step 1833, loss 0.269361, acc 0.921875, prec 0.0535622, recall 0.784151
2017-12-09T16:04:40.465057: step 1834, loss 0.199805, acc 0.9375, prec 0.0536055, recall 0.784314
2017-12-09T16:04:41.053388: step 1835, loss 0.163872, acc 0.921875, prec 0.0536717, recall 0.784557
2017-12-09T16:04:41.640314: step 1836, loss 0.312566, acc 0.9375, prec 0.0536906, recall 0.784639
2017-12-09T16:04:42.265326: step 1837, loss 0.377405, acc 0.890625, prec 0.0537053, recall 0.78472
2017-12-09T16:04:42.848271: step 1838, loss 0.235022, acc 0.921875, prec 0.0536984, recall 0.78472
2017-12-09T16:04:43.439046: step 1839, loss 0.340228, acc 0.921875, prec 0.0537402, recall 0.784882
2017-12-09T16:04:44.028034: step 1840, loss 0.109407, acc 0.9375, prec 0.053759, recall 0.784962
2017-12-09T16:04:44.611346: step 1841, loss 0.216736, acc 0.9375, prec 0.0537535, recall 0.784962
2017-12-09T16:04:45.206812: step 1842, loss 1.16349, acc 0.890625, prec 0.0537925, recall 0.785124
2017-12-09T16:04:45.799552: step 1843, loss 0.204005, acc 0.90625, prec 0.0537842, recall 0.785124
2017-12-09T16:04:46.389086: step 1844, loss 0.360941, acc 0.859375, prec 0.0537961, recall 0.785205
2017-12-09T16:04:46.985865: step 1845, loss 4.08755, acc 0.953125, prec 0.0538177, recall 0.784991
2017-12-09T16:04:47.577230: step 1846, loss 0.186058, acc 0.9375, prec 0.0538365, recall 0.785071
2017-12-09T16:04:48.166592: step 1847, loss 0.108088, acc 0.9375, prec 0.0538553, recall 0.785152
2017-12-09T16:04:48.757763: step 1848, loss 0.0847815, acc 0.96875, prec 0.0538525, recall 0.785152
2017-12-09T16:04:49.349880: step 1849, loss 0.208961, acc 0.9375, prec 0.0538956, recall 0.785313
2017-12-09T16:04:49.943344: step 1850, loss 0.433369, acc 0.890625, prec 0.0539102, recall 0.785393
2017-12-09T16:04:50.538165: step 1851, loss 0.501583, acc 0.90625, prec 0.0539262, recall 0.785474
2017-12-09T16:04:51.133251: step 1852, loss 0.245293, acc 0.90625, prec 0.0539179, recall 0.785474
2017-12-09T16:04:51.782980: step 1853, loss 0.311148, acc 0.875, prec 0.0539311, recall 0.785554
2017-12-09T16:04:52.389536: step 1854, loss 0.259809, acc 0.859375, prec 0.0539187, recall 0.785554
2017-12-09T16:04:52.984737: step 1855, loss 0.674376, acc 0.890625, prec 0.0539576, recall 0.785714
2017-12-09T16:04:53.581618: step 1856, loss 0.639475, acc 0.890625, prec 0.0539722, recall 0.785794
2017-12-09T16:04:54.182119: step 1857, loss 1.47897, acc 0.875, prec 0.0540097, recall 0.785954
2017-12-09T16:04:54.778261: step 1858, loss 0.468825, acc 0.84375, prec 0.0540201, recall 0.786034
2017-12-09T16:04:55.372917: step 1859, loss 0.305381, acc 0.890625, prec 0.0540346, recall 0.786114
2017-12-09T16:04:55.995245: step 1860, loss 0.441738, acc 0.8125, prec 0.0540423, recall 0.786194
2017-12-09T16:04:56.606012: step 1861, loss 0.459771, acc 0.8125, prec 0.0540256, recall 0.786194
2017-12-09T16:04:57.196408: step 1862, loss 0.612742, acc 0.78125, prec 0.054079, recall 0.786433
2017-12-09T16:04:57.782605: step 1863, loss 0.767617, acc 0.8125, prec 0.0541351, recall 0.786672
2017-12-09T16:04:58.374377: step 1864, loss 0.382255, acc 0.875, prec 0.0541482, recall 0.786751
2017-12-09T16:04:58.966962: step 1865, loss 0.379044, acc 0.875, prec 0.0541613, recall 0.78683
2017-12-09T16:04:59.559900: step 1866, loss 0.535162, acc 0.875, prec 0.0541745, recall 0.78691
2017-12-09T16:05:00.159242: step 1867, loss 0.252675, acc 0.921875, prec 0.0541675, recall 0.78691
2017-12-09T16:05:00.753559: step 1868, loss 0.297535, acc 0.890625, prec 0.0541578, recall 0.78691
2017-12-09T16:05:01.341939: step 1869, loss 0.244481, acc 0.90625, prec 0.0541737, recall 0.786989
2017-12-09T16:05:01.969669: step 1870, loss 0.255482, acc 0.9375, prec 0.0542408, recall 0.787226
2017-12-09T16:05:02.585300: step 1871, loss 0.26584, acc 0.90625, prec 0.0542324, recall 0.787226
2017-12-09T16:05:03.237225: step 1872, loss 0.904835, acc 0.953125, prec 0.0542525, recall 0.787305
2017-12-09T16:05:03.933151: step 1873, loss 0.40927, acc 0.796875, prec 0.0542344, recall 0.787305
2017-12-09T16:05:04.541065: step 1874, loss 0.244466, acc 0.921875, prec 0.0542275, recall 0.787305
2017-12-09T16:05:05.177917: step 1875, loss 0.28575, acc 0.921875, prec 0.0542447, recall 0.787384
2017-12-09T16:05:05.787915: step 1876, loss 0.452923, acc 0.921875, prec 0.0542862, recall 0.787542
2017-12-09T16:05:06.405853: step 1877, loss 0.120712, acc 0.953125, prec 0.054282, recall 0.787542
2017-12-09T16:05:06.996741: step 1878, loss 0.123517, acc 0.953125, prec 0.0542778, recall 0.787542
2017-12-09T16:05:07.587442: step 1879, loss 2.0627, acc 0.875, prec 0.0542923, recall 0.787329
2017-12-09T16:05:08.250884: step 1880, loss 0.423742, acc 0.890625, prec 0.0542826, recall 0.787329
2017-12-09T16:05:08.871646: step 1881, loss 0.140828, acc 0.9375, prec 0.054277, recall 0.787329
2017-12-09T16:05:09.534919: step 1882, loss 5.66711, acc 0.859375, prec 0.0543398, recall 0.786982
2017-12-09T16:05:10.129179: step 1883, loss 0.686932, acc 0.953125, prec 0.054408, recall 0.787218
2017-12-09T16:05:10.715653: step 1884, loss 0.443057, acc 0.828125, prec 0.0543928, recall 0.787218
2017-12-09T16:05:11.311538: step 1885, loss 1.64205, acc 0.890625, prec 0.0544086, recall 0.787006
2017-12-09T16:05:11.902337: step 1886, loss 0.5662, acc 0.78125, prec 0.0543891, recall 0.787006
2017-12-09T16:05:12.505743: step 1887, loss 0.515419, acc 0.78125, prec 0.0544662, recall 0.78732
2017-12-09T16:05:13.102563: step 1888, loss 0.950376, acc 0.703125, prec 0.0545362, recall 0.787633
2017-12-09T16:05:13.690672: step 1889, loss 0.733008, acc 0.734375, prec 0.0545367, recall 0.787712
2017-12-09T16:05:14.279597: step 1890, loss 1.09178, acc 0.671875, prec 0.0545075, recall 0.787712
2017-12-09T16:05:14.872353: step 1891, loss 0.865905, acc 0.625, prec 0.0544742, recall 0.787712
2017-12-09T16:05:15.458858: step 1892, loss 1.02697, acc 0.578125, prec 0.0544609, recall 0.78779
2017-12-09T16:05:16.035777: step 1893, loss 0.92815, acc 0.59375, prec 0.0544489, recall 0.787868
2017-12-09T16:05:16.629879: step 1894, loss 0.965187, acc 0.65625, prec 0.0544425, recall 0.787946
2017-12-09T16:05:17.204812: step 1895, loss 0.895442, acc 0.65625, prec 0.0544361, recall 0.788024
2017-12-09T16:05:17.794082: step 1896, loss 0.681959, acc 0.71875, prec 0.0544112, recall 0.788024
2017-12-09T16:05:18.370806: step 1897, loss 0.975018, acc 0.625, prec 0.0544021, recall 0.788101
2017-12-09T16:05:18.952365: step 1898, loss 0.58555, acc 0.78125, prec 0.0544068, recall 0.788179
2017-12-09T16:05:19.532160: step 1899, loss 0.467212, acc 0.75, prec 0.0543847, recall 0.788179
2017-12-09T16:05:20.121786: step 1900, loss 0.34642, acc 0.90625, prec 0.0543765, recall 0.788179
Saved model checkpoint to /Users/adb/Google Drive/Data Analytics/project/xtalkdb/Deep Learning/num_filter_128_fold_0/1512852011/checkpoints/model-1900

2017-12-09T16:05:21.541661: step 1901, loss 0.404404, acc 0.890625, prec 0.0543908, recall 0.788257
2017-12-09T16:05:22.110718: step 1902, loss 0.440434, acc 0.828125, prec 0.0543756, recall 0.788257
2017-12-09T16:05:22.691712: step 1903, loss 0.308068, acc 0.890625, prec 0.054366, recall 0.788257
2017-12-09T16:05:23.265468: step 1904, loss 0.26684, acc 0.890625, prec 0.0543803, recall 0.788335
2017-12-09T16:05:23.840589: step 1905, loss 0.407242, acc 0.84375, prec 0.0544144, recall 0.78849
2017-12-09T16:05:24.418933: step 1906, loss 0.152015, acc 0.953125, prec 0.0544342, recall 0.788567
2017-12-09T16:05:24.998134: step 1907, loss 1.26023, acc 0.921875, prec 0.0544512, recall 0.788645
2017-12-09T16:05:25.577927: step 1908, loss 1.21971, acc 0.9375, prec 0.0545174, recall 0.788877
2017-12-09T16:05:26.212468: step 1909, loss 0.589089, acc 0.953125, prec 0.0545372, recall 0.788954
2017-12-09T16:05:26.811424: step 1910, loss 0.186903, acc 0.96875, prec 0.0545344, recall 0.788954
2017-12-09T16:05:27.394983: step 1911, loss 0.235507, acc 0.890625, prec 0.0545487, recall 0.789031
2017-12-09T16:05:27.973984: step 1912, loss 0.632972, acc 0.921875, prec 0.0545657, recall 0.789108
2017-12-09T16:05:28.559330: step 1913, loss 0.045366, acc 1, prec 0.0545657, recall 0.789108
2017-12-09T16:05:29.155922: step 1914, loss 0.365717, acc 0.875, prec 0.0545546, recall 0.789108
2017-12-09T16:05:29.753239: step 1915, loss 0.34475, acc 0.953125, prec 0.0545983, recall 0.789262
2017-12-09T16:05:30.351782: step 1916, loss 0.110141, acc 0.96875, prec 0.0545955, recall 0.789262
2017-12-09T16:05:30.950536: step 1917, loss 0.169038, acc 0.9375, prec 0.05459, recall 0.789262
2017-12-09T16:05:31.556222: step 1918, loss 0.399525, acc 0.90625, prec 0.0546295, recall 0.789416
2017-12-09T16:05:32.150717: step 1919, loss 0.234275, acc 0.890625, prec 0.0546198, recall 0.789416
2017-12-09T16:05:32.735496: step 1920, loss 0.289569, acc 0.921875, prec 0.0546129, recall 0.789416
2017-12-09T16:05:33.340631: step 1921, loss 0.342732, acc 0.90625, prec 0.0546285, recall 0.789493
2017-12-09T16:05:33.952895: step 1922, loss 0.20546, acc 0.9375, prec 0.054623, recall 0.789493
2017-12-09T16:05:34.566125: step 1923, loss 0.185619, acc 0.921875, prec 0.0546161, recall 0.789493
2017-12-09T16:05:35.179956: step 1924, loss 0.217914, acc 0.90625, prec 0.0546079, recall 0.789493
2017-12-09T16:05:35.808781: step 1925, loss 1.18449, acc 0.921875, prec 0.0546248, recall 0.78957
2017-12-09T16:05:36.425003: step 1926, loss 0.388531, acc 0.890625, prec 0.0546867, recall 0.7898
2017-12-09T16:05:37.023010: step 1927, loss 0.168011, acc 0.9375, prec 0.0547289, recall 0.789953
2017-12-09T16:05:37.622764: step 1928, loss 0.296898, acc 0.84375, prec 0.0547151, recall 0.789953
2017-12-09T16:05:38.212193: step 1929, loss 0.0839153, acc 0.984375, prec 0.0547137, recall 0.789953
2017-12-09T16:05:38.809488: step 1930, loss 0.130411, acc 0.96875, prec 0.0547348, recall 0.790029
2017-12-09T16:05:39.399545: step 1931, loss 0.135932, acc 0.953125, prec 0.0547306, recall 0.790029
2017-12-09T16:05:39.996459: step 1932, loss 0.236852, acc 0.921875, prec 0.0547476, recall 0.790106
2017-12-09T16:05:40.599818: step 1933, loss 0.185241, acc 0.90625, prec 0.0547393, recall 0.790106
2017-12-09T16:05:41.197746: step 1934, loss 0.216186, acc 0.921875, prec 0.0547324, recall 0.790106
2017-12-09T16:05:41.803477: step 1935, loss 1.0469, acc 0.90625, prec 0.0547479, recall 0.790182
2017-12-09T16:05:42.462781: step 1936, loss 0.212538, acc 0.9375, prec 0.0547662, recall 0.790258
2017-12-09T16:05:43.057510: step 1937, loss 1.31147, acc 0.828125, prec 0.0547749, recall 0.790334
2017-12-09T16:05:43.652909: step 1938, loss 0.11699, acc 0.9375, prec 0.0547693, recall 0.790334
2017-12-09T16:05:44.250742: step 1939, loss 0.116133, acc 0.953125, prec 0.0547652, recall 0.790334
2017-12-09T16:05:44.840730: step 1940, loss 0.333443, acc 0.875, prec 0.054778, recall 0.79041
2017-12-09T16:05:45.432381: step 1941, loss 0.190009, acc 0.953125, prec 0.0547976, recall 0.790487
2017-12-09T16:05:46.022270: step 1942, loss 1.87577, acc 0.890625, prec 0.0547893, recall 0.7902
2017-12-09T16:05:46.617307: step 1943, loss 0.196036, acc 0.96875, prec 0.0548104, recall 0.790276
2017-12-09T16:05:47.192576: step 1944, loss 0.301667, acc 0.84375, prec 0.0547966, recall 0.790276
2017-12-09T16:05:47.769387: step 1945, loss 0.216134, acc 0.90625, prec 0.0548359, recall 0.790428
2017-12-09T16:05:48.352500: step 1946, loss 0.325085, acc 0.90625, prec 0.0548276, recall 0.790428
2017-12-09T16:05:48.928391: step 1947, loss 0.200327, acc 0.953125, prec 0.0548235, recall 0.790428
2017-12-09T16:05:49.508586: step 1948, loss 0.362653, acc 0.890625, prec 0.0548138, recall 0.790428
2017-12-09T16:05:50.098143: step 1949, loss 0.398497, acc 0.875, prec 0.0548265, recall 0.790504
2017-12-09T16:05:50.794473: step 1950, loss 0.472123, acc 0.890625, prec 0.0548644, recall 0.790656
2017-12-09T16:05:51.396822: step 1951, loss 0.368917, acc 0.859375, prec 0.054852, recall 0.790656
2017-12-09T16:05:51.991392: step 1952, loss 0.501471, acc 0.796875, prec 0.0548341, recall 0.790656
2017-12-09T16:05:52.584356: step 1953, loss 0.36328, acc 0.875, prec 0.0548705, recall 0.790807
2017-12-09T16:05:53.174604: step 1954, loss 0.135963, acc 0.9375, prec 0.0548888, recall 0.790883
2017-12-09T16:05:53.765303: step 1955, loss 0.425598, acc 0.859375, prec 0.0549238, recall 0.791034
2017-12-09T16:05:54.351809: step 1956, loss 0.335914, acc 0.90625, prec 0.054963, recall 0.791185
2017-12-09T16:05:54.941502: step 1957, loss 0.18062, acc 0.921875, prec 0.0549561, recall 0.791185
2017-12-09T16:05:55.541293: step 1958, loss 0.154501, acc 0.9375, prec 0.054998, recall 0.791336
2017-12-09T16:05:56.136118: step 1959, loss 1.34799, acc 0.875, prec 0.0550107, recall 0.791411
2017-12-09T16:05:56.724815: step 1960, loss 0.740545, acc 0.90625, prec 0.0550498, recall 0.791561
2017-12-09T16:05:57.312520: step 1961, loss 0.276877, acc 0.875, prec 0.0550387, recall 0.791561
2017-12-09T16:05:57.908644: step 1962, loss 0.223776, acc 0.921875, prec 0.0550555, recall 0.791637
2017-12-09T16:05:58.493724: step 1963, loss 0.318207, acc 0.90625, prec 0.0550709, recall 0.791712
2017-12-09T16:05:59.080193: step 1964, loss 0.213413, acc 0.9375, prec 0.0550654, recall 0.791712
2017-12-09T16:05:59.667696: step 1965, loss 0.91436, acc 0.9375, prec 0.0550836, recall 0.791787
2017-12-09T16:06:00.261555: step 1966, loss 0.375114, acc 0.890625, prec 0.0551213, recall 0.791937
2017-12-09T16:06:00.845573: step 1967, loss 1.29347, acc 0.9375, prec 0.0551868, recall 0.792161
2017-12-09T16:06:01.424317: step 1968, loss 0.159708, acc 0.9375, prec 0.0551812, recall 0.792161
2017-12-09T16:06:02.004821: step 1969, loss 0.476153, acc 0.828125, prec 0.0551897, recall 0.792236
2017-12-09T16:06:02.577138: step 1970, loss 0.42734, acc 0.90625, prec 0.055205, recall 0.79231
2017-12-09T16:06:03.179511: step 1971, loss 0.287233, acc 0.9375, prec 0.0552232, recall 0.792385
2017-12-09T16:06:03.765947: step 1972, loss 0.299615, acc 0.828125, prec 0.055208, recall 0.792385
2017-12-09T16:06:04.357208: step 1973, loss 0.343475, acc 0.859375, prec 0.0551955, recall 0.792385
2017-12-09T16:06:04.945756: step 1974, loss 0.24862, acc 0.875, prec 0.0551845, recall 0.792385
2017-12-09T16:06:05.539257: step 1975, loss 0.243435, acc 0.875, prec 0.0551734, recall 0.792385
2017-12-09T16:06:06.133843: step 1976, loss 0.240428, acc 0.9375, prec 0.0551679, recall 0.792385
2017-12-09T16:06:06.733260: step 1977, loss 0.550612, acc 0.9375, prec 0.0552097, recall 0.792534
2017-12-09T16:06:07.324993: step 1978, loss 0.17723, acc 0.953125, prec 0.0552055, recall 0.792534
2017-12-09T16:06:07.910201: step 1979, loss 0.414454, acc 0.890625, prec 0.0552195, recall 0.792609
2017-12-09T16:06:08.501017: step 1980, loss 0.353167, acc 0.875, prec 0.0552793, recall 0.792832
2017-12-09T16:06:09.093324: step 1981, loss 0.104313, acc 0.953125, prec 0.0552751, recall 0.792832
2017-12-09T16:06:09.697312: step 1982, loss 0.622242, acc 0.90625, prec 0.055314, recall 0.79298
2017-12-09T16:06:10.294367: step 1983, loss 0.188671, acc 0.96875, prec 0.0553821, recall 0.793202
2017-12-09T16:06:10.898866: step 1984, loss 0.194829, acc 0.9375, prec 0.0553765, recall 0.793202
2017-12-09T16:06:11.491925: step 1985, loss 0.51357, acc 0.9375, prec 0.0554182, recall 0.79335
2017-12-09T16:06:12.105776: step 1986, loss 0.278639, acc 0.9375, prec 0.0554362, recall 0.793424
2017-12-09T16:06:12.708243: step 1987, loss 0.842986, acc 0.875, prec 0.0554723, recall 0.793571
2017-12-09T16:06:13.212978: step 1988, loss 0.383356, acc 0.921569, prec 0.0554668, recall 0.793571
2017-12-09T16:06:13.825439: step 1989, loss 0.485833, acc 0.875, prec 0.0554793, recall 0.793645
2017-12-09T16:06:14.414985: step 1990, loss 0.142923, acc 0.9375, prec 0.0555209, recall 0.793792
2017-12-09T16:06:15.012034: step 1991, loss 0.578093, acc 0.84375, prec 0.0555306, recall 0.793866
2017-12-09T16:06:15.605123: step 1992, loss 0.172924, acc 0.9375, prec 0.0555251, recall 0.793866
2017-12-09T16:06:16.202603: step 1993, loss 0.131401, acc 0.953125, prec 0.0555209, recall 0.793866
2017-12-09T16:06:16.793236: step 1994, loss 0.14769, acc 0.953125, prec 0.0555168, recall 0.793866
2017-12-09T16:06:17.386802: step 1995, loss 0.278389, acc 0.890625, prec 0.0555306, recall 0.793939
2017-12-09T16:06:17.979417: step 1996, loss 0.0757404, acc 0.96875, prec 0.0555514, recall 0.794013
2017-12-09T16:06:18.569922: step 1997, loss 0.422295, acc 0.9375, prec 0.0555694, recall 0.794086
2017-12-09T16:06:19.167394: step 1998, loss 0.279659, acc 0.921875, prec 0.0555625, recall 0.794086
2017-12-09T16:06:19.770749: step 1999, loss 0.257902, acc 0.953125, prec 0.0556525, recall 0.794379
2017-12-09T16:06:20.357448: step 2000, loss 0.27415, acc 0.921875, prec 0.0556691, recall 0.794452
Saved model checkpoint to /Users/adb/Google Drive/Data Analytics/project/xtalkdb/Deep Learning/num_filter_128_fold_0/1512852011/checkpoints/model-2000

2017-12-09T16:06:21.842858: step 2001, loss 0.175323, acc 0.96875, prec 0.0556663, recall 0.794452
2017-12-09T16:06:22.508523: step 2002, loss 0.231748, acc 0.921875, prec 0.0556829, recall 0.794525
2017-12-09T16:06:23.140074: step 2003, loss 0.20403, acc 0.9375, prec 0.0556773, recall 0.794525
2017-12-09T16:06:23.758997: step 2004, loss 0.125417, acc 0.96875, prec 0.0556746, recall 0.794525
2017-12-09T16:06:24.365608: step 2005, loss 0.265199, acc 0.9375, prec 0.0556925, recall 0.794598
2017-12-09T16:06:25.033017: step 2006, loss 0.116116, acc 0.984375, prec 0.0557382, recall 0.794744
2017-12-09T16:06:25.720217: step 2007, loss 0.127883, acc 0.953125, prec 0.0558046, recall 0.794963
2017-12-09T16:06:26.333381: step 2008, loss 0.09248, acc 0.96875, prec 0.0558018, recall 0.794963
2017-12-09T16:06:27.042235: step 2009, loss 0.189238, acc 0.9375, prec 0.0558197, recall 0.795035
2017-12-09T16:06:27.811428: step 2010, loss 1.26331, acc 0.953125, prec 0.0558861, recall 0.795253
2017-12-09T16:06:28.487168: step 2011, loss 0.233428, acc 0.96875, prec 0.0559538, recall 0.795471
2017-12-09T16:06:29.289732: step 2012, loss 0.0423878, acc 0.96875, prec 0.055951, recall 0.795471
2017-12-09T16:06:30.092055: step 2013, loss 0.524349, acc 0.921875, prec 0.055991, recall 0.795615
2017-12-09T16:06:30.830612: step 2014, loss 0.0573279, acc 0.984375, prec 0.0559896, recall 0.795615
2017-12-09T16:06:31.494033: step 2015, loss 1.03265, acc 0.984375, prec 0.0560587, recall 0.795832
2017-12-09T16:06:32.273795: step 2016, loss 0.136804, acc 0.9375, prec 0.0560766, recall 0.795904
2017-12-09T16:06:32.951422: step 2017, loss 0.695033, acc 0.90625, prec 0.0560917, recall 0.795976
2017-12-09T16:06:33.629060: step 2018, loss 0.386963, acc 0.9375, prec 0.0561096, recall 0.796048
2017-12-09T16:06:34.253685: step 2019, loss 0.406615, acc 0.890625, prec 0.0560999, recall 0.796048
2017-12-09T16:06:34.896086: step 2020, loss 0.242932, acc 0.921875, prec 0.0560929, recall 0.796048
2017-12-09T16:06:35.526852: step 2021, loss 0.285399, acc 0.859375, prec 0.0561273, recall 0.796192
2017-12-09T16:06:36.201101: step 2022, loss 0.180345, acc 0.96875, prec 0.0561479, recall 0.796264
2017-12-09T16:06:36.796263: step 2023, loss 0.246108, acc 0.90625, prec 0.0561396, recall 0.796264
2017-12-09T16:06:37.392570: step 2024, loss 0.36241, acc 0.84375, prec 0.0561491, recall 0.796335
2017-12-09T16:06:37.995683: step 2025, loss 0.235764, acc 0.953125, prec 0.0561918, recall 0.796479
2017-12-09T16:06:38.592952: step 2026, loss 0.283699, acc 0.890625, prec 0.056182, recall 0.796479
2017-12-09T16:06:39.241354: step 2027, loss 0.206837, acc 0.90625, prec 0.0561736, recall 0.796479
2017-12-09T16:06:39.840079: step 2028, loss 0.248399, acc 0.921875, prec 0.0561667, recall 0.796479
2017-12-09T16:06:40.439535: step 2029, loss 0.255405, acc 0.9375, prec 0.0561845, recall 0.796551
2017-12-09T16:06:41.063302: step 2030, loss 0.294189, acc 0.921875, prec 0.0561775, recall 0.796551
2017-12-09T16:06:41.708819: step 2031, loss 0.457241, acc 0.875, prec 0.0562132, recall 0.796694
2017-12-09T16:06:42.327302: step 2032, loss 0.154455, acc 0.953125, prec 0.0562091, recall 0.796694
2017-12-09T16:06:42.918776: step 2033, loss 0.0926031, acc 0.984375, prec 0.0562311, recall 0.796765
2017-12-09T16:06:43.516667: step 2034, loss 0.588752, acc 0.9375, prec 0.0562723, recall 0.796908
2017-12-09T16:06:44.113302: step 2035, loss 0.172791, acc 0.953125, prec 0.0562681, recall 0.796908
2017-12-09T16:06:44.706568: step 2036, loss 0.718835, acc 0.90625, prec 0.0563534, recall 0.797193
2017-12-09T16:06:45.304415: step 2037, loss 0.460502, acc 0.953125, prec 0.0563726, recall 0.797264
2017-12-09T16:06:45.909854: step 2038, loss 0.223284, acc 0.9375, prec 0.056367, recall 0.797264
2017-12-09T16:06:46.504065: step 2039, loss 0.231793, acc 0.921875, prec 0.05636, recall 0.797264
2017-12-09T16:06:47.097136: step 2040, loss 0.234151, acc 0.859375, prec 0.0563475, recall 0.797264
2017-12-09T16:06:47.685779: step 2041, loss 0.204268, acc 0.890625, prec 0.0563377, recall 0.797264
2017-12-09T16:06:48.287232: step 2042, loss 0.0815566, acc 0.953125, prec 0.0563569, recall 0.797335
2017-12-09T16:06:48.883280: step 2043, loss 0.0758229, acc 0.984375, prec 0.0563555, recall 0.797335
2017-12-09T16:06:49.475305: step 2044, loss 0.15214, acc 0.953125, prec 0.0563513, recall 0.797335
2017-12-09T16:06:50.068602: step 2045, loss 0.166681, acc 0.96875, prec 0.0563719, recall 0.797406
2017-12-09T16:06:50.664084: step 2046, loss 0.0805436, acc 0.96875, prec 0.0563925, recall 0.797477
2017-12-09T16:06:51.252878: step 2047, loss 0.314019, acc 0.921875, prec 0.0564322, recall 0.797619
2017-12-09T16:06:51.847263: step 2048, loss 0.305255, acc 0.921875, prec 0.0564252, recall 0.797619
2017-12-09T16:06:52.437320: step 2049, loss 0.258245, acc 0.90625, prec 0.0564169, recall 0.797619
2017-12-09T16:06:53.031559: step 2050, loss 0.25006, acc 0.921875, prec 0.0564099, recall 0.797619
2017-12-09T16:06:53.629047: step 2051, loss 2.66922, acc 0.9375, prec 0.056429, recall 0.797411
2017-12-09T16:06:54.222689: step 2052, loss 1.12592, acc 0.921875, prec 0.0564921, recall 0.797623
2017-12-09T16:06:54.819361: step 2053, loss 0.102677, acc 0.96875, prec 0.0564893, recall 0.797623
2017-12-09T16:06:55.408928: step 2054, loss 0.201462, acc 0.921875, prec 0.0564824, recall 0.797623
2017-12-09T16:06:56.000458: step 2055, loss 0.117355, acc 0.96875, prec 0.0564796, recall 0.797623
2017-12-09T16:06:56.586844: step 2056, loss 0.147455, acc 0.9375, prec 0.0565207, recall 0.797765
2017-12-09T16:06:57.180548: step 2057, loss 0.277133, acc 0.875, prec 0.0565095, recall 0.797765
2017-12-09T16:06:57.766893: step 2058, loss 0.206338, acc 0.9375, prec 0.0565039, recall 0.797765
2017-12-09T16:06:58.355009: step 2059, loss 0.215064, acc 0.921875, prec 0.0565436, recall 0.797906
2017-12-09T16:06:58.949691: step 2060, loss 0.252431, acc 0.921875, prec 0.0565599, recall 0.797976
2017-12-09T16:06:59.537072: step 2061, loss 0.183428, acc 0.96875, prec 0.0565571, recall 0.797976
2017-12-09T16:07:00.126859: step 2062, loss 0.302179, acc 0.90625, prec 0.056572, recall 0.798047
2017-12-09T16:07:00.717036: step 2063, loss 1.26171, acc 0.890625, prec 0.0565856, recall 0.798117
2017-12-09T16:07:01.311601: step 2064, loss 0.952783, acc 0.9375, prec 0.0566033, recall 0.798187
2017-12-09T16:07:01.907347: step 2065, loss 0.244323, acc 0.921875, prec 0.0566196, recall 0.798258
2017-12-09T16:07:02.506968: step 2066, loss 0.225569, acc 0.890625, prec 0.0566098, recall 0.798258
2017-12-09T16:07:03.097524: step 2067, loss 0.483414, acc 0.875, prec 0.0565986, recall 0.798258
2017-12-09T16:07:03.693781: step 2068, loss 0.270281, acc 0.890625, prec 0.0566122, recall 0.798328
2017-12-09T16:07:04.289904: step 2069, loss 0.38497, acc 0.921875, prec 0.0566052, recall 0.798328
2017-12-09T16:07:04.891560: step 2070, loss 0.146762, acc 0.9375, prec 0.0565996, recall 0.798328
2017-12-09T16:07:05.486165: step 2071, loss 0.235803, acc 0.890625, prec 0.0565898, recall 0.798328
2017-12-09T16:07:06.081261: step 2072, loss 0.218862, acc 0.890625, prec 0.05658, recall 0.798328
2017-12-09T16:07:06.674785: step 2073, loss 0.469179, acc 0.90625, prec 0.0566182, recall 0.798468
2017-12-09T16:07:07.270511: step 2074, loss 0.19823, acc 0.921875, prec 0.0566112, recall 0.798468
2017-12-09T16:07:07.859075: step 2075, loss 0.605978, acc 0.921875, prec 0.0566508, recall 0.798609
2017-12-09T16:07:08.450390: step 2076, loss 0.254378, acc 0.953125, prec 0.0566699, recall 0.798679
2017-12-09T16:07:09.044726: step 2077, loss 0.294492, acc 0.875, prec 0.0566587, recall 0.798679
2017-12-09T16:07:09.633620: step 2078, loss 0.193864, acc 0.90625, prec 0.0566503, recall 0.798679
2017-12-09T16:07:10.229077: step 2079, loss 0.323294, acc 0.84375, prec 0.0566363, recall 0.798679
2017-12-09T16:07:10.824189: step 2080, loss 0.245839, acc 0.921875, prec 0.0566294, recall 0.798679
2017-12-09T16:07:11.421419: step 2081, loss 0.197968, acc 0.953125, prec 0.0566252, recall 0.798679
2017-12-09T16:07:12.043158: step 2082, loss 0.370103, acc 0.921875, prec 0.0566647, recall 0.798819
2017-12-09T16:07:12.637277: step 2083, loss 0.138659, acc 0.953125, prec 0.0566838, recall 0.798889
2017-12-09T16:07:13.231648: step 2084, loss 0.169729, acc 0.921875, prec 0.0567, recall 0.798958
2017-12-09T16:07:13.825012: step 2085, loss 0.116676, acc 0.953125, prec 0.0567191, recall 0.799028
2017-12-09T16:07:14.415599: step 2086, loss 0.692911, acc 0.953125, prec 0.0567614, recall 0.799168
2017-12-09T16:07:15.006050: step 2087, loss 0.234109, acc 0.953125, prec 0.0568036, recall 0.799307
2017-12-09T16:07:15.595830: step 2088, loss 0.26161, acc 0.875, prec 0.0567924, recall 0.799307
2017-12-09T16:07:16.192664: step 2089, loss 0.1442, acc 0.9375, prec 0.0567868, recall 0.799307
2017-12-09T16:07:16.785653: step 2090, loss 0.0193323, acc 1, prec 0.0567868, recall 0.799307
2017-12-09T16:07:17.376010: step 2091, loss 0.244015, acc 0.9375, prec 0.0568277, recall 0.799446
2017-12-09T16:07:17.964919: step 2092, loss 0.160943, acc 0.96875, prec 0.0568249, recall 0.799446
2017-12-09T16:07:18.555700: step 2093, loss 0.162786, acc 0.921875, prec 0.0568179, recall 0.799446
2017-12-09T16:07:19.145963: step 2094, loss 0.232733, acc 0.90625, prec 0.0568095, recall 0.799446
2017-12-09T16:07:19.740858: step 2095, loss 0.180314, acc 0.96875, prec 0.0568531, recall 0.799585
2017-12-09T16:07:20.329811: step 2096, loss 0.24409, acc 0.921875, prec 0.0568694, recall 0.799654
2017-12-09T16:07:20.916555: step 2097, loss 0.107438, acc 0.984375, prec 0.056868, recall 0.799654
2017-12-09T16:07:21.502874: step 2098, loss 0.0543237, acc 0.984375, prec 0.0568666, recall 0.799654
2017-12-09T16:07:22.099416: step 2099, loss 0.069867, acc 0.96875, prec 0.056887, recall 0.799723
2017-12-09T16:07:22.681300: step 2100, loss 0.0516048, acc 0.984375, prec 0.0568856, recall 0.799723

Evaluation:
2017-12-09T16:08:16.900911: step 2100, loss 2.84398, acc 0.956222, prec 0.0577434, recall 0.776105

Saved model checkpoint to /Users/adb/Google Drive/Data Analytics/project/xtalkdb/Deep Learning/num_filter_128_fold_0/1512852011/checkpoints/model-2100

2017-12-09T16:08:18.651936: step 2101, loss 0.0596639, acc 0.984375, prec 0.057742, recall 0.776105
2017-12-09T16:08:19.286681: step 2102, loss 0.416294, acc 0.96875, prec 0.0577621, recall 0.776178
2017-12-09T16:08:19.889455: step 2103, loss 0.101112, acc 0.984375, prec 0.0577607, recall 0.776178
2017-12-09T16:08:20.508326: step 2104, loss 0.129081, acc 0.984375, prec 0.0577822, recall 0.776251
2017-12-09T16:08:21.140982: step 2105, loss 1.64467, acc 0.921875, prec 0.0577766, recall 0.775997
2017-12-09T16:08:21.812004: step 2106, loss 0.534823, acc 0.96875, prec 0.0577967, recall 0.776071
2017-12-09T16:08:22.494321: step 2107, loss 2.71498, acc 0.90625, prec 0.0578126, recall 0.77589
2017-12-09T16:08:23.109775: step 2108, loss 0.188472, acc 0.9375, prec 0.0578299, recall 0.775963
2017-12-09T16:08:23.727891: step 2109, loss 0.146604, acc 0.9375, prec 0.0578243, recall 0.775963
2017-12-09T16:08:24.354912: step 2110, loss 0.0892136, acc 0.953125, prec 0.0578201, recall 0.775963
2017-12-09T16:08:24.973946: step 2111, loss 0.671068, acc 0.8125, prec 0.0578032, recall 0.775963
2017-12-09T16:08:25.590965: step 2112, loss 0.485715, acc 0.875, prec 0.0578378, recall 0.77611
2017-12-09T16:08:26.184609: step 2113, loss 0.392886, acc 0.890625, prec 0.0578737, recall 0.776256
2017-12-09T16:08:26.772291: step 2114, loss 0.257455, acc 0.890625, prec 0.0579097, recall 0.776402
2017-12-09T16:08:27.378058: step 2115, loss 0.443017, acc 0.84375, prec 0.0579185, recall 0.776474
2017-12-09T16:08:27.970041: step 2116, loss 0.296038, acc 0.890625, prec 0.0579316, recall 0.776547
2017-12-09T16:08:28.563091: step 2117, loss 0.488551, acc 0.828125, prec 0.057939, recall 0.77662
2017-12-09T16:08:29.184509: step 2118, loss 0.399718, acc 0.84375, prec 0.0579478, recall 0.776693
2017-12-09T16:08:29.777905: step 2119, loss 0.332835, acc 0.84375, prec 0.0579337, recall 0.776693
2017-12-09T16:08:30.364284: step 2120, loss 0.550154, acc 0.828125, prec 0.0579182, recall 0.776693
2017-12-09T16:08:30.949010: step 2121, loss 0.251053, acc 0.890625, prec 0.0579313, recall 0.776765
2017-12-09T16:08:31.561662: step 2122, loss 0.876481, acc 0.859375, prec 0.0579415, recall 0.776838
2017-12-09T16:08:32.143277: step 2123, loss 0.489497, acc 0.90625, prec 0.0579787, recall 0.776983
2017-12-09T16:08:32.733370: step 2124, loss 0.162995, acc 0.890625, prec 0.0579918, recall 0.777056
2017-12-09T16:08:33.325188: step 2125, loss 0.382774, acc 0.90625, prec 0.058029, recall 0.7772
2017-12-09T16:08:33.901733: step 2126, loss 0.162873, acc 0.953125, prec 0.0580248, recall 0.7772
2017-12-09T16:08:34.485386: step 2127, loss 0.768685, acc 0.953125, prec 0.0580434, recall 0.777273
2017-12-09T16:08:35.102008: step 2128, loss 0.312716, acc 0.921875, prec 0.0580364, recall 0.777273
2017-12-09T16:08:35.690887: step 2129, loss 0.284771, acc 0.9375, prec 0.0580764, recall 0.777417
2017-12-09T16:08:36.278296: step 2130, loss 0.259263, acc 0.90625, prec 0.058068, recall 0.777417
2017-12-09T16:08:36.861574: step 2131, loss 0.715371, acc 0.875, prec 0.0580795, recall 0.777489
2017-12-09T16:08:37.460600: step 2132, loss 0.328392, acc 0.890625, prec 0.0581153, recall 0.777634
2017-12-09T16:08:38.046080: step 2133, loss 0.350457, acc 0.875, prec 0.0581497, recall 0.777778
2017-12-09T16:08:38.643067: step 2134, loss 0.287533, acc 0.90625, prec 0.058164, recall 0.77785
2017-12-09T16:08:39.228365: step 2135, loss 0.257305, acc 0.921875, prec 0.0581798, recall 0.777922
2017-12-09T16:08:39.820458: step 2136, loss 0.282407, acc 0.90625, prec 0.0581941, recall 0.777994
2017-12-09T16:08:40.404960: step 2137, loss 0.357596, acc 0.84375, prec 0.0581801, recall 0.777994
2017-12-09T16:08:40.988306: step 2138, loss 0.311998, acc 0.859375, prec 0.0581674, recall 0.777994
2017-12-09T16:08:41.576423: step 2139, loss 0.164632, acc 0.90625, prec 0.0581589, recall 0.777994
2017-12-09T16:08:42.173178: step 2140, loss 0.497482, acc 0.9375, prec 0.0582217, recall 0.778209
2017-12-09T16:08:42.770078: step 2141, loss 0.0568809, acc 0.984375, prec 0.0582203, recall 0.778209
2017-12-09T16:08:43.362669: step 2142, loss 0.189029, acc 0.96875, prec 0.0582402, recall 0.778281
2017-12-09T16:08:43.966353: step 2143, loss 0.155588, acc 0.90625, prec 0.0582318, recall 0.778281
2017-12-09T16:08:44.558046: step 2144, loss 0.353603, acc 0.9375, prec 0.0582717, recall 0.778424
2017-12-09T16:08:45.152241: step 2145, loss 0.240416, acc 0.921875, prec 0.0582646, recall 0.778424
2017-12-09T16:08:45.767046: step 2146, loss 0.192909, acc 0.921875, prec 0.0582576, recall 0.778424
2017-12-09T16:08:46.376911: step 2147, loss 0.989925, acc 0.96875, prec 0.0583003, recall 0.778567
2017-12-09T16:08:46.987995: step 2148, loss 0.177927, acc 0.9375, prec 0.0582947, recall 0.778567
2017-12-09T16:08:47.607297: step 2149, loss 0.541651, acc 0.90625, prec 0.0583545, recall 0.778781
2017-12-09T16:08:48.224895: step 2150, loss 0.13289, acc 0.953125, prec 0.0583502, recall 0.778781
2017-12-09T16:08:48.841570: step 2151, loss 0.164721, acc 0.921875, prec 0.0583432, recall 0.778781
2017-12-09T16:08:49.457997: step 2152, loss 0.203236, acc 0.9375, prec 0.0583603, recall 0.778852
2017-12-09T16:08:50.076647: step 2153, loss 0.241883, acc 0.9375, prec 0.0584002, recall 0.778995
2017-12-09T16:08:50.696186: step 2154, loss 0.22096, acc 0.890625, prec 0.058413, recall 0.779066
2017-12-09T16:08:51.323900: step 2155, loss 0.102394, acc 0.953125, prec 0.0584088, recall 0.779066
2017-12-09T16:08:51.947278: step 2156, loss 0.906888, acc 0.9375, prec 0.0584259, recall 0.779137
2017-12-09T16:08:52.578927: step 2157, loss 0.374085, acc 0.921875, prec 0.0584416, recall 0.779208
2017-12-09T16:08:53.201314: step 2158, loss 0.111256, acc 0.953125, prec 0.0584601, recall 0.779279
2017-12-09T16:08:53.825430: step 2159, loss 0.208651, acc 0.9375, prec 0.0584544, recall 0.779279
2017-12-09T16:08:54.441630: step 2160, loss 0.181227, acc 0.9375, prec 0.0584715, recall 0.77935
2017-12-09T16:08:55.059816: step 2161, loss 2.96987, acc 0.921875, prec 0.0585113, recall 0.779242
2017-12-09T16:08:55.673128: step 2162, loss 0.472599, acc 0.90625, prec 0.0585255, recall 0.779313
2017-12-09T16:08:56.297603: step 2163, loss 0.230109, acc 0.90625, prec 0.0585171, recall 0.779313
2017-12-09T16:08:56.910003: step 2164, loss 0.145097, acc 0.9375, prec 0.0585341, recall 0.779383
2017-12-09T16:08:57.517601: step 2165, loss 0.351277, acc 0.859375, prec 0.0585214, recall 0.779383
2017-12-09T16:08:58.127221: step 2166, loss 0.381412, acc 0.875, prec 0.0585782, recall 0.779596
2017-12-09T16:08:58.718913: step 2167, loss 0.377623, acc 0.875, prec 0.0585896, recall 0.779666
2017-12-09T16:08:59.341529: step 2168, loss 0.204101, acc 0.9375, prec 0.058584, recall 0.779666
2017-12-09T16:08:59.955399: step 2169, loss 0.269403, acc 0.890625, prec 0.0585968, recall 0.779737
2017-12-09T16:09:00.582948: step 2170, loss 0.111284, acc 0.96875, prec 0.0586166, recall 0.779808
2017-12-09T16:09:01.229272: step 2171, loss 0.310126, acc 0.921875, prec 0.0586549, recall 0.779949
2017-12-09T16:09:01.846323: step 2172, loss 0.739864, acc 0.9375, prec 0.0587173, recall 0.78016
2017-12-09T16:09:02.453122: step 2173, loss 0.407855, acc 0.890625, prec 0.05873, recall 0.78023
2017-12-09T16:09:03.060592: step 2174, loss 0.276336, acc 0.859375, prec 0.0587173, recall 0.78023
2017-12-09T16:09:03.666764: step 2175, loss 0.148194, acc 0.953125, prec 0.0587131, recall 0.78023
2017-12-09T16:09:04.280980: step 2176, loss 0.311043, acc 0.90625, prec 0.0587273, recall 0.780301
2017-12-09T16:09:04.887329: step 2177, loss 0.371526, acc 0.859375, prec 0.0587372, recall 0.780371
2017-12-09T16:09:05.510312: step 2178, loss 0.30222, acc 0.875, prec 0.0587712, recall 0.780511
2017-12-09T16:09:06.131792: step 2179, loss 0.242206, acc 0.921875, prec 0.0587867, recall 0.780581
2017-12-09T16:09:06.749379: step 2180, loss 0.120324, acc 0.9375, prec 0.0587811, recall 0.780581
2017-12-09T16:09:07.379403: step 2181, loss 0.155292, acc 0.9375, prec 0.0587754, recall 0.780581
2017-12-09T16:09:08.001769: step 2182, loss 0.416094, acc 0.984375, prec 0.0587967, recall 0.780651
2017-12-09T16:09:08.623648: step 2183, loss 0.294101, acc 0.875, prec 0.0587853, recall 0.780651
2017-12-09T16:09:09.232003: step 2184, loss 0.122567, acc 0.953125, prec 0.0587811, recall 0.780651
2017-12-09T16:09:09.830991: step 2185, loss 6.52085, acc 0.921875, prec 0.0587755, recall 0.780402
2017-12-09T16:09:10.425352: step 2186, loss 0.106665, acc 0.96875, prec 0.0587726, recall 0.780402
2017-12-09T16:09:11.012119: step 2187, loss 0.110879, acc 0.953125, prec 0.0587684, recall 0.780402
2017-12-09T16:09:11.601856: step 2188, loss 0.118963, acc 0.953125, prec 0.0587868, recall 0.780472
2017-12-09T16:09:12.212591: step 2189, loss 0.0513264, acc 1, prec 0.0588094, recall 0.780542
2017-12-09T16:09:12.805243: step 2190, loss 0.0907544, acc 0.984375, prec 0.0588306, recall 0.780612
2017-12-09T16:09:13.394921: step 2191, loss 0.353686, acc 0.84375, prec 0.0588165, recall 0.780612
2017-12-09T16:09:13.984426: step 2192, loss 0.27688, acc 0.90625, prec 0.058808, recall 0.780612
2017-12-09T16:09:14.585492: step 2193, loss 0.223202, acc 0.890625, prec 0.0587981, recall 0.780612
2017-12-09T16:09:15.204889: step 2194, loss 0.252502, acc 0.859375, prec 0.0587854, recall 0.780612
2017-12-09T16:09:15.811390: step 2195, loss 0.280345, acc 0.90625, prec 0.0588221, recall 0.780752
2017-12-09T16:09:16.416683: step 2196, loss 0.485329, acc 0.9375, prec 0.0588842, recall 0.780961
2017-12-09T16:09:17.034097: step 2197, loss 0.203648, acc 0.921875, prec 0.0588772, recall 0.780961
2017-12-09T16:09:17.641167: step 2198, loss 0.202122, acc 0.953125, prec 0.0588729, recall 0.780961
2017-12-09T16:09:18.240081: step 2199, loss 0.479389, acc 0.9375, prec 0.0588899, recall 0.781031
2017-12-09T16:09:18.834150: step 2200, loss 0.213996, acc 0.890625, prec 0.05888, recall 0.781031
Saved model checkpoint to /Users/adb/Google Drive/Data Analytics/project/xtalkdb/Deep Learning/num_filter_128_fold_0/1512852011/checkpoints/model-2200

2017-12-09T16:09:20.196722: step 2201, loss 0.151646, acc 0.953125, prec 0.0588757, recall 0.781031
2017-12-09T16:09:20.782479: step 2202, loss 1.49934, acc 0.90625, prec 0.0588687, recall 0.780783
2017-12-09T16:09:21.371279: step 2203, loss 0.167783, acc 0.90625, prec 0.0588602, recall 0.780783
2017-12-09T16:09:21.958595: step 2204, loss 0.117742, acc 0.96875, prec 0.0588574, recall 0.780783
2017-12-09T16:09:22.547525: step 2205, loss 0.405427, acc 0.96875, prec 0.0589674, recall 0.781131
2017-12-09T16:09:23.132968: step 2206, loss 0.298837, acc 0.890625, prec 0.0589801, recall 0.7812
2017-12-09T16:09:23.744235: step 2207, loss 0.21792, acc 0.90625, prec 0.0589942, recall 0.78127
2017-12-09T16:09:24.344022: step 2208, loss 0.604946, acc 0.90625, prec 0.0590082, recall 0.781339
2017-12-09T16:09:24.922522: step 2209, loss 0.51699, acc 0.8125, prec 0.0590363, recall 0.781478
2017-12-09T16:09:25.501829: step 2210, loss 0.436533, acc 0.859375, prec 0.0590236, recall 0.781478
2017-12-09T16:09:26.087931: step 2211, loss 0.133612, acc 0.9375, prec 0.059018, recall 0.781478
2017-12-09T16:09:26.683256: step 2212, loss 0.340059, acc 0.90625, prec 0.0590095, recall 0.781478
2017-12-09T16:09:27.281564: step 2213, loss 0.75873, acc 0.953125, prec 0.0591179, recall 0.781824
2017-12-09T16:09:27.880486: step 2214, loss 0.173131, acc 0.9375, prec 0.0591122, recall 0.781824
2017-12-09T16:09:28.475486: step 2215, loss 0.206105, acc 0.90625, prec 0.0591037, recall 0.781824
2017-12-09T16:09:29.074509: step 2216, loss 0.312857, acc 0.890625, prec 0.0590938, recall 0.781824
2017-12-09T16:09:29.691404: step 2217, loss 0.204878, acc 0.90625, prec 0.0591079, recall 0.781893
2017-12-09T16:09:30.294493: step 2218, loss 0.603601, acc 0.796875, prec 0.059157, recall 0.7821
2017-12-09T16:09:30.903221: step 2219, loss 0.653661, acc 0.90625, prec 0.059171, recall 0.782169
2017-12-09T16:09:31.509636: step 2220, loss 0.439331, acc 0.859375, prec 0.0592258, recall 0.782375
2017-12-09T16:09:32.119083: step 2221, loss 2.22447, acc 0.875, prec 0.0592384, recall 0.782197
2017-12-09T16:09:32.729627: step 2222, loss 0.17578, acc 0.921875, prec 0.0592538, recall 0.782266
2017-12-09T16:09:33.333591: step 2223, loss 2.98098, acc 0.90625, prec 0.0592467, recall 0.782019
2017-12-09T16:09:33.999631: step 2224, loss 0.260446, acc 0.890625, prec 0.0592368, recall 0.782019
2017-12-09T16:09:34.669561: step 2225, loss 0.379744, acc 0.875, prec 0.0592255, recall 0.782019
2017-12-09T16:09:35.360807: step 2226, loss 0.490204, acc 0.8125, prec 0.059231, recall 0.782088
2017-12-09T16:09:36.029799: step 2227, loss 0.406839, acc 0.84375, prec 0.0592168, recall 0.782088
2017-12-09T16:09:36.706149: step 2228, loss 0.588611, acc 0.84375, prec 0.05927, recall 0.782294
2017-12-09T16:09:37.404757: step 2229, loss 0.432463, acc 0.84375, prec 0.0592559, recall 0.782294
2017-12-09T16:09:38.074672: step 2230, loss 0.622374, acc 0.84375, prec 0.0592642, recall 0.782362
2017-12-09T16:09:38.736634: step 2231, loss 0.907079, acc 0.765625, prec 0.0593103, recall 0.782568
2017-12-09T16:09:39.389547: step 2232, loss 0.612385, acc 0.78125, prec 0.0593129, recall 0.782636
2017-12-09T16:09:40.021597: step 2233, loss 0.535188, acc 0.796875, prec 0.059317, recall 0.782704
2017-12-09T16:09:40.706049: step 2234, loss 0.445696, acc 0.890625, prec 0.0593071, recall 0.782704
2017-12-09T16:09:41.347221: step 2235, loss 0.633111, acc 0.796875, prec 0.0593111, recall 0.782773
2017-12-09T16:09:42.055769: step 2236, loss 0.444894, acc 0.859375, prec 0.0592984, recall 0.782773
2017-12-09T16:09:42.704046: step 2237, loss 0.487637, acc 0.84375, prec 0.0592843, recall 0.782773
2017-12-09T16:09:43.394233: step 2238, loss 0.495389, acc 0.796875, prec 0.059266, recall 0.782773
2017-12-09T16:09:44.077021: step 2239, loss 0.557552, acc 0.828125, prec 0.0592728, recall 0.782841
2017-12-09T16:09:44.700441: step 2240, loss 0.196716, acc 0.9375, prec 0.0592896, recall 0.782909
2017-12-09T16:09:45.409345: step 2241, loss 0.427247, acc 0.90625, prec 0.0592811, recall 0.782909
2017-12-09T16:09:46.085574: step 2242, loss 0.272599, acc 0.875, prec 0.0593146, recall 0.783046
2017-12-09T16:09:46.768178: step 2243, loss 0.252228, acc 0.90625, prec 0.0593061, recall 0.783046
2017-12-09T16:09:47.409194: step 2244, loss 0.706418, acc 0.890625, prec 0.0593186, recall 0.783114
2017-12-09T16:09:48.088373: step 2245, loss 1.36294, acc 0.953125, prec 0.0593815, recall 0.783318
2017-12-09T16:09:48.766669: step 2246, loss 0.55741, acc 0.859375, prec 0.0593688, recall 0.783318
2017-12-09T16:09:49.429997: step 2247, loss 0.157929, acc 0.96875, prec 0.0593659, recall 0.783318
2017-12-09T16:09:50.109472: step 2248, loss 2.17517, acc 0.90625, prec 0.0593812, recall 0.78314
2017-12-09T16:09:50.790868: step 2249, loss 0.322098, acc 0.90625, prec 0.0593728, recall 0.78314
2017-12-09T16:09:51.489302: step 2250, loss 0.413761, acc 0.84375, prec 0.0593587, recall 0.78314
2017-12-09T16:09:52.153686: step 2251, loss 0.319924, acc 0.890625, prec 0.0593488, recall 0.78314
2017-12-09T16:09:52.829605: step 2252, loss 0.17049, acc 0.90625, prec 0.0593403, recall 0.78314
2017-12-09T16:09:53.510821: step 2253, loss 0.271905, acc 0.9375, prec 0.059357, recall 0.783208
2017-12-09T16:09:54.203182: step 2254, loss 0.279794, acc 0.90625, prec 0.0593709, recall 0.783276
2017-12-09T16:09:54.881921: step 2255, loss 0.0947234, acc 0.9375, prec 0.0593653, recall 0.783276
2017-12-09T16:09:55.560202: step 2256, loss 0.642309, acc 0.90625, prec 0.0594015, recall 0.783412
2017-12-09T16:09:56.219042: step 2257, loss 0.485095, acc 0.84375, prec 0.059432, recall 0.783547
2017-12-09T16:09:56.881600: step 2258, loss 0.426983, acc 0.890625, prec 0.0594221, recall 0.783547
2017-12-09T16:09:57.536528: step 2259, loss 0.297737, acc 0.875, prec 0.0594109, recall 0.783547
2017-12-09T16:09:58.126040: step 2260, loss 0.243703, acc 0.921875, prec 0.0594484, recall 0.783682
2017-12-09T16:09:58.768670: step 2261, loss 0.241474, acc 0.890625, prec 0.0594386, recall 0.783682
2017-12-09T16:09:59.396980: step 2262, loss 0.0828983, acc 0.984375, prec 0.0594595, recall 0.78375
2017-12-09T16:10:00.062623: step 2263, loss 0.323562, acc 0.921875, prec 0.0594524, recall 0.78375
2017-12-09T16:10:00.755533: step 2264, loss 0.115369, acc 0.953125, prec 0.0594928, recall 0.783885
2017-12-09T16:10:01.427839: step 2265, loss 0.0646368, acc 0.984375, prec 0.0594914, recall 0.783885
2017-12-09T16:10:02.104390: step 2266, loss 4.64249, acc 0.9375, prec 0.0595094, recall 0.783708
2017-12-09T16:10:02.786418: step 2267, loss 0.257824, acc 0.90625, prec 0.059501, recall 0.783708
2017-12-09T16:10:03.455072: step 2268, loss 0.12259, acc 0.96875, prec 0.059565, recall 0.78391
2017-12-09T16:10:04.134672: step 2269, loss 0.295271, acc 0.890625, prec 0.0595774, recall 0.783978
2017-12-09T16:10:04.797754: step 2270, loss 0.309379, acc 0.890625, prec 0.0595675, recall 0.783978
2017-12-09T16:10:05.475604: step 2271, loss 0.367422, acc 0.890625, prec 0.0596022, recall 0.784112
2017-12-09T16:10:06.167900: step 2272, loss 0.396092, acc 0.890625, prec 0.0596146, recall 0.784179
2017-12-09T16:10:06.853468: step 2273, loss 0.467301, acc 0.890625, prec 0.0596492, recall 0.784314
2017-12-09T16:10:07.559388: step 2274, loss 0.488384, acc 0.875, prec 0.0596824, recall 0.784448
2017-12-09T16:10:08.266157: step 2275, loss 0.521436, acc 0.828125, prec 0.0596669, recall 0.784448
2017-12-09T16:10:08.949049: step 2276, loss 0.442756, acc 0.859375, prec 0.0596764, recall 0.784515
2017-12-09T16:10:09.634753: step 2277, loss 0.405776, acc 0.875, prec 0.0596874, recall 0.784582
2017-12-09T16:10:10.315225: step 2278, loss 0.517345, acc 0.90625, prec 0.0596789, recall 0.784582
2017-12-09T16:10:10.969664: step 2279, loss 0.391331, acc 0.890625, prec 0.059669, recall 0.784582
2017-12-09T16:10:11.628376: step 2280, loss 0.337107, acc 0.859375, prec 0.0596786, recall 0.784649
2017-12-09T16:10:12.244099: step 2281, loss 0.172889, acc 0.9375, prec 0.0596951, recall 0.784716
2017-12-09T16:10:12.833337: step 2282, loss 0.758086, acc 0.9375, prec 0.0597339, recall 0.784849
2017-12-09T16:10:13.489090: step 2283, loss 0.203212, acc 0.921875, prec 0.0597491, recall 0.784916
2017-12-09T16:10:14.140173: step 2284, loss 0.141306, acc 0.9375, prec 0.0597434, recall 0.784916
2017-12-09T16:10:14.778325: step 2285, loss 0.199865, acc 0.921875, prec 0.0597364, recall 0.784916
2017-12-09T16:10:15.459607: step 2286, loss 1.54643, acc 0.90625, prec 0.0597515, recall 0.784739
2017-12-09T16:10:16.137795: step 2287, loss 0.205535, acc 0.890625, prec 0.0597639, recall 0.784806
2017-12-09T16:10:16.813475: step 2288, loss 0.145158, acc 0.921875, prec 0.0597568, recall 0.784806
2017-12-09T16:10:17.536669: step 2289, loss 0.330806, acc 0.90625, prec 0.0597706, recall 0.784873
2017-12-09T16:10:18.216875: step 2290, loss 0.156439, acc 0.921875, prec 0.0597857, recall 0.78494
2017-12-09T16:10:18.870506: step 2291, loss 0.254232, acc 0.90625, prec 0.0597772, recall 0.78494
2017-12-09T16:10:19.554236: step 2292, loss 0.342724, acc 0.875, prec 0.0597659, recall 0.78494
2017-12-09T16:10:20.203903: step 2293, loss 0.342404, acc 0.875, prec 0.0597547, recall 0.78494
2017-12-09T16:10:20.882421: step 2294, loss 0.256973, acc 0.9375, prec 0.059749, recall 0.78494
2017-12-09T16:10:21.563862: step 2295, loss 0.194944, acc 0.90625, prec 0.0597406, recall 0.78494
2017-12-09T16:10:22.242334: step 2296, loss 0.440487, acc 0.890625, prec 0.0597529, recall 0.785006
2017-12-09T16:10:22.920110: step 2297, loss 0.22716, acc 0.921875, prec 0.059768, recall 0.785073
2017-12-09T16:10:23.605131: step 2298, loss 0.22167, acc 0.890625, prec 0.0597581, recall 0.785073
2017-12-09T16:10:24.285550: step 2299, loss 0.246397, acc 0.9375, prec 0.0597747, recall 0.785139
2017-12-09T16:10:24.963248: step 2300, loss 0.612168, acc 0.859375, prec 0.0598063, recall 0.785272
Saved model checkpoint to /Users/adb/Google Drive/Data Analytics/project/xtalkdb/Deep Learning/num_filter_128_fold_0/1512852011/checkpoints/model-2300

2017-12-09T16:10:26.378187: step 2301, loss 0.10689, acc 0.953125, prec 0.0598242, recall 0.785339
2017-12-09T16:10:26.990596: step 2302, loss 1.07342, acc 0.921875, prec 0.0598393, recall 0.785405
2017-12-09T16:10:27.637738: step 2303, loss 0.164578, acc 0.9375, prec 0.0598558, recall 0.785471
2017-12-09T16:10:28.267537: step 2304, loss 0.220343, acc 0.890625, prec 0.059846, recall 0.785471
2017-12-09T16:10:28.916712: step 2305, loss 0.208554, acc 0.96875, prec 0.0598874, recall 0.785604
2017-12-09T16:10:29.550153: step 2306, loss 1.24976, acc 0.953125, prec 0.0599496, recall 0.785802
2017-12-09T16:10:30.210966: step 2307, loss 0.287596, acc 0.890625, prec 0.0599397, recall 0.785802
2017-12-09T16:10:30.834630: step 2308, loss 0.251401, acc 0.921875, prec 0.0599769, recall 0.785935
2017-12-09T16:10:31.520131: step 2309, loss 0.269647, acc 0.859375, prec 0.0599863, recall 0.786001
2017-12-09T16:10:32.212123: step 2310, loss 0.132323, acc 0.953125, prec 0.0600264, recall 0.786133
2017-12-09T16:10:32.899978: step 2311, loss 0.478104, acc 0.875, prec 0.0600593, recall 0.786264
2017-12-09T16:10:33.570960: step 2312, loss 0.154987, acc 0.953125, prec 0.0600772, recall 0.78633
2017-12-09T16:10:34.255341: step 2313, loss 0.382224, acc 0.9375, prec 0.0600936, recall 0.786396
2017-12-09T16:10:34.951870: step 2314, loss 0.258519, acc 0.921875, prec 0.0601086, recall 0.786462
2017-12-09T16:10:35.663102: step 2315, loss 0.246314, acc 0.9375, prec 0.0601472, recall 0.786593
2017-12-09T16:10:36.407579: step 2316, loss 0.148259, acc 0.96875, prec 0.0601665, recall 0.786658
2017-12-09T16:10:37.114115: step 2317, loss 0.132049, acc 0.953125, prec 0.0602285, recall 0.786855
2017-12-09T16:10:37.830097: step 2318, loss 0.154075, acc 0.96875, prec 0.0602478, recall 0.78692
2017-12-09T16:10:38.543721: step 2319, loss 0.295434, acc 0.890625, prec 0.0602378, recall 0.78692
2017-12-09T16:10:39.262808: step 2320, loss 0.144184, acc 0.953125, prec 0.0602778, recall 0.787051
2017-12-09T16:10:39.878293: step 2321, loss 0.181528, acc 0.90625, prec 0.0602693, recall 0.787051
2017-12-09T16:10:40.493243: step 2322, loss 0.146817, acc 0.953125, prec 0.0602871, recall 0.787117
2017-12-09T16:10:41.184524: step 2323, loss 0.136942, acc 0.953125, prec 0.0602829, recall 0.787117
2017-12-09T16:10:41.861745: step 2324, loss 0.169796, acc 0.953125, prec 0.0603007, recall 0.787182
2017-12-09T16:10:42.564668: step 2325, loss 0.0982785, acc 0.953125, prec 0.0602964, recall 0.787182
2017-12-09T16:10:43.244299: step 2326, loss 0.253088, acc 0.875, prec 0.0603072, recall 0.787247
2017-12-09T16:10:43.922853: step 2327, loss 0.116442, acc 0.9375, prec 0.0603015, recall 0.787247
2017-12-09T16:10:44.593532: step 2328, loss 0.301575, acc 0.953125, prec 0.0603634, recall 0.787443
2017-12-09T16:10:45.278925: step 2329, loss 1.79332, acc 0.9375, prec 0.0603592, recall 0.787201
2017-12-09T16:10:45.953716: step 2330, loss 0.166026, acc 0.953125, prec 0.060377, recall 0.787267
2017-12-09T16:10:46.641964: step 2331, loss 0.26081, acc 0.9375, prec 0.0603713, recall 0.787267
2017-12-09T16:10:47.294890: step 2332, loss 0.089218, acc 0.96875, prec 0.0603685, recall 0.787267
2017-12-09T16:10:47.991414: step 2333, loss 0.247378, acc 0.921875, prec 0.0603614, recall 0.787267
2017-12-09T16:10:48.671796: step 2334, loss 0.0930526, acc 0.96875, prec 0.0603806, recall 0.787332
2017-12-09T16:10:49.351315: step 2335, loss 0.253106, acc 0.921875, prec 0.0603736, recall 0.787332
2017-12-09T16:10:50.033883: step 2336, loss 0.329289, acc 0.9375, prec 0.0603899, recall 0.787397
2017-12-09T16:10:50.717068: step 2337, loss 1.06556, acc 0.96875, prec 0.0604091, recall 0.787462
2017-12-09T16:10:51.420248: step 2338, loss 1.0841, acc 0.9375, prec 0.0604696, recall 0.787657
2017-12-09T16:10:52.103470: step 2339, loss 0.135549, acc 0.9375, prec 0.0604639, recall 0.787657
2017-12-09T16:10:52.808473: step 2340, loss 0.492798, acc 0.796875, prec 0.0604675, recall 0.787721
2017-12-09T16:10:53.486929: step 2341, loss 0.163479, acc 0.953125, prec 0.0604633, recall 0.787721
2017-12-09T16:10:54.168918: step 2342, loss 0.556551, acc 0.875, prec 0.0604739, recall 0.787786
2017-12-09T16:10:54.789769: step 2343, loss 0.531333, acc 0.875, prec 0.0604846, recall 0.787851
2017-12-09T16:10:55.401088: step 2344, loss 0.258261, acc 0.90625, prec 0.0605422, recall 0.788045
2017-12-09T16:10:56.090700: step 2345, loss 0.226007, acc 0.9375, prec 0.0605365, recall 0.788045
2017-12-09T16:10:56.747116: step 2346, loss 0.123117, acc 0.96875, prec 0.0605557, recall 0.78811
2017-12-09T16:10:57.415673: step 2347, loss 0.275551, acc 0.859375, prec 0.0605429, recall 0.78811
2017-12-09T16:10:58.063036: step 2348, loss 0.502892, acc 0.859375, prec 0.0605521, recall 0.788174
2017-12-09T16:10:58.714701: step 2349, loss 0.15328, acc 0.921875, prec 0.060567, recall 0.788239
2017-12-09T16:10:59.368285: step 2350, loss 0.248614, acc 0.890625, prec 0.0605571, recall 0.788239
2017-12-09T16:11:00.011698: step 2351, loss 0.452829, acc 0.84375, prec 0.0605649, recall 0.788303
2017-12-09T16:11:00.692605: step 2352, loss 0.377986, acc 0.859375, prec 0.0605522, recall 0.788303
2017-12-09T16:11:01.330703: step 2353, loss 0.362025, acc 0.84375, prec 0.06056, recall 0.788368
2017-12-09T16:11:02.028286: step 2354, loss 0.128686, acc 0.984375, prec 0.0606025, recall 0.788497
2017-12-09T16:11:02.662804: step 2355, loss 0.179821, acc 0.90625, prec 0.060616, recall 0.788561
2017-12-09T16:11:03.356110: step 2356, loss 0.207079, acc 0.9375, prec 0.0606323, recall 0.788625
2017-12-09T16:11:04.043420: step 2357, loss 0.192947, acc 1, prec 0.0606982, recall 0.788818
2017-12-09T16:11:04.721987: step 2358, loss 0.675592, acc 0.84375, prec 0.0607279, recall 0.788946
2017-12-09T16:11:05.410105: step 2359, loss 0.177544, acc 0.921875, prec 0.0607428, recall 0.78901
2017-12-09T16:11:06.094549: step 2360, loss 0.088846, acc 0.96875, prec 0.0607399, recall 0.78901
2017-12-09T16:11:06.842045: step 2361, loss 0.724005, acc 0.9375, prec 0.0607562, recall 0.789074
2017-12-09T16:11:07.551866: step 2362, loss 1.29272, acc 0.921875, prec 0.0607505, recall 0.788835
2017-12-09T16:11:08.263455: step 2363, loss 0.228974, acc 0.953125, prec 0.0607682, recall 0.788899
2017-12-09T16:11:08.966508: step 2364, loss 0.12705, acc 0.9375, prec 0.0607625, recall 0.788899
2017-12-09T16:11:09.663476: step 2365, loss 0.210937, acc 0.90625, prec 0.060754, recall 0.788899
2017-12-09T16:11:10.276267: step 2366, loss 0.249679, acc 0.9375, prec 0.0607703, recall 0.788963
2017-12-09T16:11:10.936093: step 2367, loss 0.0356069, acc 1, prec 0.0608141, recall 0.789091
2017-12-09T16:11:11.623960: step 2368, loss 0.191918, acc 0.9375, prec 0.0608084, recall 0.789091
2017-12-09T16:11:12.277569: step 2369, loss 2.23462, acc 0.96875, prec 0.060807, recall 0.788852
2017-12-09T16:11:12.959068: step 2370, loss 0.234906, acc 0.9375, prec 0.0608013, recall 0.788852
2017-12-09T16:11:13.602265: step 2371, loss 0.0614044, acc 0.96875, prec 0.0608204, recall 0.788916
2017-12-09T16:11:14.285985: step 2372, loss 0.37325, acc 0.921875, prec 0.0608353, recall 0.78898
2017-12-09T16:11:14.945246: step 2373, loss 0.118758, acc 0.96875, prec 0.0608543, recall 0.789044
2017-12-09T16:11:15.633270: step 2374, loss 0.152037, acc 0.953125, prec 0.0608501, recall 0.789044
2017-12-09T16:11:16.275071: step 2375, loss 0.307944, acc 0.953125, prec 0.0608897, recall 0.789171
2017-12-09T16:11:16.952932: step 2376, loss 0.168367, acc 0.96875, prec 0.0609087, recall 0.789235
2017-12-09T16:11:17.590799: step 2377, loss 0.193036, acc 0.953125, prec 0.0609264, recall 0.789299
2017-12-09T16:11:18.324778: step 2378, loss 1.15861, acc 0.96875, prec 0.0609469, recall 0.789124
2017-12-09T16:11:19.009208: step 2379, loss 0.673111, acc 0.875, prec 0.0609574, recall 0.789188
2017-12-09T16:11:19.695069: step 2380, loss 0.581498, acc 0.875, prec 0.0609679, recall 0.789251
2017-12-09T16:11:20.374633: step 2381, loss 0.255359, acc 0.921875, prec 0.0609608, recall 0.789251
2017-12-09T16:11:21.055050: step 2382, loss 0.328499, acc 0.859375, prec 0.0609699, recall 0.789315
2017-12-09T16:11:21.745251: step 2383, loss 0.155211, acc 0.984375, prec 0.0610342, recall 0.789505
2017-12-09T16:11:22.427967: step 2384, loss 0.3312, acc 0.890625, prec 0.061068, recall 0.789632
2017-12-09T16:11:23.109191: step 2385, loss 0.417428, acc 0.84375, prec 0.0610538, recall 0.789632
2017-12-09T16:11:23.790186: step 2386, loss 0.376617, acc 0.875, prec 0.0610424, recall 0.789632
2017-12-09T16:11:24.460205: step 2387, loss 0.445066, acc 0.875, prec 0.0610966, recall 0.789822
2017-12-09T16:11:25.070477: step 2388, loss 0.256119, acc 0.890625, prec 0.0611304, recall 0.789949
2017-12-09T16:11:25.719189: step 2389, loss 0.208096, acc 0.9375, prec 0.0611247, recall 0.789949
2017-12-09T16:11:26.401427: step 2390, loss 0.537065, acc 0.90625, prec 0.0611162, recall 0.789949
2017-12-09T16:11:27.079784: step 2391, loss 0.140954, acc 0.9375, prec 0.0611105, recall 0.789949
2017-12-09T16:11:27.804706: step 2392, loss 0.800709, acc 0.828125, prec 0.0611385, recall 0.790075