{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os, sys\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def read_summary_file(summary_file):\n",
    "    loss=[]\n",
    "    accuracy=[]\n",
    "    precision=[]\n",
    "    recall=[]\n",
    "    for e in tf.train.summary_iterator(summary_file):\n",
    "        for v in e.summary.value:\n",
    "            if v.tag == 'loss_1':\n",
    "                loss.append(v.simple_value)\n",
    "            if v.tag == 'accuracy_1':\n",
    "                accuracy.append(v.simple_value)\n",
    "            if v.tag == 'precision':\n",
    "                precision.append(v.simple_value)\n",
    "            if v.tag == 'recall':\n",
    "                recall.append(v.simple_value)\n",
    "    return np.array(loss), np.array(accuracy), np.array(precision), np.array(recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "FailedPreconditionError",
     "evalue": "num_filter_256_fold_0/1512891150",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-48744e3637e7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprecision\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_summary_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'num_filter_256_fold_0/1512891150/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-3-cdd50380e78c>\u001b[0m in \u001b[0;36mread_summary_file\u001b[0;34m(summary_file)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprecision\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mrecall\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msummary_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtag\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'loss_1'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/adb/anaconda3/lib/python3.5/site-packages/tensorflow/python/summary/summary_iterator.py\u001b[0m in \u001b[0;36msummary_iterator\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    351\u001b[0m   \"\"\"\n\u001b[1;32m    352\u001b[0m   \u001b[0;31m# pylint: enable=line-too-long\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 353\u001b[0;31m   \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtf_record\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_record_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    354\u001b[0m     \u001b[0;32myield\u001b[0m \u001b[0mevent_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEvent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFromString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/adb/anaconda3/lib/python3.5/site-packages/tensorflow/python/lib/io/tf_record.py\u001b[0m in \u001b[0;36mtf_record_iterator\u001b[0;34m(path, options)\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[0mreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGetNext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m       \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/adb/anaconda3/lib/python3.5/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m                 \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/adb/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[0;34m()\u001b[0m\n\u001b[1;32m    464\u001b[0m           \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[1;32m    467\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m     \u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_DeleteStatus\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFailedPreconditionError\u001b[0m: num_filter_256_fold_0/1512891150"
     ]
    }
   ],
   "source": [
    "loss, accuracy, precision, recall = read_summary_file('num_filter_256_fold_0/1512891150/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_filters = [32, 64, 128, 256]\n",
    "prefix='num_filter_'\n",
    "results = []\n",
    "\n",
    "for num_filter in num_filters:\n",
    "    experiment = prefix+str(num_filter)\n",
    "    loss=[]\n",
    "    accuracy=[]\n",
    "    precision=[]\n",
    "    recall=[]\n",
    "    for fold in range(4):\n",
    "        experiment_dir = experiment + \"_fold_%s\"%fold\n",
    "        dev = os.path.join(experiment_dir, [x for x in listdir(experiment_dir) if '.' not in x][0], 'summaries/dev')\n",
    "        train = os.path.join(experiment_dir, [x for x in listdir(experiment_dir) if '.' not in x][0], 'summaries/train')\n",
    "        train_summary = os.path.join(train, listdir(train)[0])\n",
    "        dev_summary = os.path.join(dev, listdir(dev)[0])\n",
    "        l, acc, p, r = read_summary_file(dev_summary)\n",
    "        loss.append(l)\n",
    "        accuracy.append(acc)\n",
    "        recall.append(r)\n",
    "        precision.append(p)\n",
    "    loss = np.stack(loss)\n",
    "    accuracy = np.stack(accuracy)\n",
    "    precision = np.stack(precision)\n",
    "    recall = np.stack(recall)\n",
    "    average_loss=np.mean(loss, axis=0)\n",
    "    average_accuracy=np.mean(accuracy, axis=0)\n",
    "    average_precision=np.mean(precision, axis=0)\n",
    "    average_recall=np.mean(recall, axis=0)\n",
    "    average_f1_score=2/((1/average_precision) + (1/average_recall))\n",
    "    step = np.argmax(average_f1_score)\n",
    "    cross_val_loss = average_loss[step]\n",
    "    cross_val_precision = average_precision[step]\n",
    "    cross_val_accuracy = average_accuracy[step]\n",
    "    cross_val_recall = average_recall[step]\n",
    "    cross_val_f1 = average_f1_score[step]\n",
    "    results.append([experiment, cross_val_accuracy, cross_val_precision, cross_val_recall, cross_val_f1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(results, columns=['experiment', 'accuracy', 'precision', 'recall', 'f1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.to_csv('num_filter.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>num_filter_32</td>\n",
       "      <td>0.968</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.787</td>\n",
       "      <td>0.216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>num_filter_64</td>\n",
       "      <td>0.961</td>\n",
       "      <td>0.127</td>\n",
       "      <td>0.799</td>\n",
       "      <td>0.218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>num_filter_128</td>\n",
       "      <td>0.954</td>\n",
       "      <td>0.131</td>\n",
       "      <td>0.786</td>\n",
       "      <td>0.225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>num_filter_256</td>\n",
       "      <td>0.942</td>\n",
       "      <td>0.120</td>\n",
       "      <td>0.793</td>\n",
       "      <td>0.209</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       experiment  accuracy  precision  recall     f1\n",
       "0   num_filter_32     0.968      0.125   0.787  0.216\n",
       "1   num_filter_64     0.961      0.127   0.799  0.218\n",
       "2  num_filter_128     0.954      0.131   0.786  0.225\n",
       "3  num_filter_256     0.942      0.120   0.793  0.209"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_filters = [32, 64, 128, 256, 512, 1024]\n",
    "prefix='batch_size_'\n",
    "results = []\n",
    "\n",
    "for num_filter in num_filters:\n",
    "    experiment = prefix+str(num_filter)\n",
    "    loss=[]\n",
    "    accuracy=[]\n",
    "    precision=[]\n",
    "    recall=[]\n",
    "    for fold in range(4):\n",
    "        experiment_dir = experiment + \"_fold_%s\"%fold\n",
    "        dev = os.path.join(experiment_dir, [x for x in listdir(experiment_dir) if '.' not in x][0], 'summaries/dev')\n",
    "        train = os.path.join(experiment_dir, [x for x in listdir(experiment_dir) if '.' not in x][0], 'summaries/train')\n",
    "        train_summary = os.path.join(train, listdir(train)[0])\n",
    "        dev_summary = os.path.join(dev, listdir(dev)[0])\n",
    "        l, acc, p, r = read_summary_file(dev_summary)\n",
    "        loss.append(l[:20])\n",
    "        accuracy.append(acc[:20])\n",
    "        recall.append(r[:20])\n",
    "        precision.append(p[:20])\n",
    "    loss = np.stack(loss)\n",
    "    accuracy = np.stack(accuracy)\n",
    "    precision = np.stack(precision)\n",
    "    recall = np.stack(recall)\n",
    "    average_loss=np.mean(loss, axis=0)\n",
    "    average_accuracy=np.mean(accuracy, axis=0)\n",
    "    average_precision=np.mean(precision, axis=0)\n",
    "    average_recall=np.mean(recall, axis=0)\n",
    "    average_f1_score=2/((1/average_precision) + (1/average_recall))\n",
    "    step = np.argmax(average_f1_score)\n",
    "    cross_val_loss = average_loss[step]\n",
    "    cross_val_precision = average_precision[step]\n",
    "    cross_val_accuracy = average_accuracy[step]\n",
    "    cross_val_recall = average_recall[step]\n",
    "    cross_val_f1 = average_f1_score[step]\n",
    "    results.append([experiment, cross_val_accuracy, cross_val_precision, cross_val_recall, cross_val_f1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'batch_size_1024_fold_3'"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(results, columns=['experiment', 'accuracy', 'precision', 'recall', 'f1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.round(3).to_csv('batch_size.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>batch_size_32</td>\n",
       "      <td>0.956</td>\n",
       "      <td>0.066</td>\n",
       "      <td>0.761</td>\n",
       "      <td>0.121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>batch_size_64</td>\n",
       "      <td>0.937</td>\n",
       "      <td>0.088</td>\n",
       "      <td>0.793</td>\n",
       "      <td>0.158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>batch_size_128</td>\n",
       "      <td>0.958</td>\n",
       "      <td>0.085</td>\n",
       "      <td>0.843</td>\n",
       "      <td>0.154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>batch_size_256</td>\n",
       "      <td>0.938</td>\n",
       "      <td>0.076</td>\n",
       "      <td>0.864</td>\n",
       "      <td>0.139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>batch_size_512</td>\n",
       "      <td>0.931</td>\n",
       "      <td>0.064</td>\n",
       "      <td>0.867</td>\n",
       "      <td>0.120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>batch_size_1024</td>\n",
       "      <td>0.919</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.847</td>\n",
       "      <td>0.097</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        experiment  accuracy  precision  recall     f1\n",
       "0    batch_size_32     0.956      0.066   0.761  0.121\n",
       "1    batch_size_64     0.937      0.088   0.793  0.158\n",
       "2   batch_size_128     0.958      0.085   0.843  0.154\n",
       "3   batch_size_256     0.938      0.076   0.864  0.139\n",
       "4   batch_size_512     0.931      0.064   0.867  0.120\n",
       "5  batch_size_1024     0.919      0.051   0.847  0.097"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Leaving embedding out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_filters = ['leave_pos_embedding_out', 'leave_position_embedding_out', 'leave_word_embedding_out']\n",
    "prefix=''\n",
    "results = []\n",
    "\n",
    "for num_filter in num_filters:\n",
    "    experiment = prefix+str(num_filter)\n",
    "    loss=[]\n",
    "    accuracy=[]\n",
    "    precision=[]\n",
    "    recall=[]\n",
    "    for fold in range(4):\n",
    "        experiment_dir = experiment + \"_fold_%s\"%fold\n",
    "        dev = os.path.join(experiment_dir, [x for x in listdir(experiment_dir) if '.' not in x][0], 'summaries/dev')\n",
    "        train = os.path.join(experiment_dir, [x for x in listdir(experiment_dir) if '.' not in x][0], 'summaries/train')\n",
    "        train_summary = os.path.join(train, listdir(train)[0])\n",
    "        dev_summary = os.path.join(dev, listdir(dev)[0])\n",
    "        l, acc, p, r = read_summary_file(dev_summary)\n",
    "        loss.append(l)\n",
    "        accuracy.append(acc)\n",
    "        recall.append(r)\n",
    "        precision.append(p)\n",
    "    loss = np.stack(loss)\n",
    "    accuracy = np.stack(accuracy)\n",
    "    precision = np.stack(precision)\n",
    "    recall = np.stack(recall)\n",
    "    average_loss=np.mean(loss, axis=0)\n",
    "    average_accuracy=np.mean(accuracy, axis=0)\n",
    "    average_precision=np.mean(precision, axis=0)\n",
    "    average_recall=np.mean(recall, axis=0)\n",
    "    average_f1_score=2/((1/average_precision) + (1/average_recall))\n",
    "    step = np.argmax(average_f1_score)\n",
    "    cross_val_loss = average_loss[step]\n",
    "    cross_val_precision = average_precision[step]\n",
    "    cross_val_accuracy = average_accuracy[step]\n",
    "    cross_val_recall = average_recall[step]\n",
    "    cross_val_f1 = average_f1_score[step]\n",
    "    results.append([experiment, cross_val_accuracy, cross_val_precision, cross_val_recall, cross_val_f1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(results, columns=['experiment', 'accuracy', 'precision', 'recall', 'f1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.round(3).to_csv('leave_one_embedding_out.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>leave_pos_embedding_out</td>\n",
       "      <td>0.953</td>\n",
       "      <td>0.082</td>\n",
       "      <td>0.893</td>\n",
       "      <td>0.150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>leave_position_embedding_out</td>\n",
       "      <td>0.952</td>\n",
       "      <td>0.067</td>\n",
       "      <td>0.869</td>\n",
       "      <td>0.124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>leave_word_embedding_out</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.832</td>\n",
       "      <td>0.061</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     experiment  accuracy  precision  recall     f1\n",
       "0       leave_pos_embedding_out     0.953      0.082   0.893  0.150\n",
       "1  leave_position_embedding_out     0.952      0.067   0.869  0.124\n",
       "2      leave_word_embedding_out     0.625      0.032   0.832  0.061"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'embedding_size_64_fold_0'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-cecd45a72416>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mfold\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mexperiment_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexperiment\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"_fold_%s\"\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mfold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mdev\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexperiment_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexperiment_dir\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m'.'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'summaries/dev'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexperiment_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexperiment_dir\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m'.'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'summaries/train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mtrain_summary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'embedding_size_64_fold_0'"
     ]
    }
   ],
   "source": [
    "num_filters = [32, 64, 128, 256]\n",
    "prefix='embedding_size_'\n",
    "results = []\n",
    "\n",
    "for num_filter in num_filters:\n",
    "    experiment = prefix+str(num_filter)\n",
    "    loss=[]\n",
    "    accuracy=[]\n",
    "    precision=[]\n",
    "    recall=[]\n",
    "    for fold in range(4):\n",
    "        experiment_dir = experiment + \"_fold_%s\"%fold\n",
    "        dev = os.path.join(experiment_dir, [x for x in listdir(experiment_dir) if '.' not in x][0], 'summaries/dev')\n",
    "        train = os.path.join(experiment_dir, [x for x in listdir(experiment_dir) if '.' not in x][0], 'summaries/train')\n",
    "        train_summary = os.path.join(train, listdir(train)[0])\n",
    "        dev_summary = os.path.join(dev, listdir(dev)[0])\n",
    "        l, acc, p, r = read_summary_file(dev_summary)\n",
    "        loss.append(l[:20])\n",
    "        accuracy.append(acc[:20])\n",
    "        recall.append(r[:20])\n",
    "        precision.append(p[:20])\n",
    "    loss = np.stack(loss)\n",
    "    accuracy = np.stack(accuracy)\n",
    "    precision = np.stack(precision)\n",
    "    recall = np.stack(recall)\n",
    "    average_loss=np.mean(loss, axis=0)\n",
    "    average_accuracy=np.mean(accuracy, axis=0)\n",
    "    average_precision=np.mean(precision, axis=0)\n",
    "    average_recall=np.mean(recall, axis=0)\n",
    "    average_f1_score=2/((1/average_precision) + (1/average_recall))\n",
    "    step = np.argmax(average_f1_score)\n",
    "    cross_val_loss = average_loss[step]\n",
    "    cross_val_precision = average_precision[step]\n",
    "    cross_val_accuracy = average_accuracy[step]\n",
    "    cross_val_recall = average_recall[step]\n",
    "    cross_val_f1 = average_f1_score[step]\n",
    "    results.append([experiment, cross_val_accuracy, cross_val_precision, cross_val_recall, cross_val_f1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(results, columns=['experiment', 'accuracy', 'precision', 'recall', 'f1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.round(3).to_csv('embedding_size.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(df.round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'filter_sizes_3_4_fold_0'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-0757a52a98da>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mfold\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mexperiment_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexperiment\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"_fold_%s\"\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mfold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mdev\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexperiment_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexperiment_dir\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m'.'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'summaries/dev'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexperiment_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexperiment_dir\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m'.'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'summaries/train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mtrain_summary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'filter_sizes_3_4_fold_0'"
     ]
    }
   ],
   "source": [
    "num_filters = [[3,4], [4,5], [3,5], [3], [4], [5]]\n",
    "prefix='filter_sizes_'\n",
    "results = []\n",
    "\n",
    "for num_filter in num_filters:\n",
    "    experiment = prefix+'_'.join([str(x) for x in num_filter])\n",
    "    loss=[]\n",
    "    accuracy=[]\n",
    "    precision=[]\n",
    "    recall=[]\n",
    "    for fold in range(4):\n",
    "        experiment_dir = experiment + \"_fold_%s\"%fold\n",
    "        dev = os.path.join(experiment_dir, [x for x in listdir(experiment_dir) if '.' not in x][0], 'summaries/dev')\n",
    "        train = os.path.join(experiment_dir, [x for x in listdir(experiment_dir) if '.' not in x][0], 'summaries/train')\n",
    "        train_summary = os.path.join(train, listdir(train)[0])\n",
    "        dev_summary = os.path.join(dev, listdir(dev)[0])\n",
    "        l, acc, p, r = read_summary_file(dev_summary)\n",
    "        loss.append(l)\n",
    "        accuracy.append(acc)\n",
    "        recall.append(r)\n",
    "        precision.append(p)\n",
    "    loss = np.stack(loss)\n",
    "    accuracy = np.stack(accuracy)\n",
    "    precision = np.stack(precision)\n",
    "    recall = np.stack(recall)\n",
    "    average_loss=np.mean(loss, axis=0)\n",
    "    average_accuracy=np.mean(accuracy, axis=0)\n",
    "    average_precision=np.mean(precision, axis=0)\n",
    "    average_recall=np.mean(recall, axis=0)\n",
    "    average_f1_score=2/((1/average_precision) + (1/average_recall))\n",
    "    step = np.argmax(average_f1_score)\n",
    "    cross_val_loss = average_loss[step]\n",
    "    cross_val_precision = average_precision[step]\n",
    "    cross_val_accuracy = average_accuracy[step]\n",
    "    cross_val_recall = average_recall[step]\n",
    "    cross_val_f1 = average_f1_score[step]\n",
    "    results.append([experiment, cross_val_accuracy, cross_val_precision, cross_val_recall, cross_val_f1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
