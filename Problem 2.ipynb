{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import datetime\n",
    "from tensorflow.contrib import learn\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from utils import *\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /Users/adb/Google Drive/Data Analytics/project/xtalkdb/Deep Learning/num_filter_64_fold_0/1512825696/checkpoints/model-9900\n"
     ]
    }
   ],
   "source": [
    "sess=tf.Session()    \n",
    "#First let's load meta graph and restore weights\n",
    "saver = tf.train.import_meta_graph('model-9500.meta')\n",
    "saver.restore(sess,tf.train.latest_checkpoint('./'))\n",
    " \n",
    "graph = tf.get_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary Size: 33447\n",
      "encodedPathwayA = 8 encodedPathwayB = 53\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "x_text, y = load_data_and_labels()\n",
    "\n",
    "# Build vocabulary\n",
    "max_document_length = max([len(x.split(\" \")) for x in x_text])\n",
    "vocab_processor = learn.preprocessing.VocabularyProcessor(max_document_length)\n",
    "x = np.array(list(vocab_processor.fit_transform(x_text)))\n",
    "print(\"Vocabulary Size: {:d}\".format(len(vocab_processor.vocabulary_)))\n",
    "\n",
    "\n",
    "encodedPathwayA, encodedPathwayB = list(vocab_processor.transform(['pathwayA pathwayB']))[0][:2]\n",
    "print(\"encodedPathwayA = %s\" % encodedPathwayA, \"encodedPathwayB = %s\" % encodedPathwayB)\n",
    "\n",
    "word_distancesA = load_word_distancesA()\n",
    "word_distancesB = load_word_distancesB()\n",
    "\n",
    "pos_embedding = load_pos_embedding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pathway_to_genes_dict = pickle.load(open( \"data/pathway_to_genes_dict.p\", \"rb\" ))\n",
    "sentence_support_df = pd.read_csv('data/sentence_support_v3.tsv', delimiter='\\t')\n",
    "sentence_support_df.drop_duplicates(inplace=True)\n",
    "sentence_support_df['tokenizedSentenceFromPaper'] = sentence_support_df.apply(lambda x: tokenize_pathway_names(x.sentenceFromPaper, x.pathwayA, x.pathwayB), axis=1)\n",
    "sentence_support_df['predictedLabel'] = sentence_support_df.apply(lambda x: x.label, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Operation 'input_x' type=Placeholder>,\n",
       " <tf.Operation 'input_y' type=Placeholder>,\n",
       " <tf.Operation 'dropout_keep_prob' type=Placeholder>,\n",
       " <tf.Operation 'word_distancesA' type=Placeholder>,\n",
       " <tf.Operation 'word_distancesB' type=Placeholder>,\n",
       " <tf.Operation 'encoded_pos' type=Placeholder>,\n",
       " <tf.Operation 'Const' type=Const>,\n",
       " <tf.Operation 'word_embedding/random_uniform/shape' type=Const>,\n",
       " <tf.Operation 'word_embedding/random_uniform/min' type=Const>,\n",
       " <tf.Operation 'word_embedding/random_uniform/max' type=Const>,\n",
       " <tf.Operation 'word_embedding/random_uniform/RandomUniform' type=RandomUniform>,\n",
       " <tf.Operation 'word_embedding/random_uniform/sub' type=Sub>,\n",
       " <tf.Operation 'word_embedding/random_uniform/mul' type=Mul>,\n",
       " <tf.Operation 'word_embedding/random_uniform' type=Add>,\n",
       " <tf.Operation 'word_embedding/W' type=VariableV2>,\n",
       " <tf.Operation 'word_embedding/W/Assign' type=Assign>,\n",
       " <tf.Operation 'word_embedding/W/read' type=Identity>,\n",
       " <tf.Operation 'word_embedding/embedding_lookup' type=Gather>,\n",
       " <tf.Operation 'word_embedding/ExpandDims/dim' type=Const>,\n",
       " <tf.Operation 'word_embedding/ExpandDims' type=ExpandDims>,\n",
       " <tf.Operation 'position_embedding/embedding_lookup/params_0' type=Const>,\n",
       " <tf.Operation 'position_embedding/embedding_lookup' type=Gather>,\n",
       " <tf.Operation 'position_embedding/embedding_lookup_1/params_0' type=Const>,\n",
       " <tf.Operation 'position_embedding/embedding_lookup_1' type=Gather>,\n",
       " <tf.Operation 'position_embedding/concat/axis' type=Const>,\n",
       " <tf.Operation 'position_embedding/concat' type=ConcatV2>,\n",
       " <tf.Operation 'position_embedding/ExpandDims/dim' type=Const>,\n",
       " <tf.Operation 'position_embedding/ExpandDims' type=ExpandDims>,\n",
       " <tf.Operation 'position_embedding/Cast' type=Cast>,\n",
       " <tf.Operation 'pos_embedding/one_hot/on_value' type=Const>,\n",
       " <tf.Operation 'pos_embedding/one_hot/off_value' type=Const>,\n",
       " <tf.Operation 'pos_embedding/one_hot/indices' type=Const>,\n",
       " <tf.Operation 'pos_embedding/one_hot/depth' type=Const>,\n",
       " <tf.Operation 'pos_embedding/one_hot' type=OneHot>,\n",
       " <tf.Operation 'pos_embedding/embedding_lookup' type=Gather>,\n",
       " <tf.Operation 'pos_embedding/ExpandDims/dim' type=Const>,\n",
       " <tf.Operation 'pos_embedding/ExpandDims' type=ExpandDims>,\n",
       " <tf.Operation 'embedding/concat/axis' type=Const>,\n",
       " <tf.Operation 'embedding/concat' type=ConcatV2>,\n",
       " <tf.Operation 'conv-maxpool-3/truncated_normal/shape' type=Const>,\n",
       " <tf.Operation 'conv-maxpool-3/truncated_normal/mean' type=Const>,\n",
       " <tf.Operation 'conv-maxpool-3/truncated_normal/stddev' type=Const>,\n",
       " <tf.Operation 'conv-maxpool-3/truncated_normal/TruncatedNormal' type=TruncatedNormal>,\n",
       " <tf.Operation 'conv-maxpool-3/truncated_normal/mul' type=Mul>,\n",
       " <tf.Operation 'conv-maxpool-3/truncated_normal' type=Add>,\n",
       " <tf.Operation 'conv-maxpool-3/W' type=VariableV2>,\n",
       " <tf.Operation 'conv-maxpool-3/W/Assign' type=Assign>,\n",
       " <tf.Operation 'conv-maxpool-3/W/read' type=Identity>,\n",
       " <tf.Operation 'conv-maxpool-3/Const' type=Const>,\n",
       " <tf.Operation 'conv-maxpool-3/b' type=VariableV2>,\n",
       " <tf.Operation 'conv-maxpool-3/b/Assign' type=Assign>,\n",
       " <tf.Operation 'conv-maxpool-3/b/read' type=Identity>,\n",
       " <tf.Operation 'conv-maxpool-3/conv' type=Conv2D>,\n",
       " <tf.Operation 'conv-maxpool-3/BiasAdd' type=BiasAdd>,\n",
       " <tf.Operation 'conv-maxpool-3/relu' type=Relu>,\n",
       " <tf.Operation 'conv-maxpool-3/pool' type=MaxPool>,\n",
       " <tf.Operation 'conv-maxpool-4/truncated_normal/shape' type=Const>,\n",
       " <tf.Operation 'conv-maxpool-4/truncated_normal/mean' type=Const>,\n",
       " <tf.Operation 'conv-maxpool-4/truncated_normal/stddev' type=Const>,\n",
       " <tf.Operation 'conv-maxpool-4/truncated_normal/TruncatedNormal' type=TruncatedNormal>,\n",
       " <tf.Operation 'conv-maxpool-4/truncated_normal/mul' type=Mul>,\n",
       " <tf.Operation 'conv-maxpool-4/truncated_normal' type=Add>,\n",
       " <tf.Operation 'conv-maxpool-4/W' type=VariableV2>,\n",
       " <tf.Operation 'conv-maxpool-4/W/Assign' type=Assign>,\n",
       " <tf.Operation 'conv-maxpool-4/W/read' type=Identity>,\n",
       " <tf.Operation 'conv-maxpool-4/Const' type=Const>,\n",
       " <tf.Operation 'conv-maxpool-4/b' type=VariableV2>,\n",
       " <tf.Operation 'conv-maxpool-4/b/Assign' type=Assign>,\n",
       " <tf.Operation 'conv-maxpool-4/b/read' type=Identity>,\n",
       " <tf.Operation 'conv-maxpool-4/conv' type=Conv2D>,\n",
       " <tf.Operation 'conv-maxpool-4/BiasAdd' type=BiasAdd>,\n",
       " <tf.Operation 'conv-maxpool-4/relu' type=Relu>,\n",
       " <tf.Operation 'conv-maxpool-4/pool' type=MaxPool>,\n",
       " <tf.Operation 'conv-maxpool-5/truncated_normal/shape' type=Const>,\n",
       " <tf.Operation 'conv-maxpool-5/truncated_normal/mean' type=Const>,\n",
       " <tf.Operation 'conv-maxpool-5/truncated_normal/stddev' type=Const>,\n",
       " <tf.Operation 'conv-maxpool-5/truncated_normal/TruncatedNormal' type=TruncatedNormal>,\n",
       " <tf.Operation 'conv-maxpool-5/truncated_normal/mul' type=Mul>,\n",
       " <tf.Operation 'conv-maxpool-5/truncated_normal' type=Add>,\n",
       " <tf.Operation 'conv-maxpool-5/W' type=VariableV2>,\n",
       " <tf.Operation 'conv-maxpool-5/W/Assign' type=Assign>,\n",
       " <tf.Operation 'conv-maxpool-5/W/read' type=Identity>,\n",
       " <tf.Operation 'conv-maxpool-5/Const' type=Const>,\n",
       " <tf.Operation 'conv-maxpool-5/b' type=VariableV2>,\n",
       " <tf.Operation 'conv-maxpool-5/b/Assign' type=Assign>,\n",
       " <tf.Operation 'conv-maxpool-5/b/read' type=Identity>,\n",
       " <tf.Operation 'conv-maxpool-5/conv' type=Conv2D>,\n",
       " <tf.Operation 'conv-maxpool-5/BiasAdd' type=BiasAdd>,\n",
       " <tf.Operation 'conv-maxpool-5/relu' type=Relu>,\n",
       " <tf.Operation 'conv-maxpool-5/pool' type=MaxPool>,\n",
       " <tf.Operation 'concat/axis' type=Const>,\n",
       " <tf.Operation 'concat' type=ConcatV2>,\n",
       " <tf.Operation 'Reshape/shape' type=Const>,\n",
       " <tf.Operation 'Reshape' type=Reshape>,\n",
       " <tf.Operation 'dropout/dropout/Shape' type=Shape>,\n",
       " <tf.Operation 'dropout/dropout/random_uniform/min' type=Const>,\n",
       " <tf.Operation 'dropout/dropout/random_uniform/max' type=Const>,\n",
       " <tf.Operation 'dropout/dropout/random_uniform/RandomUniform' type=RandomUniform>,\n",
       " <tf.Operation 'dropout/dropout/random_uniform/sub' type=Sub>,\n",
       " <tf.Operation 'dropout/dropout/random_uniform/mul' type=Mul>,\n",
       " <tf.Operation 'dropout/dropout/random_uniform' type=Add>,\n",
       " <tf.Operation 'dropout/dropout/add' type=Add>,\n",
       " <tf.Operation 'dropout/dropout/Floor' type=Floor>,\n",
       " <tf.Operation 'dropout/dropout/div' type=RealDiv>,\n",
       " <tf.Operation 'dropout/dropout/mul' type=Mul>,\n",
       " <tf.Operation 'W/Initializer/random_uniform/shape' type=Const>,\n",
       " <tf.Operation 'W/Initializer/random_uniform/min' type=Const>,\n",
       " <tf.Operation 'W/Initializer/random_uniform/max' type=Const>,\n",
       " <tf.Operation 'W/Initializer/random_uniform/RandomUniform' type=RandomUniform>,\n",
       " <tf.Operation 'W/Initializer/random_uniform/sub' type=Sub>,\n",
       " <tf.Operation 'W/Initializer/random_uniform/mul' type=Mul>,\n",
       " <tf.Operation 'W/Initializer/random_uniform' type=Add>,\n",
       " <tf.Operation 'W' type=VariableV2>,\n",
       " <tf.Operation 'W/Assign' type=Assign>,\n",
       " <tf.Operation 'W/read' type=Identity>,\n",
       " <tf.Operation 'output/Const' type=Const>,\n",
       " <tf.Operation 'output/b' type=VariableV2>,\n",
       " <tf.Operation 'output/b/Assign' type=Assign>,\n",
       " <tf.Operation 'output/b/read' type=Identity>,\n",
       " <tf.Operation 'output/L2Loss' type=L2Loss>,\n",
       " <tf.Operation 'output/add' type=Add>,\n",
       " <tf.Operation 'output/L2Loss_1' type=L2Loss>,\n",
       " <tf.Operation 'output/add_1' type=Add>,\n",
       " <tf.Operation 'output/scores/MatMul' type=MatMul>,\n",
       " <tf.Operation 'output/scores' type=BiasAdd>,\n",
       " <tf.Operation 'output/predictions/dimension' type=Const>,\n",
       " <tf.Operation 'output/predictions' type=ArgMax>,\n",
       " <tf.Operation 'loss/Const' type=Const>,\n",
       " <tf.Operation 'loss/mul' type=Mul>,\n",
       " <tf.Operation 'loss/Sum/reduction_indices' type=Const>,\n",
       " <tf.Operation 'loss/Sum' type=Sum>,\n",
       " <tf.Operation 'loss/Rank' type=Const>,\n",
       " <tf.Operation 'loss/Shape' type=Shape>,\n",
       " <tf.Operation 'loss/Rank_1' type=Const>,\n",
       " <tf.Operation 'loss/Shape_1' type=Shape>,\n",
       " <tf.Operation 'loss/Sub/y' type=Const>,\n",
       " <tf.Operation 'loss/Sub' type=Sub>,\n",
       " <tf.Operation 'loss/Slice/begin' type=Pack>,\n",
       " <tf.Operation 'loss/Slice/size' type=Const>,\n",
       " <tf.Operation 'loss/Slice' type=Slice>,\n",
       " <tf.Operation 'loss/concat/values_0' type=Const>,\n",
       " <tf.Operation 'loss/concat/axis' type=Const>,\n",
       " <tf.Operation 'loss/concat' type=ConcatV2>,\n",
       " <tf.Operation 'loss/Reshape' type=Reshape>,\n",
       " <tf.Operation 'loss/Rank_2' type=Const>,\n",
       " <tf.Operation 'loss/Shape_2' type=Shape>,\n",
       " <tf.Operation 'loss/Sub_1/y' type=Const>,\n",
       " <tf.Operation 'loss/Sub_1' type=Sub>,\n",
       " <tf.Operation 'loss/Slice_1/begin' type=Pack>,\n",
       " <tf.Operation 'loss/Slice_1/size' type=Const>,\n",
       " <tf.Operation 'loss/Slice_1' type=Slice>,\n",
       " <tf.Operation 'loss/concat_1/values_0' type=Const>,\n",
       " <tf.Operation 'loss/concat_1/axis' type=Const>,\n",
       " <tf.Operation 'loss/concat_1' type=ConcatV2>,\n",
       " <tf.Operation 'loss/Reshape_1' type=Reshape>,\n",
       " <tf.Operation 'loss/SoftmaxCrossEntropyWithLogits' type=SoftmaxCrossEntropyWithLogits>,\n",
       " <tf.Operation 'loss/Sub_2/y' type=Const>,\n",
       " <tf.Operation 'loss/Sub_2' type=Sub>,\n",
       " <tf.Operation 'loss/Slice_2/begin' type=Const>,\n",
       " <tf.Operation 'loss/Slice_2/size' type=Pack>,\n",
       " <tf.Operation 'loss/Slice_2' type=Slice>,\n",
       " <tf.Operation 'loss/Reshape_2' type=Reshape>,\n",
       " <tf.Operation 'loss/mul_1' type=Mul>,\n",
       " <tf.Operation 'loss/Const_1' type=Const>,\n",
       " <tf.Operation 'loss/Mean' type=Mean>,\n",
       " <tf.Operation 'loss/mul_2/x' type=Const>,\n",
       " <tf.Operation 'loss/mul_2' type=Mul>,\n",
       " <tf.Operation 'loss/add' type=Add>,\n",
       " <tf.Operation 'accuracy/ArgMax/dimension' type=Const>,\n",
       " <tf.Operation 'accuracy/ArgMax' type=ArgMax>,\n",
       " <tf.Operation 'accuracy/Equal' type=Equal>,\n",
       " <tf.Operation 'accuracy/Cast' type=Cast>,\n",
       " <tf.Operation 'accuracy/Const' type=Const>,\n",
       " <tf.Operation 'accuracy/accuracy' type=Mean>,\n",
       " <tf.Operation 'accuracy/ArgMax_1/dimension' type=Const>,\n",
       " <tf.Operation 'accuracy/ArgMax_1' type=ArgMax>,\n",
       " <tf.Operation 'accuracy/precision/Cast' type=Cast>,\n",
       " <tf.Operation 'accuracy/precision/Cast_1' type=Cast>,\n",
       " <tf.Operation 'accuracy/precision/true_positives/Equal/y' type=Const>,\n",
       " <tf.Operation 'accuracy/precision/true_positives/Equal' type=Equal>,\n",
       " <tf.Operation 'accuracy/precision/true_positives/Equal_1/y' type=Const>,\n",
       " <tf.Operation 'accuracy/precision/true_positives/Equal_1' type=Equal>,\n",
       " <tf.Operation 'accuracy/precision/true_positives/LogicalAnd' type=LogicalAnd>,\n",
       " <tf.Operation 'accuracy/precision/true_positives/assert_type/statically_determined_correct_type' type=NoOp>,\n",
       " <tf.Operation 'accuracy/precision/true_positives/count/Initializer/zeros' type=Const>,\n",
       " <tf.Operation 'accuracy/precision/true_positives/count' type=VariableV2>,\n",
       " <tf.Operation 'accuracy/precision/true_positives/count/Assign' type=Assign>,\n",
       " <tf.Operation 'accuracy/precision/true_positives/count/read' type=Identity>,\n",
       " <tf.Operation 'accuracy/precision/true_positives/ToFloat' type=Cast>,\n",
       " <tf.Operation 'accuracy/precision/true_positives/Identity' type=Identity>,\n",
       " <tf.Operation 'accuracy/precision/true_positives/Const' type=Const>,\n",
       " <tf.Operation 'accuracy/precision/true_positives/Sum' type=Sum>,\n",
       " <tf.Operation 'accuracy/precision/true_positives/AssignAdd' type=AssignAdd>,\n",
       " <tf.Operation 'accuracy/precision/false_positives/Equal/y' type=Const>,\n",
       " <tf.Operation 'accuracy/precision/false_positives/Equal' type=Equal>,\n",
       " <tf.Operation 'accuracy/precision/false_positives/Equal_1/y' type=Const>,\n",
       " <tf.Operation 'accuracy/precision/false_positives/Equal_1' type=Equal>,\n",
       " <tf.Operation 'accuracy/precision/false_positives/LogicalAnd' type=LogicalAnd>,\n",
       " <tf.Operation 'accuracy/precision/false_positives/assert_type/statically_determined_correct_type' type=NoOp>,\n",
       " <tf.Operation 'accuracy/precision/false_positives/count/Initializer/zeros' type=Const>,\n",
       " <tf.Operation 'accuracy/precision/false_positives/count' type=VariableV2>,\n",
       " <tf.Operation 'accuracy/precision/false_positives/count/Assign' type=Assign>,\n",
       " <tf.Operation 'accuracy/precision/false_positives/count/read' type=Identity>,\n",
       " <tf.Operation 'accuracy/precision/false_positives/ToFloat' type=Cast>,\n",
       " <tf.Operation 'accuracy/precision/false_positives/Identity' type=Identity>,\n",
       " <tf.Operation 'accuracy/precision/false_positives/Const' type=Const>,\n",
       " <tf.Operation 'accuracy/precision/false_positives/Sum' type=Sum>,\n",
       " <tf.Operation 'accuracy/precision/false_positives/AssignAdd' type=AssignAdd>,\n",
       " <tf.Operation 'accuracy/precision/add' type=Add>,\n",
       " <tf.Operation 'accuracy/precision/Greater/y' type=Const>,\n",
       " <tf.Operation 'accuracy/precision/Greater' type=Greater>,\n",
       " <tf.Operation 'accuracy/precision/add_1' type=Add>,\n",
       " <tf.Operation 'accuracy/precision/div' type=RealDiv>,\n",
       " <tf.Operation 'accuracy/precision/value/e' type=Const>,\n",
       " <tf.Operation 'accuracy/precision/value' type=Select>,\n",
       " <tf.Operation 'accuracy/precision/add_2' type=Add>,\n",
       " <tf.Operation 'accuracy/precision/Greater_1/y' type=Const>,\n",
       " <tf.Operation 'accuracy/precision/Greater_1' type=Greater>,\n",
       " <tf.Operation 'accuracy/precision/add_3' type=Add>,\n",
       " <tf.Operation 'accuracy/precision/div_1' type=RealDiv>,\n",
       " <tf.Operation 'accuracy/precision/update_op/e' type=Const>,\n",
       " <tf.Operation 'accuracy/precision/update_op' type=Select>,\n",
       " <tf.Operation 'accuracy/ArgMax_2/dimension' type=Const>,\n",
       " <tf.Operation 'accuracy/ArgMax_2' type=ArgMax>,\n",
       " <tf.Operation 'accuracy/recall/Cast' type=Cast>,\n",
       " <tf.Operation 'accuracy/recall/Cast_1' type=Cast>,\n",
       " <tf.Operation 'accuracy/recall/true_positives/Equal/y' type=Const>,\n",
       " <tf.Operation 'accuracy/recall/true_positives/Equal' type=Equal>,\n",
       " <tf.Operation 'accuracy/recall/true_positives/Equal_1/y' type=Const>,\n",
       " <tf.Operation 'accuracy/recall/true_positives/Equal_1' type=Equal>,\n",
       " <tf.Operation 'accuracy/recall/true_positives/LogicalAnd' type=LogicalAnd>,\n",
       " <tf.Operation 'accuracy/recall/true_positives/assert_type/statically_determined_correct_type' type=NoOp>,\n",
       " <tf.Operation 'accuracy/recall/true_positives/count/Initializer/zeros' type=Const>,\n",
       " <tf.Operation 'accuracy/recall/true_positives/count' type=VariableV2>,\n",
       " <tf.Operation 'accuracy/recall/true_positives/count/Assign' type=Assign>,\n",
       " <tf.Operation 'accuracy/recall/true_positives/count/read' type=Identity>,\n",
       " <tf.Operation 'accuracy/recall/true_positives/ToFloat' type=Cast>,\n",
       " <tf.Operation 'accuracy/recall/true_positives/Identity' type=Identity>,\n",
       " <tf.Operation 'accuracy/recall/true_positives/Const' type=Const>,\n",
       " <tf.Operation 'accuracy/recall/true_positives/Sum' type=Sum>,\n",
       " <tf.Operation 'accuracy/recall/true_positives/AssignAdd' type=AssignAdd>,\n",
       " <tf.Operation 'accuracy/recall/false_negatives/Equal/y' type=Const>,\n",
       " <tf.Operation 'accuracy/recall/false_negatives/Equal' type=Equal>,\n",
       " <tf.Operation 'accuracy/recall/false_negatives/Equal_1/y' type=Const>,\n",
       " <tf.Operation 'accuracy/recall/false_negatives/Equal_1' type=Equal>,\n",
       " <tf.Operation 'accuracy/recall/false_negatives/LogicalAnd' type=LogicalAnd>,\n",
       " <tf.Operation 'accuracy/recall/false_negatives/assert_type/statically_determined_correct_type' type=NoOp>,\n",
       " <tf.Operation 'accuracy/recall/false_negatives/count/Initializer/zeros' type=Const>,\n",
       " <tf.Operation 'accuracy/recall/false_negatives/count' type=VariableV2>,\n",
       " <tf.Operation 'accuracy/recall/false_negatives/count/Assign' type=Assign>,\n",
       " <tf.Operation 'accuracy/recall/false_negatives/count/read' type=Identity>,\n",
       " <tf.Operation 'accuracy/recall/false_negatives/ToFloat' type=Cast>,\n",
       " <tf.Operation 'accuracy/recall/false_negatives/Identity' type=Identity>,\n",
       " <tf.Operation 'accuracy/recall/false_negatives/Const' type=Const>,\n",
       " <tf.Operation 'accuracy/recall/false_negatives/Sum' type=Sum>,\n",
       " <tf.Operation 'accuracy/recall/false_negatives/AssignAdd' type=AssignAdd>,\n",
       " <tf.Operation 'accuracy/recall/add' type=Add>,\n",
       " <tf.Operation 'accuracy/recall/Greater/y' type=Const>,\n",
       " <tf.Operation 'accuracy/recall/Greater' type=Greater>,\n",
       " <tf.Operation 'accuracy/recall/add_1' type=Add>,\n",
       " <tf.Operation 'accuracy/recall/div' type=RealDiv>,\n",
       " <tf.Operation 'accuracy/recall/value/e' type=Const>,\n",
       " <tf.Operation 'accuracy/recall/value' type=Select>,\n",
       " <tf.Operation 'accuracy/recall/add_2' type=Add>,\n",
       " <tf.Operation 'accuracy/recall/Greater_1/y' type=Const>,\n",
       " <tf.Operation 'accuracy/recall/Greater_1' type=Greater>,\n",
       " <tf.Operation 'accuracy/recall/add_3' type=Add>,\n",
       " <tf.Operation 'accuracy/recall/div_1' type=RealDiv>,\n",
       " <tf.Operation 'accuracy/recall/update_op/e' type=Const>,\n",
       " <tf.Operation 'accuracy/recall/update_op' type=Select>,\n",
       " <tf.Operation 'global_step/initial_value' type=Const>,\n",
       " <tf.Operation 'global_step' type=VariableV2>,\n",
       " <tf.Operation 'global_step/Assign' type=Assign>,\n",
       " <tf.Operation 'global_step/read' type=Identity>,\n",
       " <tf.Operation 'gradients/Shape' type=Const>,\n",
       " <tf.Operation 'gradients/Const' type=Const>,\n",
       " <tf.Operation 'gradients/Fill' type=Fill>,\n",
       " <tf.Operation 'gradients/loss/add_grad/Shape' type=Const>,\n",
       " <tf.Operation 'gradients/loss/add_grad/Shape_1' type=Const>,\n",
       " <tf.Operation 'gradients/loss/add_grad/BroadcastGradientArgs' type=BroadcastGradientArgs>,\n",
       " <tf.Operation 'gradients/loss/add_grad/Sum' type=Sum>,\n",
       " <tf.Operation 'gradients/loss/add_grad/Reshape' type=Reshape>,\n",
       " <tf.Operation 'gradients/loss/add_grad/Sum_1' type=Sum>,\n",
       " <tf.Operation 'gradients/loss/add_grad/Reshape_1' type=Reshape>,\n",
       " <tf.Operation 'gradients/loss/add_grad/tuple/group_deps' type=NoOp>,\n",
       " <tf.Operation 'gradients/loss/add_grad/tuple/control_dependency' type=Identity>,\n",
       " <tf.Operation 'gradients/loss/add_grad/tuple/control_dependency_1' type=Identity>,\n",
       " <tf.Operation 'gradients/loss/Mean_grad/Reshape/shape' type=Const>,\n",
       " <tf.Operation 'gradients/loss/Mean_grad/Reshape' type=Reshape>,\n",
       " <tf.Operation 'gradients/loss/Mean_grad/Shape' type=Shape>,\n",
       " <tf.Operation 'gradients/loss/Mean_grad/Tile' type=Tile>,\n",
       " <tf.Operation 'gradients/loss/Mean_grad/Shape_1' type=Shape>,\n",
       " <tf.Operation 'gradients/loss/Mean_grad/Shape_2' type=Const>,\n",
       " <tf.Operation 'gradients/loss/Mean_grad/Const' type=Const>,\n",
       " <tf.Operation 'gradients/loss/Mean_grad/Prod' type=Prod>,\n",
       " <tf.Operation 'gradients/loss/Mean_grad/Const_1' type=Const>,\n",
       " <tf.Operation 'gradients/loss/Mean_grad/Prod_1' type=Prod>,\n",
       " <tf.Operation 'gradients/loss/Mean_grad/Maximum/y' type=Const>,\n",
       " <tf.Operation 'gradients/loss/Mean_grad/Maximum' type=Maximum>,\n",
       " <tf.Operation 'gradients/loss/Mean_grad/floordiv' type=FloorDiv>,\n",
       " <tf.Operation 'gradients/loss/Mean_grad/Cast' type=Cast>,\n",
       " <tf.Operation 'gradients/loss/Mean_grad/truediv' type=RealDiv>,\n",
       " <tf.Operation 'gradients/loss/mul_2_grad/Shape' type=Const>,\n",
       " <tf.Operation 'gradients/loss/mul_2_grad/Shape_1' type=Const>,\n",
       " <tf.Operation 'gradients/loss/mul_2_grad/BroadcastGradientArgs' type=BroadcastGradientArgs>,\n",
       " <tf.Operation 'gradients/loss/mul_2_grad/mul' type=Mul>,\n",
       " <tf.Operation 'gradients/loss/mul_2_grad/Sum' type=Sum>,\n",
       " <tf.Operation 'gradients/loss/mul_2_grad/Reshape' type=Reshape>,\n",
       " <tf.Operation 'gradients/loss/mul_2_grad/mul_1' type=Mul>,\n",
       " <tf.Operation 'gradients/loss/mul_2_grad/Sum_1' type=Sum>,\n",
       " <tf.Operation 'gradients/loss/mul_2_grad/Reshape_1' type=Reshape>,\n",
       " <tf.Operation 'gradients/loss/mul_2_grad/tuple/group_deps' type=NoOp>,\n",
       " <tf.Operation 'gradients/loss/mul_2_grad/tuple/control_dependency' type=Identity>,\n",
       " <tf.Operation 'gradients/loss/mul_2_grad/tuple/control_dependency_1' type=Identity>,\n",
       " <tf.Operation 'gradients/loss/mul_1_grad/Shape' type=Shape>,\n",
       " <tf.Operation 'gradients/loss/mul_1_grad/Shape_1' type=Shape>,\n",
       " <tf.Operation 'gradients/loss/mul_1_grad/BroadcastGradientArgs' type=BroadcastGradientArgs>,\n",
       " <tf.Operation 'gradients/loss/mul_1_grad/mul' type=Mul>,\n",
       " <tf.Operation 'gradients/loss/mul_1_grad/Sum' type=Sum>,\n",
       " <tf.Operation 'gradients/loss/mul_1_grad/Reshape' type=Reshape>,\n",
       " <tf.Operation 'gradients/loss/mul_1_grad/mul_1' type=Mul>,\n",
       " <tf.Operation 'gradients/loss/mul_1_grad/Sum_1' type=Sum>,\n",
       " <tf.Operation 'gradients/loss/mul_1_grad/Reshape_1' type=Reshape>,\n",
       " <tf.Operation 'gradients/loss/mul_1_grad/tuple/group_deps' type=NoOp>,\n",
       " <tf.Operation 'gradients/loss/mul_1_grad/tuple/control_dependency' type=Identity>,\n",
       " <tf.Operation 'gradients/loss/mul_1_grad/tuple/control_dependency_1' type=Identity>,\n",
       " <tf.Operation 'gradients/output/add_1_grad/Shape' type=Const>,\n",
       " <tf.Operation 'gradients/output/add_1_grad/Shape_1' type=Const>,\n",
       " <tf.Operation 'gradients/output/add_1_grad/BroadcastGradientArgs' type=BroadcastGradientArgs>,\n",
       " <tf.Operation 'gradients/output/add_1_grad/Sum' type=Sum>,\n",
       " <tf.Operation 'gradients/output/add_1_grad/Reshape' type=Reshape>,\n",
       " <tf.Operation 'gradients/output/add_1_grad/Sum_1' type=Sum>,\n",
       " <tf.Operation 'gradients/output/add_1_grad/Reshape_1' type=Reshape>,\n",
       " <tf.Operation 'gradients/output/add_1_grad/tuple/group_deps' type=NoOp>,\n",
       " <tf.Operation 'gradients/output/add_1_grad/tuple/control_dependency' type=Identity>,\n",
       " <tf.Operation 'gradients/output/add_1_grad/tuple/control_dependency_1' type=Identity>,\n",
       " <tf.Operation 'gradients/loss/Reshape_2_grad/Shape' type=Shape>,\n",
       " <tf.Operation 'gradients/loss/Reshape_2_grad/Reshape' type=Reshape>,\n",
       " <tf.Operation 'gradients/output/add_grad/Shape' type=Const>,\n",
       " <tf.Operation 'gradients/output/add_grad/Shape_1' type=Const>,\n",
       " <tf.Operation 'gradients/output/add_grad/BroadcastGradientArgs' type=BroadcastGradientArgs>,\n",
       " <tf.Operation 'gradients/output/add_grad/Sum' type=Sum>,\n",
       " <tf.Operation 'gradients/output/add_grad/Reshape' type=Reshape>,\n",
       " <tf.Operation 'gradients/output/add_grad/Sum_1' type=Sum>,\n",
       " <tf.Operation 'gradients/output/add_grad/Reshape_1' type=Reshape>,\n",
       " <tf.Operation 'gradients/output/add_grad/tuple/group_deps' type=NoOp>,\n",
       " <tf.Operation 'gradients/output/add_grad/tuple/control_dependency' type=Identity>,\n",
       " <tf.Operation 'gradients/output/add_grad/tuple/control_dependency_1' type=Identity>,\n",
       " <tf.Operation 'gradients/output/L2Loss_1_grad/mul' type=Mul>,\n",
       " <tf.Operation 'gradients/zeros_like' type=ZerosLike>,\n",
       " <tf.Operation 'gradients/loss/SoftmaxCrossEntropyWithLogits_grad/ExpandDims/dim' type=Const>,\n",
       " <tf.Operation 'gradients/loss/SoftmaxCrossEntropyWithLogits_grad/ExpandDims' type=ExpandDims>,\n",
       " <tf.Operation 'gradients/loss/SoftmaxCrossEntropyWithLogits_grad/mul' type=Mul>,\n",
       " <tf.Operation 'gradients/output/L2Loss_grad/mul' type=Mul>,\n",
       " <tf.Operation 'gradients/loss/Reshape_grad/Shape' type=Shape>,\n",
       " <tf.Operation 'gradients/loss/Reshape_grad/Reshape' type=Reshape>,\n",
       " <tf.Operation 'gradients/output/scores_grad/BiasAddGrad' type=BiasAddGrad>,\n",
       " <tf.Operation 'gradients/output/scores_grad/tuple/group_deps' type=NoOp>,\n",
       " <tf.Operation 'gradients/output/scores_grad/tuple/control_dependency' type=Identity>,\n",
       " <tf.Operation 'gradients/output/scores_grad/tuple/control_dependency_1' type=Identity>,\n",
       " <tf.Operation 'gradients/output/scores/MatMul_grad/MatMul' type=MatMul>,\n",
       " <tf.Operation 'gradients/output/scores/MatMul_grad/MatMul_1' type=MatMul>,\n",
       " <tf.Operation 'gradients/output/scores/MatMul_grad/tuple/group_deps' type=NoOp>,\n",
       " <tf.Operation 'gradients/output/scores/MatMul_grad/tuple/control_dependency' type=Identity>,\n",
       " <tf.Operation 'gradients/output/scores/MatMul_grad/tuple/control_dependency_1' type=Identity>,\n",
       " <tf.Operation 'gradients/AddN' type=AddN>,\n",
       " <tf.Operation 'gradients/dropout/dropout/mul_grad/Shape' type=Shape>,\n",
       " <tf.Operation 'gradients/dropout/dropout/mul_grad/Shape_1' type=Shape>,\n",
       " <tf.Operation 'gradients/dropout/dropout/mul_grad/BroadcastGradientArgs' type=BroadcastGradientArgs>,\n",
       " <tf.Operation 'gradients/dropout/dropout/mul_grad/mul' type=Mul>,\n",
       " <tf.Operation 'gradients/dropout/dropout/mul_grad/Sum' type=Sum>,\n",
       " <tf.Operation 'gradients/dropout/dropout/mul_grad/Reshape' type=Reshape>,\n",
       " <tf.Operation 'gradients/dropout/dropout/mul_grad/mul_1' type=Mul>,\n",
       " <tf.Operation 'gradients/dropout/dropout/mul_grad/Sum_1' type=Sum>,\n",
       " <tf.Operation 'gradients/dropout/dropout/mul_grad/Reshape_1' type=Reshape>,\n",
       " <tf.Operation 'gradients/dropout/dropout/mul_grad/tuple/group_deps' type=NoOp>,\n",
       " <tf.Operation 'gradients/dropout/dropout/mul_grad/tuple/control_dependency' type=Identity>,\n",
       " <tf.Operation 'gradients/dropout/dropout/mul_grad/tuple/control_dependency_1' type=Identity>,\n",
       " <tf.Operation 'gradients/AddN_1' type=AddN>,\n",
       " <tf.Operation 'gradients/dropout/dropout/div_grad/Shape' type=Shape>,\n",
       " <tf.Operation 'gradients/dropout/dropout/div_grad/Shape_1' type=Shape>,\n",
       " <tf.Operation 'gradients/dropout/dropout/div_grad/BroadcastGradientArgs' type=BroadcastGradientArgs>,\n",
       " <tf.Operation 'gradients/dropout/dropout/div_grad/RealDiv' type=RealDiv>,\n",
       " <tf.Operation 'gradients/dropout/dropout/div_grad/Sum' type=Sum>,\n",
       " <tf.Operation 'gradients/dropout/dropout/div_grad/Reshape' type=Reshape>,\n",
       " <tf.Operation 'gradients/dropout/dropout/div_grad/Neg' type=Neg>,\n",
       " <tf.Operation 'gradients/dropout/dropout/div_grad/RealDiv_1' type=RealDiv>,\n",
       " <tf.Operation 'gradients/dropout/dropout/div_grad/RealDiv_2' type=RealDiv>,\n",
       " <tf.Operation 'gradients/dropout/dropout/div_grad/mul' type=Mul>,\n",
       " <tf.Operation 'gradients/dropout/dropout/div_grad/Sum_1' type=Sum>,\n",
       " <tf.Operation 'gradients/dropout/dropout/div_grad/Reshape_1' type=Reshape>,\n",
       " <tf.Operation 'gradients/dropout/dropout/div_grad/tuple/group_deps' type=NoOp>,\n",
       " <tf.Operation 'gradients/dropout/dropout/div_grad/tuple/control_dependency' type=Identity>,\n",
       " <tf.Operation 'gradients/dropout/dropout/div_grad/tuple/control_dependency_1' type=Identity>,\n",
       " <tf.Operation 'gradients/Reshape_grad/Shape' type=Shape>,\n",
       " <tf.Operation 'gradients/Reshape_grad/Reshape' type=Reshape>,\n",
       " <tf.Operation 'gradients/concat_grad/Rank' type=Const>,\n",
       " <tf.Operation 'gradients/concat_grad/mod' type=FloorMod>,\n",
       " <tf.Operation 'gradients/concat_grad/Shape' type=Shape>,\n",
       " <tf.Operation 'gradients/concat_grad/ShapeN' type=ShapeN>,\n",
       " <tf.Operation 'gradients/concat_grad/ConcatOffset' type=ConcatOffset>,\n",
       " <tf.Operation 'gradients/concat_grad/Slice' type=Slice>,\n",
       " <tf.Operation 'gradients/concat_grad/Slice_1' type=Slice>,\n",
       " <tf.Operation 'gradients/concat_grad/Slice_2' type=Slice>,\n",
       " <tf.Operation 'gradients/concat_grad/tuple/group_deps' type=NoOp>,\n",
       " <tf.Operation 'gradients/concat_grad/tuple/control_dependency' type=Identity>,\n",
       " <tf.Operation 'gradients/concat_grad/tuple/control_dependency_1' type=Identity>,\n",
       " <tf.Operation 'gradients/concat_grad/tuple/control_dependency_2' type=Identity>,\n",
       " <tf.Operation 'gradients/conv-maxpool-3/pool_grad/MaxPoolGrad' type=MaxPoolGrad>,\n",
       " <tf.Operation 'gradients/conv-maxpool-4/pool_grad/MaxPoolGrad' type=MaxPoolGrad>,\n",
       " <tf.Operation 'gradients/conv-maxpool-5/pool_grad/MaxPoolGrad' type=MaxPoolGrad>,\n",
       " <tf.Operation 'gradients/conv-maxpool-3/relu_grad/ReluGrad' type=ReluGrad>,\n",
       " <tf.Operation 'gradients/conv-maxpool-4/relu_grad/ReluGrad' type=ReluGrad>,\n",
       " <tf.Operation 'gradients/conv-maxpool-5/relu_grad/ReluGrad' type=ReluGrad>,\n",
       " <tf.Operation 'gradients/conv-maxpool-3/BiasAdd_grad/BiasAddGrad' type=BiasAddGrad>,\n",
       " <tf.Operation 'gradients/conv-maxpool-3/BiasAdd_grad/tuple/group_deps' type=NoOp>,\n",
       " <tf.Operation 'gradients/conv-maxpool-3/BiasAdd_grad/tuple/control_dependency' type=Identity>,\n",
       " <tf.Operation 'gradients/conv-maxpool-3/BiasAdd_grad/tuple/control_dependency_1' type=Identity>,\n",
       " <tf.Operation 'gradients/conv-maxpool-4/BiasAdd_grad/BiasAddGrad' type=BiasAddGrad>,\n",
       " <tf.Operation 'gradients/conv-maxpool-4/BiasAdd_grad/tuple/group_deps' type=NoOp>,\n",
       " <tf.Operation 'gradients/conv-maxpool-4/BiasAdd_grad/tuple/control_dependency' type=Identity>,\n",
       " <tf.Operation 'gradients/conv-maxpool-4/BiasAdd_grad/tuple/control_dependency_1' type=Identity>,\n",
       " <tf.Operation 'gradients/conv-maxpool-5/BiasAdd_grad/BiasAddGrad' type=BiasAddGrad>,\n",
       " <tf.Operation 'gradients/conv-maxpool-5/BiasAdd_grad/tuple/group_deps' type=NoOp>,\n",
       " <tf.Operation 'gradients/conv-maxpool-5/BiasAdd_grad/tuple/control_dependency' type=Identity>,\n",
       " <tf.Operation 'gradients/conv-maxpool-5/BiasAdd_grad/tuple/control_dependency_1' type=Identity>,\n",
       " <tf.Operation 'gradients/conv-maxpool-3/conv_grad/Shape' type=Shape>,\n",
       " <tf.Operation 'gradients/conv-maxpool-3/conv_grad/Conv2DBackpropInput' type=Conv2DBackpropInput>,\n",
       " <tf.Operation 'gradients/conv-maxpool-3/conv_grad/Shape_1' type=Const>,\n",
       " <tf.Operation 'gradients/conv-maxpool-3/conv_grad/Conv2DBackpropFilter' type=Conv2DBackpropFilter>,\n",
       " <tf.Operation 'gradients/conv-maxpool-3/conv_grad/tuple/group_deps' type=NoOp>,\n",
       " <tf.Operation 'gradients/conv-maxpool-3/conv_grad/tuple/control_dependency' type=Identity>,\n",
       " <tf.Operation 'gradients/conv-maxpool-3/conv_grad/tuple/control_dependency_1' type=Identity>,\n",
       " <tf.Operation 'gradients/conv-maxpool-4/conv_grad/Shape' type=Shape>,\n",
       " <tf.Operation 'gradients/conv-maxpool-4/conv_grad/Conv2DBackpropInput' type=Conv2DBackpropInput>,\n",
       " <tf.Operation 'gradients/conv-maxpool-4/conv_grad/Shape_1' type=Const>,\n",
       " <tf.Operation 'gradients/conv-maxpool-4/conv_grad/Conv2DBackpropFilter' type=Conv2DBackpropFilter>,\n",
       " <tf.Operation 'gradients/conv-maxpool-4/conv_grad/tuple/group_deps' type=NoOp>,\n",
       " <tf.Operation 'gradients/conv-maxpool-4/conv_grad/tuple/control_dependency' type=Identity>,\n",
       " <tf.Operation 'gradients/conv-maxpool-4/conv_grad/tuple/control_dependency_1' type=Identity>,\n",
       " <tf.Operation 'gradients/conv-maxpool-5/conv_grad/Shape' type=Shape>,\n",
       " <tf.Operation 'gradients/conv-maxpool-5/conv_grad/Conv2DBackpropInput' type=Conv2DBackpropInput>,\n",
       " <tf.Operation 'gradients/conv-maxpool-5/conv_grad/Shape_1' type=Const>,\n",
       " <tf.Operation 'gradients/conv-maxpool-5/conv_grad/Conv2DBackpropFilter' type=Conv2DBackpropFilter>,\n",
       " <tf.Operation 'gradients/conv-maxpool-5/conv_grad/tuple/group_deps' type=NoOp>,\n",
       " <tf.Operation 'gradients/conv-maxpool-5/conv_grad/tuple/control_dependency' type=Identity>,\n",
       " <tf.Operation 'gradients/conv-maxpool-5/conv_grad/tuple/control_dependency_1' type=Identity>,\n",
       " <tf.Operation 'gradients/AddN_2' type=AddN>,\n",
       " <tf.Operation 'gradients/embedding/concat_grad/Rank' type=Const>,\n",
       " <tf.Operation 'gradients/embedding/concat_grad/mod' type=FloorMod>,\n",
       " <tf.Operation 'gradients/embedding/concat_grad/Shape' type=Shape>,\n",
       " <tf.Operation 'gradients/embedding/concat_grad/ShapeN' type=ShapeN>,\n",
       " <tf.Operation 'gradients/embedding/concat_grad/ConcatOffset' type=ConcatOffset>,\n",
       " <tf.Operation 'gradients/embedding/concat_grad/Slice' type=Slice>,\n",
       " <tf.Operation 'gradients/embedding/concat_grad/Slice_1' type=Slice>,\n",
       " <tf.Operation 'gradients/embedding/concat_grad/Slice_2' type=Slice>,\n",
       " <tf.Operation 'gradients/embedding/concat_grad/tuple/group_deps' type=NoOp>,\n",
       " <tf.Operation 'gradients/embedding/concat_grad/tuple/control_dependency' type=Identity>,\n",
       " <tf.Operation 'gradients/embedding/concat_grad/tuple/control_dependency_1' type=Identity>,\n",
       " <tf.Operation 'gradients/embedding/concat_grad/tuple/control_dependency_2' type=Identity>,\n",
       " <tf.Operation 'gradients/word_embedding/ExpandDims_grad/Shape' type=Shape>,\n",
       " <tf.Operation 'gradients/word_embedding/ExpandDims_grad/Reshape' type=Reshape>,\n",
       " <tf.Operation 'gradients/word_embedding/embedding_lookup_grad/Shape' type=Const>,\n",
       " <tf.Operation 'gradients/word_embedding/embedding_lookup_grad/ToInt32' type=Cast>,\n",
       " <tf.Operation 'gradients/word_embedding/embedding_lookup_grad/Size' type=Size>,\n",
       " <tf.Operation 'gradients/word_embedding/embedding_lookup_grad/ExpandDims/dim' type=Const>,\n",
       " <tf.Operation 'gradients/word_embedding/embedding_lookup_grad/ExpandDims' type=ExpandDims>,\n",
       " <tf.Operation 'gradients/word_embedding/embedding_lookup_grad/strided_slice/stack' type=Const>,\n",
       " <tf.Operation 'gradients/word_embedding/embedding_lookup_grad/strided_slice/stack_1' type=Const>,\n",
       " <tf.Operation 'gradients/word_embedding/embedding_lookup_grad/strided_slice/stack_2' type=Const>,\n",
       " <tf.Operation 'gradients/word_embedding/embedding_lookup_grad/strided_slice' type=StridedSlice>,\n",
       " <tf.Operation 'gradients/word_embedding/embedding_lookup_grad/concat/axis' type=Const>,\n",
       " <tf.Operation 'gradients/word_embedding/embedding_lookup_grad/concat' type=ConcatV2>,\n",
       " <tf.Operation 'gradients/word_embedding/embedding_lookup_grad/Reshape' type=Reshape>,\n",
       " <tf.Operation 'gradients/word_embedding/embedding_lookup_grad/Reshape_1' type=Reshape>,\n",
       " <tf.Operation 'beta1_power/initial_value' type=Const>,\n",
       " <tf.Operation 'beta1_power' type=VariableV2>,\n",
       " <tf.Operation 'beta1_power/Assign' type=Assign>,\n",
       " <tf.Operation 'beta1_power/read' type=Identity>,\n",
       " <tf.Operation 'beta2_power/initial_value' type=Const>,\n",
       " <tf.Operation 'beta2_power' type=VariableV2>,\n",
       " <tf.Operation 'beta2_power/Assign' type=Assign>,\n",
       " <tf.Operation 'beta2_power/read' type=Identity>,\n",
       " <tf.Operation 'word_embedding/W/Adam/Initializer/zeros' type=Const>,\n",
       " <tf.Operation 'word_embedding/W/Adam' type=VariableV2>,\n",
       " <tf.Operation 'word_embedding/W/Adam/Assign' type=Assign>,\n",
       " <tf.Operation 'word_embedding/W/Adam/read' type=Identity>,\n",
       " <tf.Operation 'word_embedding/W/Adam_1/Initializer/zeros' type=Const>,\n",
       " <tf.Operation 'word_embedding/W/Adam_1' type=VariableV2>,\n",
       " <tf.Operation 'word_embedding/W/Adam_1/Assign' type=Assign>,\n",
       " <tf.Operation 'word_embedding/W/Adam_1/read' type=Identity>,\n",
       " <tf.Operation 'conv-maxpool-3/W/Adam/Initializer/zeros' type=Const>,\n",
       " <tf.Operation 'conv-maxpool-3/W/Adam' type=VariableV2>,\n",
       " <tf.Operation 'conv-maxpool-3/W/Adam/Assign' type=Assign>,\n",
       " <tf.Operation 'conv-maxpool-3/W/Adam/read' type=Identity>,\n",
       " <tf.Operation 'conv-maxpool-3/W/Adam_1/Initializer/zeros' type=Const>,\n",
       " <tf.Operation 'conv-maxpool-3/W/Adam_1' type=VariableV2>,\n",
       " <tf.Operation 'conv-maxpool-3/W/Adam_1/Assign' type=Assign>,\n",
       " <tf.Operation 'conv-maxpool-3/W/Adam_1/read' type=Identity>,\n",
       " <tf.Operation 'conv-maxpool-3/b/Adam/Initializer/zeros' type=Const>,\n",
       " <tf.Operation 'conv-maxpool-3/b/Adam' type=VariableV2>,\n",
       " <tf.Operation 'conv-maxpool-3/b/Adam/Assign' type=Assign>,\n",
       " <tf.Operation 'conv-maxpool-3/b/Adam/read' type=Identity>,\n",
       " <tf.Operation 'conv-maxpool-3/b/Adam_1/Initializer/zeros' type=Const>,\n",
       " <tf.Operation 'conv-maxpool-3/b/Adam_1' type=VariableV2>,\n",
       " <tf.Operation 'conv-maxpool-3/b/Adam_1/Assign' type=Assign>,\n",
       " <tf.Operation 'conv-maxpool-3/b/Adam_1/read' type=Identity>,\n",
       " <tf.Operation 'conv-maxpool-4/W/Adam/Initializer/zeros' type=Const>,\n",
       " <tf.Operation 'conv-maxpool-4/W/Adam' type=VariableV2>,\n",
       " <tf.Operation 'conv-maxpool-4/W/Adam/Assign' type=Assign>,\n",
       " <tf.Operation 'conv-maxpool-4/W/Adam/read' type=Identity>,\n",
       " <tf.Operation 'conv-maxpool-4/W/Adam_1/Initializer/zeros' type=Const>,\n",
       " <tf.Operation 'conv-maxpool-4/W/Adam_1' type=VariableV2>,\n",
       " <tf.Operation 'conv-maxpool-4/W/Adam_1/Assign' type=Assign>,\n",
       " <tf.Operation 'conv-maxpool-4/W/Adam_1/read' type=Identity>,\n",
       " <tf.Operation 'conv-maxpool-4/b/Adam/Initializer/zeros' type=Const>,\n",
       " <tf.Operation 'conv-maxpool-4/b/Adam' type=VariableV2>,\n",
       " <tf.Operation 'conv-maxpool-4/b/Adam/Assign' type=Assign>,\n",
       " <tf.Operation 'conv-maxpool-4/b/Adam/read' type=Identity>,\n",
       " <tf.Operation 'conv-maxpool-4/b/Adam_1/Initializer/zeros' type=Const>,\n",
       " <tf.Operation 'conv-maxpool-4/b/Adam_1' type=VariableV2>,\n",
       " <tf.Operation 'conv-maxpool-4/b/Adam_1/Assign' type=Assign>,\n",
       " <tf.Operation 'conv-maxpool-4/b/Adam_1/read' type=Identity>,\n",
       " <tf.Operation 'conv-maxpool-5/W/Adam/Initializer/zeros' type=Const>,\n",
       " <tf.Operation 'conv-maxpool-5/W/Adam' type=VariableV2>,\n",
       " <tf.Operation 'conv-maxpool-5/W/Adam/Assign' type=Assign>,\n",
       " <tf.Operation 'conv-maxpool-5/W/Adam/read' type=Identity>,\n",
       " <tf.Operation 'conv-maxpool-5/W/Adam_1/Initializer/zeros' type=Const>,\n",
       " <tf.Operation 'conv-maxpool-5/W/Adam_1' type=VariableV2>,\n",
       " <tf.Operation 'conv-maxpool-5/W/Adam_1/Assign' type=Assign>,\n",
       " <tf.Operation 'conv-maxpool-5/W/Adam_1/read' type=Identity>,\n",
       " <tf.Operation 'conv-maxpool-5/b/Adam/Initializer/zeros' type=Const>,\n",
       " <tf.Operation 'conv-maxpool-5/b/Adam' type=VariableV2>,\n",
       " <tf.Operation 'conv-maxpool-5/b/Adam/Assign' type=Assign>,\n",
       " <tf.Operation 'conv-maxpool-5/b/Adam/read' type=Identity>,\n",
       " <tf.Operation 'conv-maxpool-5/b/Adam_1/Initializer/zeros' type=Const>,\n",
       " <tf.Operation 'conv-maxpool-5/b/Adam_1' type=VariableV2>,\n",
       " <tf.Operation 'conv-maxpool-5/b/Adam_1/Assign' type=Assign>,\n",
       " <tf.Operation 'conv-maxpool-5/b/Adam_1/read' type=Identity>,\n",
       " <tf.Operation 'W/Adam/Initializer/zeros' type=Const>,\n",
       " <tf.Operation 'W/Adam' type=VariableV2>,\n",
       " <tf.Operation 'W/Adam/Assign' type=Assign>,\n",
       " <tf.Operation 'W/Adam/read' type=Identity>,\n",
       " <tf.Operation 'W/Adam_1/Initializer/zeros' type=Const>,\n",
       " <tf.Operation 'W/Adam_1' type=VariableV2>,\n",
       " <tf.Operation 'W/Adam_1/Assign' type=Assign>,\n",
       " <tf.Operation 'W/Adam_1/read' type=Identity>,\n",
       " <tf.Operation 'output/b/Adam/Initializer/zeros' type=Const>,\n",
       " <tf.Operation 'output/b/Adam' type=VariableV2>,\n",
       " <tf.Operation 'output/b/Adam/Assign' type=Assign>,\n",
       " <tf.Operation 'output/b/Adam/read' type=Identity>,\n",
       " <tf.Operation 'output/b/Adam_1/Initializer/zeros' type=Const>,\n",
       " <tf.Operation 'output/b/Adam_1' type=VariableV2>,\n",
       " <tf.Operation 'output/b/Adam_1/Assign' type=Assign>,\n",
       " <tf.Operation 'output/b/Adam_1/read' type=Identity>,\n",
       " <tf.Operation 'Adam/learning_rate' type=Const>,\n",
       " <tf.Operation 'Adam/beta1' type=Const>,\n",
       " <tf.Operation 'Adam/beta2' type=Const>,\n",
       " <tf.Operation 'Adam/epsilon' type=Const>,\n",
       " <tf.Operation 'Adam/update_word_embedding/W/Unique' type=Unique>,\n",
       " <tf.Operation 'Adam/update_word_embedding/W/Shape' type=Shape>,\n",
       " <tf.Operation 'Adam/update_word_embedding/W/strided_slice/stack' type=Const>,\n",
       " <tf.Operation 'Adam/update_word_embedding/W/strided_slice/stack_1' type=Const>,\n",
       " <tf.Operation 'Adam/update_word_embedding/W/strided_slice/stack_2' type=Const>,\n",
       " <tf.Operation 'Adam/update_word_embedding/W/strided_slice' type=StridedSlice>,\n",
       " <tf.Operation 'Adam/update_word_embedding/W/UnsortedSegmentSum' type=UnsortedSegmentSum>,\n",
       " <tf.Operation 'Adam/update_word_embedding/W/sub/x' type=Const>,\n",
       " <tf.Operation 'Adam/update_word_embedding/W/sub' type=Sub>,\n",
       " <tf.Operation 'Adam/update_word_embedding/W/Sqrt' type=Sqrt>,\n",
       " <tf.Operation 'Adam/update_word_embedding/W/mul' type=Mul>,\n",
       " <tf.Operation 'Adam/update_word_embedding/W/sub_1/x' type=Const>,\n",
       " <tf.Operation 'Adam/update_word_embedding/W/sub_1' type=Sub>,\n",
       " <tf.Operation 'Adam/update_word_embedding/W/truediv' type=RealDiv>,\n",
       " <tf.Operation 'Adam/update_word_embedding/W/sub_2/x' type=Const>,\n",
       " <tf.Operation 'Adam/update_word_embedding/W/sub_2' type=Sub>,\n",
       " <tf.Operation 'Adam/update_word_embedding/W/mul_1' type=Mul>,\n",
       " <tf.Operation 'Adam/update_word_embedding/W/mul_2' type=Mul>,\n",
       " <tf.Operation 'Adam/update_word_embedding/W/Assign' type=Assign>,\n",
       " <tf.Operation 'Adam/update_word_embedding/W/ScatterAdd' type=ScatterAdd>,\n",
       " <tf.Operation 'Adam/update_word_embedding/W/mul_3' type=Mul>,\n",
       " <tf.Operation 'Adam/update_word_embedding/W/sub_3/x' type=Const>,\n",
       " <tf.Operation 'Adam/update_word_embedding/W/sub_3' type=Sub>,\n",
       " <tf.Operation 'Adam/update_word_embedding/W/mul_4' type=Mul>,\n",
       " <tf.Operation 'Adam/update_word_embedding/W/mul_5' type=Mul>,\n",
       " <tf.Operation 'Adam/update_word_embedding/W/Assign_1' type=Assign>,\n",
       " <tf.Operation 'Adam/update_word_embedding/W/ScatterAdd_1' type=ScatterAdd>,\n",
       " <tf.Operation 'Adam/update_word_embedding/W/Sqrt_1' type=Sqrt>,\n",
       " <tf.Operation 'Adam/update_word_embedding/W/mul_6' type=Mul>,\n",
       " <tf.Operation 'Adam/update_word_embedding/W/add' type=Add>,\n",
       " <tf.Operation 'Adam/update_word_embedding/W/truediv_1' type=RealDiv>,\n",
       " <tf.Operation 'Adam/update_word_embedding/W/AssignSub' type=AssignSub>,\n",
       " <tf.Operation 'Adam/update_word_embedding/W/group_deps' type=NoOp>,\n",
       " <tf.Operation 'Adam/update_conv-maxpool-3/W/ApplyAdam' type=ApplyAdam>,\n",
       " <tf.Operation 'Adam/update_conv-maxpool-3/b/ApplyAdam' type=ApplyAdam>,\n",
       " <tf.Operation 'Adam/update_conv-maxpool-4/W/ApplyAdam' type=ApplyAdam>,\n",
       " <tf.Operation 'Adam/update_conv-maxpool-4/b/ApplyAdam' type=ApplyAdam>,\n",
       " <tf.Operation 'Adam/update_conv-maxpool-5/W/ApplyAdam' type=ApplyAdam>,\n",
       " <tf.Operation 'Adam/update_conv-maxpool-5/b/ApplyAdam' type=ApplyAdam>,\n",
       " <tf.Operation 'Adam/update_W/ApplyAdam' type=ApplyAdam>,\n",
       " <tf.Operation 'Adam/update_output/b/ApplyAdam' type=ApplyAdam>,\n",
       " <tf.Operation 'Adam/mul' type=Mul>,\n",
       " <tf.Operation 'Adam/Assign' type=Assign>,\n",
       " <tf.Operation 'Adam/mul_1' type=Mul>,\n",
       " <tf.Operation 'Adam/Assign_1' type=Assign>,\n",
       " <tf.Operation 'Adam/update/NoOp' type=NoOp>,\n",
       " <tf.Operation 'Adam/update/NoOp_1' type=NoOp>,\n",
       " <tf.Operation 'Adam/update' type=NoOp>,\n",
       " <tf.Operation 'Adam/value' type=Const>,\n",
       " <tf.Operation 'Adam' type=AssignAdd>,\n",
       " <tf.Operation 'word_embedding/W_0/grad/hist/tag' type=Const>,\n",
       " <tf.Operation 'word_embedding/W_0/grad/hist/strided_slice/stack' type=Const>,\n",
       " <tf.Operation 'word_embedding/W_0/grad/hist/strided_slice/stack_1' type=Const>,\n",
       " <tf.Operation 'word_embedding/W_0/grad/hist/strided_slice/stack_2' type=Const>,\n",
       " <tf.Operation 'word_embedding/W_0/grad/hist/strided_slice' type=StridedSlice>,\n",
       " <tf.Operation 'word_embedding/W_0/grad/hist/values' type=UnsortedSegmentSum>,\n",
       " <tf.Operation 'word_embedding/W_0/grad/hist' type=HistogramSummary>,\n",
       " <tf.Operation 'zero_fraction/strided_slice/stack' type=Const>,\n",
       " <tf.Operation 'zero_fraction/strided_slice/stack_1' type=Const>,\n",
       " <tf.Operation 'zero_fraction/strided_slice/stack_2' type=Const>,\n",
       " <tf.Operation 'zero_fraction/strided_slice' type=StridedSlice>,\n",
       " <tf.Operation 'zero_fraction/value' type=UnsortedSegmentSum>,\n",
       " <tf.Operation 'zero_fraction/zero' type=Const>,\n",
       " <tf.Operation 'zero_fraction/Equal' type=Equal>,\n",
       " <tf.Operation 'zero_fraction/Cast' type=Cast>,\n",
       " <tf.Operation 'zero_fraction/Const' type=Const>,\n",
       " <tf.Operation 'zero_fraction/Mean' type=Mean>,\n",
       " <tf.Operation 'word_embedding/W_0/grad/sparsity/tags' type=Const>,\n",
       " <tf.Operation 'word_embedding/W_0/grad/sparsity' type=ScalarSummary>,\n",
       " <tf.Operation 'conv-maxpool-3/W_0/grad/hist/tag' type=Const>,\n",
       " <tf.Operation 'conv-maxpool-3/W_0/grad/hist' type=HistogramSummary>,\n",
       " <tf.Operation 'zero_fraction_1/zero' type=Const>,\n",
       " <tf.Operation 'zero_fraction_1/Equal' type=Equal>,\n",
       " <tf.Operation 'zero_fraction_1/Cast' type=Cast>,\n",
       " <tf.Operation 'zero_fraction_1/Const' type=Const>,\n",
       " <tf.Operation 'zero_fraction_1/Mean' type=Mean>,\n",
       " <tf.Operation 'conv-maxpool-3/W_0/grad/sparsity/tags' type=Const>,\n",
       " <tf.Operation 'conv-maxpool-3/W_0/grad/sparsity' type=ScalarSummary>,\n",
       " <tf.Operation 'conv-maxpool-3/b_0/grad/hist/tag' type=Const>,\n",
       " <tf.Operation 'conv-maxpool-3/b_0/grad/hist' type=HistogramSummary>,\n",
       " <tf.Operation 'zero_fraction_2/zero' type=Const>,\n",
       " <tf.Operation 'zero_fraction_2/Equal' type=Equal>,\n",
       " <tf.Operation 'zero_fraction_2/Cast' type=Cast>,\n",
       " <tf.Operation 'zero_fraction_2/Const' type=Const>,\n",
       " <tf.Operation 'zero_fraction_2/Mean' type=Mean>,\n",
       " <tf.Operation 'conv-maxpool-3/b_0/grad/sparsity/tags' type=Const>,\n",
       " <tf.Operation 'conv-maxpool-3/b_0/grad/sparsity' type=ScalarSummary>,\n",
       " <tf.Operation 'conv-maxpool-4/W_0/grad/hist/tag' type=Const>,\n",
       " <tf.Operation 'conv-maxpool-4/W_0/grad/hist' type=HistogramSummary>,\n",
       " <tf.Operation 'zero_fraction_3/zero' type=Const>,\n",
       " <tf.Operation 'zero_fraction_3/Equal' type=Equal>,\n",
       " <tf.Operation 'zero_fraction_3/Cast' type=Cast>,\n",
       " <tf.Operation 'zero_fraction_3/Const' type=Const>,\n",
       " <tf.Operation 'zero_fraction_3/Mean' type=Mean>,\n",
       " <tf.Operation 'conv-maxpool-4/W_0/grad/sparsity/tags' type=Const>,\n",
       " <tf.Operation 'conv-maxpool-4/W_0/grad/sparsity' type=ScalarSummary>,\n",
       " <tf.Operation 'conv-maxpool-4/b_0/grad/hist/tag' type=Const>,\n",
       " <tf.Operation 'conv-maxpool-4/b_0/grad/hist' type=HistogramSummary>,\n",
       " <tf.Operation 'zero_fraction_4/zero' type=Const>,\n",
       " <tf.Operation 'zero_fraction_4/Equal' type=Equal>,\n",
       " <tf.Operation 'zero_fraction_4/Cast' type=Cast>,\n",
       " <tf.Operation 'zero_fraction_4/Const' type=Const>,\n",
       " <tf.Operation 'zero_fraction_4/Mean' type=Mean>,\n",
       " <tf.Operation 'conv-maxpool-4/b_0/grad/sparsity/tags' type=Const>,\n",
       " <tf.Operation 'conv-maxpool-4/b_0/grad/sparsity' type=ScalarSummary>,\n",
       " <tf.Operation 'conv-maxpool-5/W_0/grad/hist/tag' type=Const>,\n",
       " <tf.Operation 'conv-maxpool-5/W_0/grad/hist' type=HistogramSummary>,\n",
       " <tf.Operation 'zero_fraction_5/zero' type=Const>,\n",
       " <tf.Operation 'zero_fraction_5/Equal' type=Equal>,\n",
       " <tf.Operation 'zero_fraction_5/Cast' type=Cast>,\n",
       " <tf.Operation 'zero_fraction_5/Const' type=Const>,\n",
       " <tf.Operation 'zero_fraction_5/Mean' type=Mean>,\n",
       " <tf.Operation 'conv-maxpool-5/W_0/grad/sparsity/tags' type=Const>,\n",
       " <tf.Operation 'conv-maxpool-5/W_0/grad/sparsity' type=ScalarSummary>,\n",
       " <tf.Operation 'conv-maxpool-5/b_0/grad/hist/tag' type=Const>,\n",
       " <tf.Operation 'conv-maxpool-5/b_0/grad/hist' type=HistogramSummary>,\n",
       " <tf.Operation 'zero_fraction_6/zero' type=Const>,\n",
       " <tf.Operation 'zero_fraction_6/Equal' type=Equal>,\n",
       " <tf.Operation 'zero_fraction_6/Cast' type=Cast>,\n",
       " <tf.Operation 'zero_fraction_6/Const' type=Const>,\n",
       " <tf.Operation 'zero_fraction_6/Mean' type=Mean>,\n",
       " <tf.Operation 'conv-maxpool-5/b_0/grad/sparsity/tags' type=Const>,\n",
       " <tf.Operation 'conv-maxpool-5/b_0/grad/sparsity' type=ScalarSummary>,\n",
       " <tf.Operation 'W_0/grad/hist/tag' type=Const>,\n",
       " <tf.Operation 'W_0/grad/hist' type=HistogramSummary>,\n",
       " <tf.Operation 'zero_fraction_7/zero' type=Const>,\n",
       " <tf.Operation 'zero_fraction_7/Equal' type=Equal>,\n",
       " <tf.Operation 'zero_fraction_7/Cast' type=Cast>,\n",
       " <tf.Operation 'zero_fraction_7/Const' type=Const>,\n",
       " <tf.Operation 'zero_fraction_7/Mean' type=Mean>,\n",
       " <tf.Operation 'W_0/grad/sparsity/tags' type=Const>,\n",
       " <tf.Operation 'W_0/grad/sparsity' type=ScalarSummary>,\n",
       " <tf.Operation 'output/b_0/grad/hist/tag' type=Const>,\n",
       " <tf.Operation 'output/b_0/grad/hist' type=HistogramSummary>,\n",
       " <tf.Operation 'zero_fraction_8/zero' type=Const>,\n",
       " <tf.Operation 'zero_fraction_8/Equal' type=Equal>,\n",
       " <tf.Operation 'zero_fraction_8/Cast' type=Cast>,\n",
       " <tf.Operation 'zero_fraction_8/Const' type=Const>,\n",
       " <tf.Operation 'zero_fraction_8/Mean' type=Mean>,\n",
       " <tf.Operation 'output/b_0/grad/sparsity/tags' type=Const>,\n",
       " <tf.Operation 'output/b_0/grad/sparsity' type=ScalarSummary>,\n",
       " <tf.Operation 'Merge/MergeSummary' type=MergeSummary>,\n",
       " <tf.Operation 'loss_1/tags' type=Const>,\n",
       " <tf.Operation 'loss_1' type=ScalarSummary>,\n",
       " <tf.Operation 'accuracy_1/tags' type=Const>,\n",
       " <tf.Operation 'accuracy_1' type=ScalarSummary>,\n",
       " <tf.Operation 'precision/tags' type=Const>,\n",
       " <tf.Operation 'precision' type=ScalarSummary>,\n",
       " <tf.Operation 'recall/tags' type=Const>,\n",
       " <tf.Operation 'recall' type=ScalarSummary>,\n",
       " <tf.Operation 'Merge_1/MergeSummary' type=MergeSummary>,\n",
       " <tf.Operation 'Merge_2/MergeSummary' type=MergeSummary>,\n",
       " <tf.Operation 'save/Const' type=Const>,\n",
       " <tf.Operation 'save/SaveV2/tensor_names' type=Const>,\n",
       " <tf.Operation 'save/SaveV2/shape_and_slices' type=Const>,\n",
       " <tf.Operation 'save/SaveV2' type=SaveV2>,\n",
       " <tf.Operation 'save/control_dependency' type=Identity>,\n",
       " <tf.Operation 'save/RestoreV2/tensor_names' type=Const>,\n",
       " <tf.Operation 'save/RestoreV2/shape_and_slices' type=Const>,\n",
       " <tf.Operation 'save/RestoreV2' type=RestoreV2>,\n",
       " <tf.Operation 'save/Assign' type=Assign>,\n",
       " <tf.Operation 'save/RestoreV2_1/tensor_names' type=Const>,\n",
       " <tf.Operation 'save/RestoreV2_1/shape_and_slices' type=Const>,\n",
       " <tf.Operation 'save/RestoreV2_1' type=RestoreV2>,\n",
       " <tf.Operation 'save/Assign_1' type=Assign>,\n",
       " <tf.Operation 'save/RestoreV2_2/tensor_names' type=Const>,\n",
       " <tf.Operation 'save/RestoreV2_2/shape_and_slices' type=Const>,\n",
       " <tf.Operation 'save/RestoreV2_2' type=RestoreV2>,\n",
       " <tf.Operation 'save/Assign_2' type=Assign>,\n",
       " <tf.Operation 'save/RestoreV2_3/tensor_names' type=Const>,\n",
       " <tf.Operation 'save/RestoreV2_3/shape_and_slices' type=Const>,\n",
       " <tf.Operation 'save/RestoreV2_3' type=RestoreV2>,\n",
       " <tf.Operation 'save/Assign_3' type=Assign>,\n",
       " <tf.Operation 'save/RestoreV2_4/tensor_names' type=Const>,\n",
       " <tf.Operation 'save/RestoreV2_4/shape_and_slices' type=Const>,\n",
       " <tf.Operation 'save/RestoreV2_4' type=RestoreV2>,\n",
       " <tf.Operation 'save/Assign_4' type=Assign>,\n",
       " <tf.Operation 'save/RestoreV2_5/tensor_names' type=Const>,\n",
       " <tf.Operation 'save/RestoreV2_5/shape_and_slices' type=Const>,\n",
       " <tf.Operation 'save/RestoreV2_5' type=RestoreV2>,\n",
       " <tf.Operation 'save/Assign_5' type=Assign>,\n",
       " <tf.Operation 'save/RestoreV2_6/tensor_names' type=Const>,\n",
       " <tf.Operation 'save/RestoreV2_6/shape_and_slices' type=Const>,\n",
       " <tf.Operation 'save/RestoreV2_6' type=RestoreV2>,\n",
       " <tf.Operation 'save/Assign_6' type=Assign>,\n",
       " <tf.Operation 'save/RestoreV2_7/tensor_names' type=Const>,\n",
       " <tf.Operation 'save/RestoreV2_7/shape_and_slices' type=Const>,\n",
       " <tf.Operation 'save/RestoreV2_7' type=RestoreV2>,\n",
       " <tf.Operation 'save/Assign_7' type=Assign>,\n",
       " <tf.Operation 'save/RestoreV2_8/tensor_names' type=Const>,\n",
       " <tf.Operation 'save/RestoreV2_8/shape_and_slices' type=Const>,\n",
       " <tf.Operation 'save/RestoreV2_8' type=RestoreV2>,\n",
       " <tf.Operation 'save/Assign_8' type=Assign>,\n",
       " <tf.Operation 'save/RestoreV2_9/tensor_names' type=Const>,\n",
       " <tf.Operation 'save/RestoreV2_9/shape_and_slices' type=Const>,\n",
       " <tf.Operation 'save/RestoreV2_9' type=RestoreV2>,\n",
       " <tf.Operation 'save/Assign_9' type=Assign>,\n",
       " <tf.Operation 'save/RestoreV2_10/tensor_names' type=Const>,\n",
       " <tf.Operation 'save/RestoreV2_10/shape_and_slices' type=Const>,\n",
       " <tf.Operation 'save/RestoreV2_10' type=RestoreV2>,\n",
       " <tf.Operation 'save/Assign_10' type=Assign>,\n",
       " <tf.Operation 'save/RestoreV2_11/tensor_names' type=Const>,\n",
       " <tf.Operation 'save/RestoreV2_11/shape_and_slices' type=Const>,\n",
       " <tf.Operation 'save/RestoreV2_11' type=RestoreV2>,\n",
       " <tf.Operation 'save/Assign_11' type=Assign>,\n",
       " <tf.Operation 'save/RestoreV2_12/tensor_names' type=Const>,\n",
       " <tf.Operation 'save/RestoreV2_12/shape_and_slices' type=Const>,\n",
       " <tf.Operation 'save/RestoreV2_12' type=RestoreV2>,\n",
       " <tf.Operation 'save/Assign_12' type=Assign>,\n",
       " <tf.Operation 'save/RestoreV2_13/tensor_names' type=Const>,\n",
       " <tf.Operation 'save/RestoreV2_13/shape_and_slices' type=Const>,\n",
       " <tf.Operation 'save/RestoreV2_13' type=RestoreV2>,\n",
       " <tf.Operation 'save/Assign_13' type=Assign>,\n",
       " <tf.Operation 'save/RestoreV2_14/tensor_names' type=Const>,\n",
       " <tf.Operation 'save/RestoreV2_14/shape_and_slices' type=Const>,\n",
       " <tf.Operation 'save/RestoreV2_14' type=RestoreV2>,\n",
       " <tf.Operation 'save/Assign_14' type=Assign>,\n",
       " <tf.Operation 'save/RestoreV2_15/tensor_names' type=Const>,\n",
       " <tf.Operation 'save/RestoreV2_15/shape_and_slices' type=Const>,\n",
       " <tf.Operation 'save/RestoreV2_15' type=RestoreV2>,\n",
       " <tf.Operation 'save/Assign_15' type=Assign>,\n",
       " <tf.Operation 'save/RestoreV2_16/tensor_names' type=Const>,\n",
       " <tf.Operation 'save/RestoreV2_16/shape_and_slices' type=Const>,\n",
       " <tf.Operation 'save/RestoreV2_16' type=RestoreV2>,\n",
       " <tf.Operation 'save/Assign_16' type=Assign>,\n",
       " <tf.Operation 'save/RestoreV2_17/tensor_names' type=Const>,\n",
       " <tf.Operation 'save/RestoreV2_17/shape_and_slices' type=Const>,\n",
       " <tf.Operation 'save/RestoreV2_17' type=RestoreV2>,\n",
       " <tf.Operation 'save/Assign_17' type=Assign>,\n",
       " <tf.Operation 'save/RestoreV2_18/tensor_names' type=Const>,\n",
       " <tf.Operation 'save/RestoreV2_18/shape_and_slices' type=Const>,\n",
       " <tf.Operation 'save/RestoreV2_18' type=RestoreV2>,\n",
       " <tf.Operation 'save/Assign_18' type=Assign>,\n",
       " <tf.Operation 'save/RestoreV2_19/tensor_names' type=Const>,\n",
       " <tf.Operation 'save/RestoreV2_19/shape_and_slices' type=Const>,\n",
       " <tf.Operation 'save/RestoreV2_19' type=RestoreV2>,\n",
       " <tf.Operation 'save/Assign_19' type=Assign>,\n",
       " <tf.Operation 'save/RestoreV2_20/tensor_names' type=Const>,\n",
       " <tf.Operation 'save/RestoreV2_20/shape_and_slices' type=Const>,\n",
       " <tf.Operation 'save/RestoreV2_20' type=RestoreV2>,\n",
       " <tf.Operation 'save/Assign_20' type=Assign>,\n",
       " <tf.Operation 'save/RestoreV2_21/tensor_names' type=Const>,\n",
       " <tf.Operation 'save/RestoreV2_21/shape_and_slices' type=Const>,\n",
       " <tf.Operation 'save/RestoreV2_21' type=RestoreV2>,\n",
       " <tf.Operation 'save/Assign_21' type=Assign>,\n",
       " <tf.Operation 'save/RestoreV2_22/tensor_names' type=Const>,\n",
       " <tf.Operation 'save/RestoreV2_22/shape_and_slices' type=Const>,\n",
       " <tf.Operation 'save/RestoreV2_22' type=RestoreV2>,\n",
       " <tf.Operation 'save/Assign_22' type=Assign>,\n",
       " <tf.Operation 'save/RestoreV2_23/tensor_names' type=Const>,\n",
       " <tf.Operation 'save/RestoreV2_23/shape_and_slices' type=Const>,\n",
       " <tf.Operation 'save/RestoreV2_23' type=RestoreV2>,\n",
       " <tf.Operation 'save/Assign_23' type=Assign>,\n",
       " <tf.Operation 'save/RestoreV2_24/tensor_names' type=Const>,\n",
       " <tf.Operation 'save/RestoreV2_24/shape_and_slices' type=Const>,\n",
       " <tf.Operation 'save/RestoreV2_24' type=RestoreV2>,\n",
       " <tf.Operation 'save/Assign_24' type=Assign>,\n",
       " <tf.Operation 'save/RestoreV2_25/tensor_names' type=Const>,\n",
       " <tf.Operation 'save/RestoreV2_25/shape_and_slices' type=Const>,\n",
       " <tf.Operation 'save/RestoreV2_25' type=RestoreV2>,\n",
       " <tf.Operation 'save/Assign_25' type=Assign>,\n",
       " <tf.Operation 'save/RestoreV2_26/tensor_names' type=Const>,\n",
       " <tf.Operation 'save/RestoreV2_26/shape_and_slices' type=Const>,\n",
       " <tf.Operation 'save/RestoreV2_26' type=RestoreV2>,\n",
       " <tf.Operation 'save/Assign_26' type=Assign>,\n",
       " <tf.Operation 'save/RestoreV2_27/tensor_names' type=Const>,\n",
       " <tf.Operation 'save/RestoreV2_27/shape_and_slices' type=Const>,\n",
       " <tf.Operation 'save/RestoreV2_27' type=RestoreV2>,\n",
       " <tf.Operation 'save/Assign_27' type=Assign>,\n",
       " <tf.Operation 'save/RestoreV2_28/tensor_names' type=Const>,\n",
       " <tf.Operation 'save/RestoreV2_28/shape_and_slices' type=Const>,\n",
       " <tf.Operation 'save/RestoreV2_28' type=RestoreV2>,\n",
       " <tf.Operation 'save/Assign_28' type=Assign>,\n",
       " <tf.Operation 'save/RestoreV2_29/tensor_names' type=Const>,\n",
       " <tf.Operation 'save/RestoreV2_29/shape_and_slices' type=Const>,\n",
       " <tf.Operation 'save/RestoreV2_29' type=RestoreV2>,\n",
       " <tf.Operation 'save/Assign_29' type=Assign>,\n",
       " <tf.Operation 'save/restore_all/NoOp' type=NoOp>,\n",
       " <tf.Operation 'save/restore_all/NoOp_1' type=NoOp>,\n",
       " <tf.Operation 'save/restore_all' type=NoOp>,\n",
       " <tf.Operation 'init/NoOp' type=NoOp>,\n",
       " <tf.Operation 'init/NoOp_1' type=NoOp>,\n",
       " <tf.Operation 'init' type=NoOp>,\n",
       " <tf.Operation 'init_1' type=NoOp>]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.graph.get_operations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pathwayA</th>\n",
       "      <th>pathwayB</th>\n",
       "      <th>crosstalk</th>\n",
       "      <th>pmid</th>\n",
       "      <th>sentenceFromPaper</th>\n",
       "      <th>label</th>\n",
       "      <th>tokenizedSentenceFromPaper</th>\n",
       "      <th>predictedLabel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adipocytokine signaling pathway</td>\n",
       "      <td>ErbB signaling pathway</td>\n",
       "      <td>yes</td>\n",
       "      <td>23228483</td>\n",
       "      <td>In the present study, we demonstrate that lept...</td>\n",
       "      <td>1</td>\n",
       "      <td>in the present study, we demonstrate that path...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adipocytokine signaling pathway</td>\n",
       "      <td>ErbB signaling pathway</td>\n",
       "      <td>yes</td>\n",
       "      <td>18945363</td>\n",
       "      <td>In summary, our results suggest the existence ...</td>\n",
       "      <td>1</td>\n",
       "      <td>in summary, our results suggest the existence ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adipocytokine signaling pathway</td>\n",
       "      <td>Estrogen signaling pathway</td>\n",
       "      <td>yes</td>\n",
       "      <td>20410173</td>\n",
       "      <td>These observations support the notion that the...</td>\n",
       "      <td>1</td>\n",
       "      <td>these observations support the notion that the...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Adipocytokine signaling pathway</td>\n",
       "      <td>Estrogen signaling pathway</td>\n",
       "      <td>yes</td>\n",
       "      <td>23357303</td>\n",
       "      <td>The crosstalk between leptin and estrogen resc...</td>\n",
       "      <td>1</td>\n",
       "      <td>the crosstalk between pathwayA and pathwayB re...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adipocytokine signaling pathway</td>\n",
       "      <td>Estrogen signaling pathway</td>\n",
       "      <td>yes</td>\n",
       "      <td>22178935</td>\n",
       "      <td>The study supports the existence of a crosstal...</td>\n",
       "      <td>1</td>\n",
       "      <td>the study supports the existence of a crosstal...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          pathwayA                    pathwayB crosstalk  \\\n",
       "0  Adipocytokine signaling pathway      ErbB signaling pathway       yes   \n",
       "1  Adipocytokine signaling pathway      ErbB signaling pathway       yes   \n",
       "2  Adipocytokine signaling pathway  Estrogen signaling pathway       yes   \n",
       "3  Adipocytokine signaling pathway  Estrogen signaling pathway       yes   \n",
       "4  Adipocytokine signaling pathway  Estrogen signaling pathway       yes   \n",
       "\n",
       "       pmid                                  sentenceFromPaper  label  \\\n",
       "0  23228483  In the present study, we demonstrate that lept...      1   \n",
       "1  18945363  In summary, our results suggest the existence ...      1   \n",
       "2  20410173  These observations support the notion that the...      1   \n",
       "3  23357303  The crosstalk between leptin and estrogen resc...      1   \n",
       "4  22178935  The study supports the existence of a crosstal...      1   \n",
       "\n",
       "                          tokenizedSentenceFromPaper  predictedLabel  \n",
       "0  in the present study, we demonstrate that path...               1  \n",
       "1  in summary, our results suggest the existence ...               1  \n",
       "2  these observations support the notion that the...               1  \n",
       "3  the crosstalk between pathwayA and pathwayB re...               1  \n",
       "4  the study supports the existence of a crosstal...               1  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_support_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output = np.zeros(sentence_support_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 0 => Train/Dev split: 31795/10599\n",
      "Fold: 1 => Train/Dev split: 31795/10599\n",
      "Fold: 2 => Train/Dev split: 31796/10598\n",
      "Fold: 3 => Train/Dev split: 31796/10598\n"
     ]
    }
   ],
   "source": [
    "# Creating folds\n",
    "kf = KFold(n_splits=4, random_state=5, shuffle=True)\n",
    "for k, (train_index, test_index) in enumerate(kf.split(x, y)):\n",
    "# for train_index, test_index in kf.split(x):\n",
    "#     print(\"Fold: %s =>\" % k,  \"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    x_train, x_dev = x[train_index], x[test_index]\n",
    "    y_train, y_dev = y[train_index], y[test_index]\n",
    "    \n",
    "    train_word_distancesA = word_distancesA[train_index]\n",
    "    train_word_distancesB = word_distancesB[train_index]\n",
    "    \n",
    "    test_word_distancesA = word_distancesA[test_index]\n",
    "    test_word_distancesB = word_distancesB[test_index]\n",
    "    \n",
    "    train_pos_embedding = pos_embedding[train_index]\n",
    "    test_pos_embedding = pos_embedding[test_index]\n",
    "    \n",
    "    print(\"Fold: %s =>\" % k, \"Train/Dev split: {:d}/{:d}\".format(len(y_train), len(y_dev)))\n",
    "    \n",
    "    def predict(x,y,word_distancesA, word_distancesB, pos_embedding):\n",
    "        input_x = sess.graph.get_tensor_by_name('input_x:0')\n",
    "        input_y = sess.graph.get_tensor_by_name('input_y:0')\n",
    "        dropout_keep_prob = sess.graph.get_tensor_by_name('dropout_keep_prob:0')\n",
    "        wA = sess.graph.get_tensor_by_name('word_distancesA:0')\n",
    "        wB = sess.graph.get_tensor_by_name('word_distancesB:0')\n",
    "        encoded_pos = sess.graph.get_tensor_by_name('encoded_pos:0')\n",
    "\n",
    "        return sess.run(sess.graph.get_tensor_by_name('output/predictions:0'), feed_dict = {\n",
    "                  input_x: x,\n",
    "                  input_y: y,\n",
    "                  dropout_keep_prob: 1.0,\n",
    "                  wA: word_distancesA,\n",
    "                  wB: word_distancesB,\n",
    "                  encoded_pos: pos_embedding\n",
    "                })\n",
    "    output[test_index] = predict(x_dev, y_dev, test_word_distancesA, test_word_distancesB, test_pos_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    42394.000000\n",
       "mean         0.014578\n",
       "std          0.119856\n",
       "min          0.000000\n",
       "25%          0.000000\n",
       "50%          0.000000\n",
       "75%          0.000000\n",
       "max          1.000000\n",
       "Name: predictedLabel, dtype: float64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_support_df['predictedLabel'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentence_support_df['predictedLabel'] = pd.Series(output, dtype='int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    40626.000000\n",
       "mean         0.026412\n",
       "std          0.160358\n",
       "min          0.000000\n",
       "25%          0.000000\n",
       "50%          0.000000\n",
       "75%          0.000000\n",
       "max          1.000000\n",
       "Name: predictedLabel, dtype: float64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_support_df['predictedLabel'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39879, 8)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_support_df[sentence_support_df['predictedLabel'] == sentence_support_df['label']].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pathwayA</th>\n",
       "      <th>pathwayB</th>\n",
       "      <th>crosstalk</th>\n",
       "      <th>pmid</th>\n",
       "      <th>sentenceFromPaper</th>\n",
       "      <th>label</th>\n",
       "      <th>tokenizedSentenceFromPaper</th>\n",
       "      <th>predictedLabel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adipocytokine signaling pathway</td>\n",
       "      <td>ErbB signaling pathway</td>\n",
       "      <td>1</td>\n",
       "      <td>23228483</td>\n",
       "      <td>In the present study, we demonstrate that lept...</td>\n",
       "      <td>1</td>\n",
       "      <td>in the present study, we demonstrate that path...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adipocytokine signaling pathway</td>\n",
       "      <td>ErbB signaling pathway</td>\n",
       "      <td>1</td>\n",
       "      <td>18945363</td>\n",
       "      <td>In summary, our results suggest the existence ...</td>\n",
       "      <td>1</td>\n",
       "      <td>in summary, our results suggest the existence ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adipocytokine signaling pathway</td>\n",
       "      <td>Estrogen signaling pathway</td>\n",
       "      <td>1</td>\n",
       "      <td>20410173</td>\n",
       "      <td>These observations support the notion that the...</td>\n",
       "      <td>1</td>\n",
       "      <td>these observations support the notion that the...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Adipocytokine signaling pathway</td>\n",
       "      <td>Estrogen signaling pathway</td>\n",
       "      <td>1</td>\n",
       "      <td>23357303</td>\n",
       "      <td>The crosstalk between leptin and estrogen resc...</td>\n",
       "      <td>1</td>\n",
       "      <td>the crosstalk between pathwayA and pathwayB re...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adipocytokine signaling pathway</td>\n",
       "      <td>Estrogen signaling pathway</td>\n",
       "      <td>1</td>\n",
       "      <td>22178935</td>\n",
       "      <td>The study supports the existence of a crosstal...</td>\n",
       "      <td>1</td>\n",
       "      <td>the study supports the existence of a crosstal...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          pathwayA                    pathwayB  crosstalk  \\\n",
       "0  Adipocytokine signaling pathway      ErbB signaling pathway          1   \n",
       "1  Adipocytokine signaling pathway      ErbB signaling pathway          1   \n",
       "2  Adipocytokine signaling pathway  Estrogen signaling pathway          1   \n",
       "3  Adipocytokine signaling pathway  Estrogen signaling pathway          1   \n",
       "4  Adipocytokine signaling pathway  Estrogen signaling pathway          1   \n",
       "\n",
       "       pmid                                  sentenceFromPaper  label  \\\n",
       "0  23228483  In the present study, we demonstrate that lept...      1   \n",
       "1  18945363  In summary, our results suggest the existence ...      1   \n",
       "2  20410173  These observations support the notion that the...      1   \n",
       "3  23357303  The crosstalk between leptin and estrogen resc...      1   \n",
       "4  22178935  The study supports the existence of a crosstal...      1   \n",
       "\n",
       "                          tokenizedSentenceFromPaper  predictedLabel  \n",
       "0  in the present study, we demonstrate that path...             1.0  \n",
       "1  in summary, our results suggest the existence ...             1.0  \n",
       "2  these observations support the notion that the...             1.0  \n",
       "3  the crosstalk between pathwayA and pathwayB re...             0.0  \n",
       "4  the study supports the existence of a crosstal...             1.0  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_support_df['crosstalk'] = sentence_support_df['crosstalk'].replace(['unclear', 'no'], 0)\n",
    "sentence_support_df['crosstalk'] = sentence_support_df['crosstalk'].replace(['yes'], 1)\n",
    "sentence_support_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    41776\n",
       "1      618\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_support_df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pathwayA</th>\n",
       "      <th>pathwayB</th>\n",
       "      <th>pmid</th>\n",
       "      <th>crosstalk</th>\n",
       "      <th>label</th>\n",
       "      <th>predictedLabel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adherens junction</td>\n",
       "      <td>Adipocytokine signaling pathway</td>\n",
       "      <td>18537097</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adherens junction</td>\n",
       "      <td>Apoptosis</td>\n",
       "      <td>23375756</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adherens junction</td>\n",
       "      <td>Apoptosis</td>\n",
       "      <td>25488805</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Adherens junction</td>\n",
       "      <td>Apoptosis</td>\n",
       "      <td>25546411</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adherens junction</td>\n",
       "      <td>Apoptosis</td>\n",
       "      <td>25725070</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            pathwayA                         pathwayB      pmid  crosstalk  \\\n",
       "0  Adherens junction  Adipocytokine signaling pathway  18537097          0   \n",
       "1  Adherens junction                        Apoptosis  23375756          0   \n",
       "2  Adherens junction                        Apoptosis  25488805          1   \n",
       "3  Adherens junction                        Apoptosis  25546411          0   \n",
       "4  Adherens junction                        Apoptosis  25725070          0   \n",
       "\n",
       "   label  predictedLabel  \n",
       "0      0               0  \n",
       "1      0               1  \n",
       "2      1               1  \n",
       "3      0               0  \n",
       "4      0               0  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_support = sentence_support_df[['pathwayA', 'pathwayB','pmid', 'crosstalk', 'label', 'predictedLabel']]\n",
    "documents = pd.DataFrame(sentence_support.groupby(['pathwayA', 'pathwayB','pmid']).sum()).reset_index()\n",
    "documents['crosstalk'] = documents['crosstalk'].apply(lambda x: 1 if x>0 else 0)\n",
    "documents['label'] = documents['label'].apply(lambda x: 1 if x>0 else 0)\n",
    "documents['predictedLabel'] = documents['predictedLabel'].apply(lambda x: 1 if x>0 else 0)\n",
    "documents.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.58156911581569115"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, classification_report, accuracy_score, roc_auc_score\n",
    "precision_score(documents.label, documents.predictedLabel)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    2353\n",
       "1.0     591\n",
       "2.0     164\n",
       "3.0      40\n",
       "4.0       6\n",
       "5.0       2\n",
       "Name: predictedLabel, dtype: int64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents.predictedLabel.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "    non-sup       0.96      0.88      0.92      2703\n",
      "        sup       0.58      0.82      0.68       568\n",
      "\n",
      "avg / total       0.89      0.87      0.87      3271\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(documents.label, documents.predictedLabel, target_names=['non-sup', 'sup']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.866401712015\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(documents.label, documents.predictedLabel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.848938386144\n"
     ]
    }
   ],
   "source": [
    "print(roc_auc_score(documents.label, documents.predictedLabel))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Machine learning performance\n",
    "\n",
    "accuracy_score 0.449939686369\n",
    "\n",
    "recall_score 0.788321167883\n",
    "\n",
    "precision_score 0.201869158879\n",
    "\n",
    "f1_score 0.321428571429"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pathwayA</th>\n",
       "      <th>pathwayB</th>\n",
       "      <th>crosstalk</th>\n",
       "      <th>predictedLabel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adherens junction</td>\n",
       "      <td>Adipocytokine signaling pathway</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adherens junction</td>\n",
       "      <td>Apoptosis</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adherens junction</td>\n",
       "      <td>ErbB signaling pathway</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Adherens junction</td>\n",
       "      <td>Estrogen signaling pathway</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adherens junction</td>\n",
       "      <td>HIF-1 signaling pathway</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            pathwayA                         pathwayB  crosstalk  \\\n",
       "0  Adherens junction  Adipocytokine signaling pathway          0   \n",
       "1  Adherens junction                        Apoptosis          1   \n",
       "2  Adherens junction           ErbB signaling pathway          1   \n",
       "3  Adherens junction       Estrogen signaling pathway          1   \n",
       "4  Adherens junction          HIF-1 signaling pathway          0   \n",
       "\n",
       "   predictedLabel  \n",
       "0               0  \n",
       "1               1  \n",
       "2               1  \n",
       "3               1  \n",
       "4               0  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pathway_pairs = pd.DataFrame(documents.groupby(['pathwayA', 'pathwayB']).sum()).reset_index()[['pathwayA', 'pathwayB', 'crosstalk', 'predictedLabel']]\n",
    "pathway_pairs.drop_duplicates(inplace=True)\n",
    "pathway_pairs.crosstalk = pathway_pairs.crosstalk.apply(lambda x: 1 if x>0 else 0)\n",
    "pathway_pairs.predictedLabel = pathway_pairs.predictedLabel.apply(lambda x: 1 if x>0 else 0)\n",
    "pathway_pairs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "no crosstalk       0.85      0.55      0.67       273\n",
      "   crosstalk       0.72      0.92      0.81       345\n",
      "\n",
      " avg / total       0.78      0.76      0.75       618\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(pathway_pairs.crosstalk, pathway_pairs.predictedLabel, target_names=['no crosstalk', 'crosstalk']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.758899676375\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(pathway_pairs.crosstalk, pathway_pairs.predictedLabel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.737044115305\n"
     ]
    }
   ],
   "source": [
    "print(roc_auc_score(pathway_pairs.crosstalk, pathway_pairs.predictedLabel))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Machine learning performance\n",
    "\n",
    "accuracy_score 0.548387096774\n",
    "\n",
    "recall_score 0.5\n",
    "\n",
    "precision_score 0.628571428571\n",
    "\n",
    "f1_score 0.556962025316"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "accuracy_score 0.548387096774\n",
    "recall_score 0.5\n",
    "precision_score 0.628571428571\n",
    "f1_score 0.556962025316"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
